{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IouSX_uZ68uj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "#convolutional block\n",
        "def conv_block(x, kernelsize, filters, dropout, batchnorm=False): \n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "\n",
        "#residual convolutional block\n",
        "def res_conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv1 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        conv1 = layers.BatchNormalization(axis=3)(conv1)\n",
        "    conv1 = layers.Activation('relu')(conv1)    \n",
        "    conv2 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(conv1)\n",
        "    if batchnorm is True:\n",
        "        conv2 = layers.BatchNormalization(axis=3)(conv2)\n",
        "        conv2 = layers.Activation(\"relu\")(conv2)\n",
        "    if dropout > 0:\n",
        "        conv2 = layers.Dropout(dropout)(conv2)\n",
        "        \n",
        "    #skip connection    \n",
        "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "    shortcut = layers.Activation(\"relu\")(shortcut)\n",
        "    respath = layers.add([shortcut, conv2])       \n",
        "    return respath\n",
        "\n",
        "\n",
        "#gating signal for attention unit\n",
        "def gatingsignal(input, out_size, batchnorm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batchnorm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "#attention unit/block based on soft attention\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x) \n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg) \n",
        "    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)                          \n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n",
        "    attenblock = layers.BatchNormalization()(result)\n",
        "    return attenblock\n",
        "\n",
        "#Simple U-NET\n",
        "def unetmodel(input_shape, dropout=0.2, batchnorm=True):    \n",
        "    \n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "    \n",
        "    inputs = layers.Input(input_shape)    \n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "    \n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "    \n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "    \n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "    \n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers   \n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, dn_4], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "    \n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, dn_3], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "       \n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, dn_2], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "    \n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, dn_1], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)    \n",
        "   \n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)  \n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()        \n",
        "    return model\n",
        "\n",
        "    \n",
        "#Attention U-NET\n",
        "def attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "    \n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape) \n",
        "\n",
        "    # Downsampling layers    \n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "    \n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "    \n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "    \n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "    \n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers    \n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "    \n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "   \n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "    \n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "    \n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)  \n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()       \n",
        "    return model    \n",
        "\n",
        "#Res-UNET\n",
        "def residualunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape) \n",
        "\n",
        "    # Downsampling layers    \n",
        "    dn_conv1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    dn_pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv1)\n",
        "\n",
        "    dn_conv2 = res_conv_block(dn_pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    dn_pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv2)\n",
        "\n",
        "    dn_conv3 = res_conv_block(dn_pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    dn_pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv3)\n",
        "\n",
        "    dn_conv4 = res_conv_block(dn_pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    dn_pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv4)\n",
        "\n",
        "    dn_conv5 = res_conv_block(dn_pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "   \n",
        "    # upsampling layers\n",
        "    up_conv6 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_conv5)\n",
        "    up_conv6 = layers.concatenate([up_conv6, dn_conv4], axis=3)\n",
        "    up_conv6 = res_conv_block(up_conv6, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_conv7 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv6)\n",
        "    up_conv7 = layers.concatenate([up_conv7, dn_conv3], axis=3)\n",
        "    up_conv7 = res_conv_block(up_conv7, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_conv8 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv7)\n",
        "    up_conv8 = layers.concatenate([up_conv8, dn_conv2], axis=3)\n",
        "    up_conv8 = res_conv_block(up_conv8, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_conv9 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv8)\n",
        "    up_conv9 = layers.concatenate([up_conv9, dn_conv1], axis=3)\n",
        "    up_conv9 = res_conv_block(up_conv9, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv9)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final) \n",
        "    \n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "#Residual-Attention UNET (RA-UNET)\n",
        "def residual_attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "    \n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "    \n",
        "    inputs = layers.Input(input_shape)    \n",
        "    \n",
        "    # Downsampling layers\n",
        "    dn_1 = res_conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = res_conv_block(pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = res_conv_block(pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = res_conv_block(pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = res_conv_block(pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers    \n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = res_conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "    \n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = res_conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "   \n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = res_conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "    \n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = res_conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "   \n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)  \n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary() \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "\n",
        "\n",
        "def IoU_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def IoU_loss(y_true, y_pred):\n",
        "    return -IoU_coef(y_true, y_pred)\n",
        " \n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        " \n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "  \n",
        "def accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    return acc\n",
        "  \n",
        "def IoU(y_true, y_pred, labels = [0, 1]):\n",
        "   IoU = []\n",
        "   for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "      IoU.append(jaccard)     \n",
        "   return np.mean(IoU) "
      ],
      "metadata": {
        "id": "R9n0BtLe7GTU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tifffile \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C4fPJgPB180",
        "outputId": "cbd83a83-579e-4215-eaca-39023d9a0d62"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (2021.11.2)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tifffile) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "np.random.seed(0) \n",
        "\n",
        "\n",
        "#CLAHE\n",
        "def clahe_equalized(imgs):    \n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))    \n",
        "    imgs_equalized = clahe.apply(imgs)\n",
        "    return imgs_equalized\n",
        "\n",
        "\n",
        "path1 = '/content/drive/MyDrive/DRIVE/training/images/' #training images directory\n",
        "path2 = '/content/drive/MyDrive/DRIVE/training/1st_manual/' #training masks directory\n",
        "\n",
        "image_dataset = []\n",
        "mask_dataset = [] \n",
        "\n",
        "patch_size = 512\n",
        "\n",
        "images = sorted(os.listdir(path1)) \n",
        "!pip install imagecodecs\n",
        "for i, image_name in enumerate(images):  \n",
        "   if image_name.endswith(\".tif\"):                   \n",
        "       image = skimage.io.imread(path1+\"/\"+image_name)  #Read image\n",
        "       image = image[:,:,1] #selecting green channel\n",
        "       image = clahe_equalized(image) #applying CLAHE\n",
        "       SIZE_X = (image.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       SIZE_Y = (image.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       image = Image.fromarray(image)        \n",
        "       image = image.resize((SIZE_X, SIZE_Y)) #resize image       \n",
        "       image = np.array(image) \n",
        "       patches_img = patchify(image, (patch_size, patch_size), step=patch_size)  #create patches(patch_sizexpatch_sizex1)\n",
        "            \n",
        "       for i in range(patches_img.shape[0]):\n",
        "           for j in range(patches_img.shape[1]):                        \n",
        "               single_patch_img = patches_img[i,j,:,:]                 \n",
        "               single_patch_img = (single_patch_img.astype('float32')) / 255.                    \n",
        "               image_dataset.append(single_patch_img)\n",
        "\n",
        "masks = sorted(os.listdir(path2))  \n",
        "for i, mask_name in enumerate(masks):  \n",
        "    if mask_name.endswith(\".gif\"):                  \n",
        "        mask = skimage.io.imread(path2+\"/\"+mask_name)   #Read masks\n",
        "        print(\"mask namexxxxxxxxxxxxxx\",mask_name)\n",
        "        print(\"mask\",mask)\n",
        "        print(\"mask_path\",path2+\"/\"+mask_name)\n",
        "        \n",
        "        SIZE_X = (mask.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "        SIZE_Y = (mask.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "        mask = Image.fromarray(mask)        \n",
        "        mask = mask.resize((SIZE_X, SIZE_Y))  #resize image\n",
        "        mask = np.array(mask)\n",
        "        patches_mask = patchify(mask, (patch_size, patch_size), step=patch_size)  #create patches(patch_sizexpatch_sizex1)\n",
        "            \n",
        "        for i in range(patches_mask.shape[0]):\n",
        "            for j in range(patches_mask.shape[1]):                            \n",
        "                single_patch_mask = patches_mask[i,j,:,:]\n",
        "                single_patch_mask = (single_patch_mask.astype('float32'))/255. \n",
        "                mask_dataset.append(single_patch_mask) \n",
        " \n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "image_dataset = np.expand_dims(image_dataset,axis=-1)\n",
        "mask_dataset =  np.expand_dims(mask_dataset,axis=-1)\n",
        "\n",
        "\n",
        "#importing models\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "IMG_HEIGHT = patch_size\n",
        "IMG_WIDTH = patch_size\n",
        "IMG_CHANNELS = 1\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = unetmodel(input_shape)\n",
        "model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "#model = residualunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "#model = attentionunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "#model = residual_attentionunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "\n",
        "#splitting data into 70-30 ratio to validate training performance\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size=0.2, random_state=0)\n",
        "\n",
        "#train model\n",
        "history = model.fit(x_train, y_train, \n",
        "                    verbose=1,\n",
        "                    batch_size = 16,\n",
        "                    validation_data=(x_test, y_test ), \n",
        "                    shuffle=False,\n",
        "                    epochs=2000)\n",
        "\n",
        "#training-validation loss curve\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation accuracy curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'y', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation IoU curve\n",
        "iou_coef = history.history['IoU_coef']\n",
        "val_iou_coef = history.history['val_IoU_coef']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, iou_coef, 'r', label='Training IoU')\n",
        "plt.plot(epochs, val_iou_coef, 'y', label='Validation IoU')\n",
        "plt.title('Training and validation IoU coefficients')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#save model\n",
        "#model.save('/content/drive/MyDrive/training/retina_Unet_150epochs.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jz3_cGZ97HAV",
        "outputId": "25927aad-78a2-4fdb-f848-1785c7076605"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (2021.11.20)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n",
            "mask namexxxxxxxxxxxxxx 21_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//21_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 22_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//22_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 23_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//23_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 24_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//24_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 25_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//25_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 26_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//26_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 27_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//27_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 28_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//28_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 29_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//29_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 30_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//30_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 31_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//31_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 32_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//32_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 33_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//33_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 34_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//34_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 35_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//35_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 36_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//36_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 37_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//37_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 38_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//38_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 39_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//39_manual1.gif\n",
            "mask namexxxxxxxxxxxxxx 40_manual1.gif\n",
            "mask [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "mask_path /content/drive/MyDrive/DRIVE/training/1st_manual//40_manual1.gif\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 512, 512, 16  160         ['input_9[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 512, 512, 16  64         ['conv2d_152[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_152[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_72 (Dropout)           (None, 512, 512, 16  0           ['activation_152[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 512, 512, 16  2320        ['dropout_72[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 512, 512, 16  64         ['conv2d_153[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_153[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooling2D  (None, 256, 256, 16  0          ['activation_153[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 256, 256, 32  4640        ['max_pooling2d_32[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 256, 256, 32  128        ['conv2d_154[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_154[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_73 (Dropout)           (None, 256, 256, 32  0           ['activation_154[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 256, 256, 32  9248        ['dropout_73[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 256, 256, 32  128        ['conv2d_155[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_155[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooling2D  (None, 128, 128, 32  0          ['activation_155[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 128, 128, 64  18496       ['max_pooling2d_33[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 128, 128, 64  256        ['conv2d_156[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_156[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)           (None, 128, 128, 64  0           ['activation_156[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 128, 128, 64  36928       ['dropout_74[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 128, 128, 64  256        ['conv2d_157[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_157[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_34 (MaxPooling2D  (None, 64, 64, 64)  0           ['activation_157[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 64, 64, 128)  73856       ['max_pooling2d_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 64, 64, 128)  512        ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 64, 64, 128)  0           ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 64, 64, 128)  147584      ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 64, 64, 128)  512        ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_35 (MaxPooling2D  (None, 32, 32, 128)  0          ['activation_159[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 32, 32, 256)  295168      ['max_pooling2d_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 32, 32, 256)  1024       ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)           (None, 32, 32, 256)  0           ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 32, 32, 256)  590080      ['dropout_76[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 32, 32, 256)  1024       ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_32 (UpSampling2D  (None, 64, 64, 256)  0          ['activation_161[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 64, 64, 384)  0           ['up_sampling2d_32[0][0]',       \n",
            "                                                                  'activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 64, 64, 128)  442496      ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 64, 64, 128)  512        ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)           (None, 64, 64, 128)  0           ['activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 64, 64, 128)  147584      ['dropout_77[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 64, 64, 128)  512        ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_33 (UpSampling2D  (None, 128, 128, 12  0          ['activation_163[0][0]']         \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 128, 128, 19  0           ['up_sampling2d_33[0][0]',       \n",
            "                                2)                                'activation_157[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 128, 128, 64  110656      ['concatenate_33[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 128, 128, 64  256        ['conv2d_164[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_164[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_78 (Dropout)           (None, 128, 128, 64  0           ['activation_164[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 128, 128, 64  36928       ['dropout_78[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 128, 128, 64  256        ['conv2d_165[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_165[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_34 (UpSampling2D  (None, 256, 256, 64  0          ['activation_165[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 256, 256, 96  0           ['up_sampling2d_34[0][0]',       \n",
            "                                )                                 'activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 256, 256, 32  27680       ['concatenate_34[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 256, 256, 32  128        ['conv2d_166[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_166[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_79 (Dropout)           (None, 256, 256, 32  0           ['activation_166[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 256, 256, 32  9248        ['dropout_79[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 256, 256, 32  128        ['conv2d_167[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_167[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_35 (UpSampling2D  (None, 512, 512, 32  0          ['activation_167[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 512, 512, 48  0           ['up_sampling2d_35[0][0]',       \n",
            "                                )                                 'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 512, 512, 16  6928        ['concatenate_35[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 512, 512, 16  64         ['conv2d_168[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_168[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_80 (Dropout)           (None, 512, 512, 16  0           ['activation_168[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 512, 512, 16  2320        ['dropout_80[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 512, 512, 16  64         ['conv2d_169[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_169[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 512, 512, 1)  17          ['activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 512, 512, 1)  4          ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 512, 512, 1)  0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,968,229\n",
            "Trainable params: 1,965,283\n",
            "Non-trainable params: 2,946\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: -0.0829 - accuracy: 0.4988 - IoU_coef: 0.0829 - val_loss: -0.0758 - val_accuracy: 0.7731 - val_IoU_coef: 0.0758\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: -0.0973 - accuracy: 0.5467 - IoU_coef: 0.0973 - val_loss: -0.0647 - val_accuracy: 0.8608 - val_IoU_coef: 0.0647\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: -0.1097 - accuracy: 0.5680 - IoU_coef: 0.1097 - val_loss: -0.0374 - val_accuracy: 0.8659 - val_IoU_coef: 0.0374\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: -0.1182 - accuracy: 0.5890 - IoU_coef: 0.1182 - val_loss: -0.0635 - val_accuracy: 0.7546 - val_IoU_coef: 0.0635\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: -0.1248 - accuracy: 0.5969 - IoU_coef: 0.1248 - val_loss: -0.0996 - val_accuracy: 0.3055 - val_IoU_coef: 0.0996\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 1s 533ms/step - loss: -0.1299 - accuracy: 0.6214 - IoU_coef: 0.1299 - val_loss: -0.0952 - val_accuracy: 0.1675 - val_IoU_coef: 0.0952\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: -0.1338 - accuracy: 0.6577 - IoU_coef: 0.1338 - val_loss: -0.0922 - val_accuracy: 0.1421 - val_IoU_coef: 0.0922\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 1s 526ms/step - loss: -0.1369 - accuracy: 0.6841 - IoU_coef: 0.1369 - val_loss: -0.0913 - val_accuracy: 0.1359 - val_IoU_coef: 0.0913\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.1392 - accuracy: 0.7017 - IoU_coef: 0.1392 - val_loss: -0.0909 - val_accuracy: 0.1359 - val_IoU_coef: 0.0909\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.1410 - accuracy: 0.7228 - IoU_coef: 0.1410 - val_loss: -0.0910 - val_accuracy: 0.1409 - val_IoU_coef: 0.0910\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 474ms/step - loss: -0.1428 - accuracy: 0.7295 - IoU_coef: 0.1428 - val_loss: -0.0913 - val_accuracy: 0.1476 - val_IoU_coef: 0.0913\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.1442 - accuracy: 0.7288 - IoU_coef: 0.1442 - val_loss: -0.0916 - val_accuracy: 0.1561 - val_IoU_coef: 0.0916\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.1454 - accuracy: 0.7350 - IoU_coef: 0.1454 - val_loss: -0.0921 - val_accuracy: 0.1682 - val_IoU_coef: 0.0921\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: -0.1465 - accuracy: 0.7405 - IoU_coef: 0.1465 - val_loss: -0.0930 - val_accuracy: 0.1847 - val_IoU_coef: 0.0930\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: -0.1473 - accuracy: 0.7422 - IoU_coef: 0.1473 - val_loss: -0.0947 - val_accuracy: 0.2101 - val_IoU_coef: 0.0947\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 491ms/step - loss: -0.1483 - accuracy: 0.7476 - IoU_coef: 0.1483 - val_loss: -0.0974 - val_accuracy: 0.2483 - val_IoU_coef: 0.0974\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.1490 - accuracy: 0.7515 - IoU_coef: 0.1490 - val_loss: -0.1001 - val_accuracy: 0.2840 - val_IoU_coef: 0.1001\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1496 - accuracy: 0.7537 - IoU_coef: 0.1496 - val_loss: -0.1022 - val_accuracy: 0.3180 - val_IoU_coef: 0.1022\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1503 - accuracy: 0.7548 - IoU_coef: 0.1503 - val_loss: -0.1039 - val_accuracy: 0.3562 - val_IoU_coef: 0.1039\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1508 - accuracy: 0.7586 - IoU_coef: 0.1508 - val_loss: -0.1055 - val_accuracy: 0.4056 - val_IoU_coef: 0.1055\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1513 - accuracy: 0.7626 - IoU_coef: 0.1513 - val_loss: -0.1071 - val_accuracy: 0.4609 - val_IoU_coef: 0.1071\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1519 - accuracy: 0.7660 - IoU_coef: 0.1519 - val_loss: -0.1081 - val_accuracy: 0.5380 - val_IoU_coef: 0.1081\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1523 - accuracy: 0.7699 - IoU_coef: 0.1523 - val_loss: -0.1059 - val_accuracy: 0.6432 - val_IoU_coef: 0.1059\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1527 - accuracy: 0.7750 - IoU_coef: 0.1527 - val_loss: -0.1009 - val_accuracy: 0.7275 - val_IoU_coef: 0.1009\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1532 - accuracy: 0.7784 - IoU_coef: 0.1532 - val_loss: -0.0968 - val_accuracy: 0.7705 - val_IoU_coef: 0.0968\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1535 - accuracy: 0.7801 - IoU_coef: 0.1535 - val_loss: -0.0936 - val_accuracy: 0.7960 - val_IoU_coef: 0.0936\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1539 - accuracy: 0.7806 - IoU_coef: 0.1539 - val_loss: -0.0908 - val_accuracy: 0.8158 - val_IoU_coef: 0.0908\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1544 - accuracy: 0.7806 - IoU_coef: 0.1544 - val_loss: -0.0877 - val_accuracy: 0.8338 - val_IoU_coef: 0.0877\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1546 - accuracy: 0.7816 - IoU_coef: 0.1546 - val_loss: -0.0833 - val_accuracy: 0.8498 - val_IoU_coef: 0.0833\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1549 - accuracy: 0.7834 - IoU_coef: 0.1549 - val_loss: -0.0796 - val_accuracy: 0.8617 - val_IoU_coef: 0.0796\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.1553 - accuracy: 0.7838 - IoU_coef: 0.1553 - val_loss: -0.0770 - val_accuracy: 0.8694 - val_IoU_coef: 0.0770\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1557 - accuracy: 0.7863 - IoU_coef: 0.1557 - val_loss: -0.0753 - val_accuracy: 0.8718 - val_IoU_coef: 0.0753\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1559 - accuracy: 0.7867 - IoU_coef: 0.1559 - val_loss: -0.0746 - val_accuracy: 0.8737 - val_IoU_coef: 0.0746\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.1563 - accuracy: 0.7862 - IoU_coef: 0.1563 - val_loss: -0.0739 - val_accuracy: 0.8748 - val_IoU_coef: 0.0739\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1566 - accuracy: 0.7879 - IoU_coef: 0.1566 - val_loss: -0.0735 - val_accuracy: 0.8751 - val_IoU_coef: 0.0735\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1569 - accuracy: 0.7901 - IoU_coef: 0.1569 - val_loss: -0.0730 - val_accuracy: 0.8752 - val_IoU_coef: 0.0730\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.1572 - accuracy: 0.7917 - IoU_coef: 0.1572 - val_loss: -0.0724 - val_accuracy: 0.8752 - val_IoU_coef: 0.0724\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1576 - accuracy: 0.7939 - IoU_coef: 0.1576 - val_loss: -0.0722 - val_accuracy: 0.8755 - val_IoU_coef: 0.0722\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1578 - accuracy: 0.7936 - IoU_coef: 0.1578 - val_loss: -0.0719 - val_accuracy: 0.8758 - val_IoU_coef: 0.0719\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1581 - accuracy: 0.7987 - IoU_coef: 0.1581 - val_loss: -0.0720 - val_accuracy: 0.8760 - val_IoU_coef: 0.0720\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1582 - accuracy: 0.7969 - IoU_coef: 0.1582 - val_loss: -0.0717 - val_accuracy: 0.8770 - val_IoU_coef: 0.0717\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1585 - accuracy: 0.8019 - IoU_coef: 0.1585 - val_loss: -0.0717 - val_accuracy: 0.8771 - val_IoU_coef: 0.0717\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1588 - accuracy: 0.8009 - IoU_coef: 0.1588 - val_loss: -0.0713 - val_accuracy: 0.8771 - val_IoU_coef: 0.0713\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1592 - accuracy: 0.8017 - IoU_coef: 0.1592 - val_loss: -0.0709 - val_accuracy: 0.8771 - val_IoU_coef: 0.0709\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1593 - accuracy: 0.8018 - IoU_coef: 0.1593 - val_loss: -0.0707 - val_accuracy: 0.8771 - val_IoU_coef: 0.0707\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1596 - accuracy: 0.8004 - IoU_coef: 0.1596 - val_loss: -0.0707 - val_accuracy: 0.8771 - val_IoU_coef: 0.0707\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1599 - accuracy: 0.8038 - IoU_coef: 0.1599 - val_loss: -0.0710 - val_accuracy: 0.8771 - val_IoU_coef: 0.0710\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1602 - accuracy: 0.8071 - IoU_coef: 0.1602 - val_loss: -0.0713 - val_accuracy: 0.8768 - val_IoU_coef: 0.0713\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1603 - accuracy: 0.8057 - IoU_coef: 0.1603 - val_loss: -0.0715 - val_accuracy: 0.8752 - val_IoU_coef: 0.0715\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1605 - accuracy: 0.8115 - IoU_coef: 0.1605 - val_loss: -0.0718 - val_accuracy: 0.8748 - val_IoU_coef: 0.0718\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1608 - accuracy: 0.8082 - IoU_coef: 0.1608 - val_loss: -0.0724 - val_accuracy: 0.8744 - val_IoU_coef: 0.0724\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1612 - accuracy: 0.8125 - IoU_coef: 0.1612 - val_loss: -0.0729 - val_accuracy: 0.8739 - val_IoU_coef: 0.0729\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1613 - accuracy: 0.8153 - IoU_coef: 0.1613 - val_loss: -0.0733 - val_accuracy: 0.8721 - val_IoU_coef: 0.0733\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1615 - accuracy: 0.8109 - IoU_coef: 0.1615 - val_loss: -0.0736 - val_accuracy: 0.8706 - val_IoU_coef: 0.0736\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1618 - accuracy: 0.8155 - IoU_coef: 0.1618 - val_loss: -0.0738 - val_accuracy: 0.8706 - val_IoU_coef: 0.0738\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1621 - accuracy: 0.8139 - IoU_coef: 0.1621 - val_loss: -0.0741 - val_accuracy: 0.8706 - val_IoU_coef: 0.0741\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1623 - accuracy: 0.8128 - IoU_coef: 0.1623 - val_loss: -0.0745 - val_accuracy: 0.8715 - val_IoU_coef: 0.0745\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1625 - accuracy: 0.8163 - IoU_coef: 0.1625 - val_loss: -0.0749 - val_accuracy: 0.8717 - val_IoU_coef: 0.0749\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1627 - accuracy: 0.8175 - IoU_coef: 0.1627 - val_loss: -0.0752 - val_accuracy: 0.8719 - val_IoU_coef: 0.0752\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1630 - accuracy: 0.8166 - IoU_coef: 0.1630 - val_loss: -0.0755 - val_accuracy: 0.8722 - val_IoU_coef: 0.0755\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1630 - accuracy: 0.8190 - IoU_coef: 0.1630 - val_loss: -0.0761 - val_accuracy: 0.8724 - val_IoU_coef: 0.0761\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1635 - accuracy: 0.8199 - IoU_coef: 0.1635 - val_loss: -0.0768 - val_accuracy: 0.8734 - val_IoU_coef: 0.0768\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1636 - accuracy: 0.8196 - IoU_coef: 0.1636 - val_loss: -0.0775 - val_accuracy: 0.8746 - val_IoU_coef: 0.0775\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1639 - accuracy: 0.8227 - IoU_coef: 0.1639 - val_loss: -0.0783 - val_accuracy: 0.8752 - val_IoU_coef: 0.0783\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1639 - accuracy: 0.8188 - IoU_coef: 0.1639 - val_loss: -0.0789 - val_accuracy: 0.8758 - val_IoU_coef: 0.0789\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1643 - accuracy: 0.8237 - IoU_coef: 0.1643 - val_loss: -0.0794 - val_accuracy: 0.8763 - val_IoU_coef: 0.0794\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1645 - accuracy: 0.8226 - IoU_coef: 0.1645 - val_loss: -0.0799 - val_accuracy: 0.8765 - val_IoU_coef: 0.0799\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1648 - accuracy: 0.8223 - IoU_coef: 0.1648 - val_loss: -0.0808 - val_accuracy: 0.8786 - val_IoU_coef: 0.0808\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1650 - accuracy: 0.8265 - IoU_coef: 0.1650 - val_loss: -0.0818 - val_accuracy: 0.8795 - val_IoU_coef: 0.0818\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1651 - accuracy: 0.8255 - IoU_coef: 0.1651 - val_loss: -0.0824 - val_accuracy: 0.8801 - val_IoU_coef: 0.0824\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1654 - accuracy: 0.8284 - IoU_coef: 0.1654 - val_loss: -0.0829 - val_accuracy: 0.8798 - val_IoU_coef: 0.0829\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1656 - accuracy: 0.8259 - IoU_coef: 0.1656 - val_loss: -0.0834 - val_accuracy: 0.8812 - val_IoU_coef: 0.0834\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1659 - accuracy: 0.8268 - IoU_coef: 0.1659 - val_loss: -0.0841 - val_accuracy: 0.8827 - val_IoU_coef: 0.0841\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1660 - accuracy: 0.8278 - IoU_coef: 0.1660 - val_loss: -0.0851 - val_accuracy: 0.8830 - val_IoU_coef: 0.0851\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1662 - accuracy: 0.8272 - IoU_coef: 0.1662 - val_loss: -0.0851 - val_accuracy: 0.8826 - val_IoU_coef: 0.0851\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1665 - accuracy: 0.8300 - IoU_coef: 0.1665 - val_loss: -0.0858 - val_accuracy: 0.8830 - val_IoU_coef: 0.0858\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1667 - accuracy: 0.8278 - IoU_coef: 0.1667 - val_loss: -0.0872 - val_accuracy: 0.8832 - val_IoU_coef: 0.0872\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.1670 - accuracy: 0.8313 - IoU_coef: 0.1670 - val_loss: -0.0885 - val_accuracy: 0.8823 - val_IoU_coef: 0.0885\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1671 - accuracy: 0.8329 - IoU_coef: 0.1671 - val_loss: -0.0895 - val_accuracy: 0.8816 - val_IoU_coef: 0.0895\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1673 - accuracy: 0.8321 - IoU_coef: 0.1673 - val_loss: -0.0904 - val_accuracy: 0.8814 - val_IoU_coef: 0.0904\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1675 - accuracy: 0.8351 - IoU_coef: 0.1675 - val_loss: -0.0917 - val_accuracy: 0.8808 - val_IoU_coef: 0.0917\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: -0.1676 - accuracy: 0.8288 - IoU_coef: 0.1676 - val_loss: -0.0918 - val_accuracy: 0.8810 - val_IoU_coef: 0.0918\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1676 - accuracy: 0.8353 - IoU_coef: 0.1676 - val_loss: -0.0929 - val_accuracy: 0.8813 - val_IoU_coef: 0.0929\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1681 - accuracy: 0.8319 - IoU_coef: 0.1681 - val_loss: -0.0929 - val_accuracy: 0.8816 - val_IoU_coef: 0.0929\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1683 - accuracy: 0.8337 - IoU_coef: 0.1683 - val_loss: -0.0918 - val_accuracy: 0.8823 - val_IoU_coef: 0.0918\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1684 - accuracy: 0.8369 - IoU_coef: 0.1684 - val_loss: -0.0916 - val_accuracy: 0.8814 - val_IoU_coef: 0.0916\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1688 - accuracy: 0.8347 - IoU_coef: 0.1688 - val_loss: -0.0927 - val_accuracy: 0.8805 - val_IoU_coef: 0.0927\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1690 - accuracy: 0.8346 - IoU_coef: 0.1690 - val_loss: -0.0933 - val_accuracy: 0.8800 - val_IoU_coef: 0.0933\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1691 - accuracy: 0.8366 - IoU_coef: 0.1691 - val_loss: -0.0940 - val_accuracy: 0.8797 - val_IoU_coef: 0.0940\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.1694 - accuracy: 0.8364 - IoU_coef: 0.1694 - val_loss: -0.0953 - val_accuracy: 0.8795 - val_IoU_coef: 0.0953\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1696 - accuracy: 0.8353 - IoU_coef: 0.1696 - val_loss: -0.0962 - val_accuracy: 0.8797 - val_IoU_coef: 0.0962\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1696 - accuracy: 0.8411 - IoU_coef: 0.1696 - val_loss: -0.0959 - val_accuracy: 0.8798 - val_IoU_coef: 0.0959\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1700 - accuracy: 0.8381 - IoU_coef: 0.1700 - val_loss: -0.0972 - val_accuracy: 0.8802 - val_IoU_coef: 0.0972\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1701 - accuracy: 0.8391 - IoU_coef: 0.1701 - val_loss: -0.0982 - val_accuracy: 0.8811 - val_IoU_coef: 0.0982\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1704 - accuracy: 0.8413 - IoU_coef: 0.1704 - val_loss: -0.0990 - val_accuracy: 0.8814 - val_IoU_coef: 0.0990\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1705 - accuracy: 0.8386 - IoU_coef: 0.1705 - val_loss: -0.0999 - val_accuracy: 0.8812 - val_IoU_coef: 0.0999\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1708 - accuracy: 0.8385 - IoU_coef: 0.1708 - val_loss: -0.0972 - val_accuracy: 0.8811 - val_IoU_coef: 0.0972\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1710 - accuracy: 0.8400 - IoU_coef: 0.1710 - val_loss: -0.0964 - val_accuracy: 0.8808 - val_IoU_coef: 0.0964\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1713 - accuracy: 0.8410 - IoU_coef: 0.1713 - val_loss: -0.1003 - val_accuracy: 0.8816 - val_IoU_coef: 0.1003\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1714 - accuracy: 0.8441 - IoU_coef: 0.1714 - val_loss: -0.1009 - val_accuracy: 0.8819 - val_IoU_coef: 0.1009\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1717 - accuracy: 0.8431 - IoU_coef: 0.1717 - val_loss: -0.0997 - val_accuracy: 0.8817 - val_IoU_coef: 0.0997\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1718 - accuracy: 0.8439 - IoU_coef: 0.1718 - val_loss: -0.1017 - val_accuracy: 0.8825 - val_IoU_coef: 0.1017\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1721 - accuracy: 0.8439 - IoU_coef: 0.1721 - val_loss: -0.1014 - val_accuracy: 0.8825 - val_IoU_coef: 0.1014\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1723 - accuracy: 0.8441 - IoU_coef: 0.1723 - val_loss: -0.0992 - val_accuracy: 0.8805 - val_IoU_coef: 0.0992\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1723 - accuracy: 0.8448 - IoU_coef: 0.1723 - val_loss: -0.1044 - val_accuracy: 0.8807 - val_IoU_coef: 0.1044\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1727 - accuracy: 0.8434 - IoU_coef: 0.1727 - val_loss: -0.1009 - val_accuracy: 0.8793 - val_IoU_coef: 0.1009\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.1729 - accuracy: 0.8452 - IoU_coef: 0.1729 - val_loss: -0.0996 - val_accuracy: 0.8784 - val_IoU_coef: 0.0996\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1731 - accuracy: 0.8461 - IoU_coef: 0.1731 - val_loss: -0.0996 - val_accuracy: 0.8771 - val_IoU_coef: 0.0996\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1732 - accuracy: 0.8462 - IoU_coef: 0.1732 - val_loss: -0.0979 - val_accuracy: 0.8774 - val_IoU_coef: 0.0979\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1735 - accuracy: 0.8475 - IoU_coef: 0.1735 - val_loss: -0.1032 - val_accuracy: 0.8792 - val_IoU_coef: 0.1032\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1736 - accuracy: 0.8451 - IoU_coef: 0.1736 - val_loss: -0.0998 - val_accuracy: 0.8804 - val_IoU_coef: 0.0998\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1738 - accuracy: 0.8495 - IoU_coef: 0.1738 - val_loss: -0.1029 - val_accuracy: 0.8805 - val_IoU_coef: 0.1029\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1739 - accuracy: 0.8456 - IoU_coef: 0.1739 - val_loss: -0.1005 - val_accuracy: 0.8805 - val_IoU_coef: 0.1005\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1741 - accuracy: 0.8513 - IoU_coef: 0.1741 - val_loss: -0.1015 - val_accuracy: 0.8808 - val_IoU_coef: 0.1015\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1744 - accuracy: 0.8485 - IoU_coef: 0.1744 - val_loss: -0.1058 - val_accuracy: 0.8808 - val_IoU_coef: 0.1058\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1746 - accuracy: 0.8458 - IoU_coef: 0.1746 - val_loss: -0.1032 - val_accuracy: 0.8809 - val_IoU_coef: 0.1032\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1748 - accuracy: 0.8510 - IoU_coef: 0.1748 - val_loss: -0.0995 - val_accuracy: 0.8809 - val_IoU_coef: 0.0995\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1750 - accuracy: 0.8487 - IoU_coef: 0.1750 - val_loss: -0.1019 - val_accuracy: 0.8799 - val_IoU_coef: 0.1019\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1752 - accuracy: 0.8498 - IoU_coef: 0.1752 - val_loss: -0.1042 - val_accuracy: 0.8775 - val_IoU_coef: 0.1042\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1754 - accuracy: 0.8531 - IoU_coef: 0.1754 - val_loss: -0.0995 - val_accuracy: 0.8789 - val_IoU_coef: 0.0995\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1756 - accuracy: 0.8507 - IoU_coef: 0.1756 - val_loss: -0.1005 - val_accuracy: 0.8782 - val_IoU_coef: 0.1005\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1759 - accuracy: 0.8502 - IoU_coef: 0.1759 - val_loss: -0.1026 - val_accuracy: 0.8768 - val_IoU_coef: 0.1026\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1760 - accuracy: 0.8515 - IoU_coef: 0.1760 - val_loss: -0.0982 - val_accuracy: 0.8801 - val_IoU_coef: 0.0982\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1763 - accuracy: 0.8519 - IoU_coef: 0.1763 - val_loss: -0.0994 - val_accuracy: 0.8799 - val_IoU_coef: 0.0994\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1765 - accuracy: 0.8523 - IoU_coef: 0.1765 - val_loss: -0.1034 - val_accuracy: 0.8745 - val_IoU_coef: 0.1034\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1766 - accuracy: 0.8532 - IoU_coef: 0.1766 - val_loss: -0.1013 - val_accuracy: 0.8772 - val_IoU_coef: 0.1013\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1769 - accuracy: 0.8534 - IoU_coef: 0.1769 - val_loss: -0.0991 - val_accuracy: 0.8797 - val_IoU_coef: 0.0991\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1771 - accuracy: 0.8542 - IoU_coef: 0.1771 - val_loss: -0.1015 - val_accuracy: 0.8799 - val_IoU_coef: 0.1015\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1773 - accuracy: 0.8554 - IoU_coef: 0.1773 - val_loss: -0.1011 - val_accuracy: 0.8809 - val_IoU_coef: 0.1011\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1775 - accuracy: 0.8541 - IoU_coef: 0.1775 - val_loss: -0.0979 - val_accuracy: 0.8801 - val_IoU_coef: 0.0979\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1777 - accuracy: 0.8547 - IoU_coef: 0.1777 - val_loss: -0.0987 - val_accuracy: 0.8799 - val_IoU_coef: 0.0987\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1779 - accuracy: 0.8538 - IoU_coef: 0.1779 - val_loss: -0.0981 - val_accuracy: 0.8796 - val_IoU_coef: 0.0981\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1781 - accuracy: 0.8547 - IoU_coef: 0.1781 - val_loss: -0.0949 - val_accuracy: 0.8782 - val_IoU_coef: 0.0949\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1783 - accuracy: 0.8566 - IoU_coef: 0.1783 - val_loss: -0.0960 - val_accuracy: 0.8788 - val_IoU_coef: 0.0960\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1785 - accuracy: 0.8571 - IoU_coef: 0.1785 - val_loss: -0.0991 - val_accuracy: 0.8791 - val_IoU_coef: 0.0991\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1787 - accuracy: 0.8564 - IoU_coef: 0.1787 - val_loss: -0.1005 - val_accuracy: 0.8792 - val_IoU_coef: 0.1005\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1789 - accuracy: 0.8562 - IoU_coef: 0.1789 - val_loss: -0.0998 - val_accuracy: 0.8792 - val_IoU_coef: 0.0998\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1791 - accuracy: 0.8575 - IoU_coef: 0.1791 - val_loss: -0.1017 - val_accuracy: 0.8804 - val_IoU_coef: 0.1017\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1793 - accuracy: 0.8565 - IoU_coef: 0.1793 - val_loss: -0.1011 - val_accuracy: 0.8804 - val_IoU_coef: 0.1011\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1795 - accuracy: 0.8589 - IoU_coef: 0.1795 - val_loss: -0.1023 - val_accuracy: 0.8811 - val_IoU_coef: 0.1023\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1796 - accuracy: 0.8584 - IoU_coef: 0.1796 - val_loss: -0.1035 - val_accuracy: 0.8810 - val_IoU_coef: 0.1035\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1798 - accuracy: 0.8599 - IoU_coef: 0.1798 - val_loss: -0.1055 - val_accuracy: 0.8778 - val_IoU_coef: 0.1055\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.1802 - accuracy: 0.8587 - IoU_coef: 0.1802 - val_loss: -0.1065 - val_accuracy: 0.8775 - val_IoU_coef: 0.1065\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 496ms/step - loss: -0.1803 - accuracy: 0.8579 - IoU_coef: 0.1803 - val_loss: -0.1066 - val_accuracy: 0.8762 - val_IoU_coef: 0.1066\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1805 - accuracy: 0.8601 - IoU_coef: 0.1805 - val_loss: -0.1067 - val_accuracy: 0.8770 - val_IoU_coef: 0.1067\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1807 - accuracy: 0.8608 - IoU_coef: 0.1807 - val_loss: -0.1062 - val_accuracy: 0.8791 - val_IoU_coef: 0.1062\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1808 - accuracy: 0.8583 - IoU_coef: 0.1808 - val_loss: -0.1048 - val_accuracy: 0.8809 - val_IoU_coef: 0.1048\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1811 - accuracy: 0.8623 - IoU_coef: 0.1811 - val_loss: -0.1062 - val_accuracy: 0.8715 - val_IoU_coef: 0.1062\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1812 - accuracy: 0.8588 - IoU_coef: 0.1812 - val_loss: -0.1047 - val_accuracy: 0.8808 - val_IoU_coef: 0.1047\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1813 - accuracy: 0.8635 - IoU_coef: 0.1813 - val_loss: -0.1051 - val_accuracy: 0.8811 - val_IoU_coef: 0.1051\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1816 - accuracy: 0.8608 - IoU_coef: 0.1816 - val_loss: -0.1066 - val_accuracy: 0.8616 - val_IoU_coef: 0.1066\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1818 - accuracy: 0.8606 - IoU_coef: 0.1818 - val_loss: -0.1067 - val_accuracy: 0.8235 - val_IoU_coef: 0.1067\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1821 - accuracy: 0.8652 - IoU_coef: 0.1821 - val_loss: -0.1068 - val_accuracy: 0.8275 - val_IoU_coef: 0.1068\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1822 - accuracy: 0.8631 - IoU_coef: 0.1822 - val_loss: -0.1061 - val_accuracy: 0.8777 - val_IoU_coef: 0.1061\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1825 - accuracy: 0.8614 - IoU_coef: 0.1825 - val_loss: -0.1055 - val_accuracy: 0.8808 - val_IoU_coef: 0.1055\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1826 - accuracy: 0.8627 - IoU_coef: 0.1826 - val_loss: -0.1080 - val_accuracy: 0.8501 - val_IoU_coef: 0.1080\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1828 - accuracy: 0.8629 - IoU_coef: 0.1828 - val_loss: -0.1084 - val_accuracy: 0.7905 - val_IoU_coef: 0.1084\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1830 - accuracy: 0.8636 - IoU_coef: 0.1830 - val_loss: -0.1077 - val_accuracy: 0.7988 - val_IoU_coef: 0.1077\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1832 - accuracy: 0.8662 - IoU_coef: 0.1832 - val_loss: -0.1077 - val_accuracy: 0.8164 - val_IoU_coef: 0.1077\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1835 - accuracy: 0.8642 - IoU_coef: 0.1835 - val_loss: -0.1074 - val_accuracy: 0.8623 - val_IoU_coef: 0.1074\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1836 - accuracy: 0.8626 - IoU_coef: 0.1836 - val_loss: -0.1065 - val_accuracy: 0.8775 - val_IoU_coef: 0.1065\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1838 - accuracy: 0.8652 - IoU_coef: 0.1838 - val_loss: -0.1072 - val_accuracy: 0.8767 - val_IoU_coef: 0.1072\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1841 - accuracy: 0.8644 - IoU_coef: 0.1841 - val_loss: -0.1081 - val_accuracy: 0.8711 - val_IoU_coef: 0.1081\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1842 - accuracy: 0.8651 - IoU_coef: 0.1842 - val_loss: -0.1083 - val_accuracy: 0.8673 - val_IoU_coef: 0.1083\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1844 - accuracy: 0.8669 - IoU_coef: 0.1844 - val_loss: -0.1078 - val_accuracy: 0.8749 - val_IoU_coef: 0.1078\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1846 - accuracy: 0.8671 - IoU_coef: 0.1846 - val_loss: -0.1074 - val_accuracy: 0.8718 - val_IoU_coef: 0.1074\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1848 - accuracy: 0.8660 - IoU_coef: 0.1848 - val_loss: -0.1067 - val_accuracy: 0.8743 - val_IoU_coef: 0.1067\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1850 - accuracy: 0.8671 - IoU_coef: 0.1850 - val_loss: -0.1056 - val_accuracy: 0.8781 - val_IoU_coef: 0.1056\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 481ms/step - loss: -0.1852 - accuracy: 0.8652 - IoU_coef: 0.1852 - val_loss: -0.1041 - val_accuracy: 0.8802 - val_IoU_coef: 0.1041\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1854 - accuracy: 0.8666 - IoU_coef: 0.1854 - val_loss: -0.1053 - val_accuracy: 0.8747 - val_IoU_coef: 0.1053\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1856 - accuracy: 0.8695 - IoU_coef: 0.1856 - val_loss: -0.1061 - val_accuracy: 0.8714 - val_IoU_coef: 0.1061\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1858 - accuracy: 0.8673 - IoU_coef: 0.1858 - val_loss: -0.1042 - val_accuracy: 0.8745 - val_IoU_coef: 0.1042\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1860 - accuracy: 0.8669 - IoU_coef: 0.1860 - val_loss: -0.1054 - val_accuracy: 0.8701 - val_IoU_coef: 0.1054\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1862 - accuracy: 0.8681 - IoU_coef: 0.1862 - val_loss: -0.1057 - val_accuracy: 0.8673 - val_IoU_coef: 0.1057\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1864 - accuracy: 0.8683 - IoU_coef: 0.1864 - val_loss: -0.1048 - val_accuracy: 0.8678 - val_IoU_coef: 0.1048\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1865 - accuracy: 0.8708 - IoU_coef: 0.1865 - val_loss: -0.1059 - val_accuracy: 0.8639 - val_IoU_coef: 0.1059\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1868 - accuracy: 0.8697 - IoU_coef: 0.1868 - val_loss: -0.1074 - val_accuracy: 0.8408 - val_IoU_coef: 0.1074\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1870 - accuracy: 0.8674 - IoU_coef: 0.1870 - val_loss: -0.1051 - val_accuracy: 0.8671 - val_IoU_coef: 0.1051\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1871 - accuracy: 0.8697 - IoU_coef: 0.1871 - val_loss: -0.1042 - val_accuracy: 0.8696 - val_IoU_coef: 0.1042\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1873 - accuracy: 0.8689 - IoU_coef: 0.1873 - val_loss: -0.1059 - val_accuracy: 0.8634 - val_IoU_coef: 0.1059\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1876 - accuracy: 0.8704 - IoU_coef: 0.1876 - val_loss: -0.1050 - val_accuracy: 0.8677 - val_IoU_coef: 0.1050\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.1878 - accuracy: 0.8723 - IoU_coef: 0.1878 - val_loss: -0.1036 - val_accuracy: 0.8744 - val_IoU_coef: 0.1036\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1881 - accuracy: 0.8700 - IoU_coef: 0.1881 - val_loss: -0.1052 - val_accuracy: 0.8742 - val_IoU_coef: 0.1052\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1882 - accuracy: 0.8691 - IoU_coef: 0.1882 - val_loss: -0.1065 - val_accuracy: 0.8697 - val_IoU_coef: 0.1065\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1883 - accuracy: 0.8725 - IoU_coef: 0.1883 - val_loss: -0.1060 - val_accuracy: 0.8712 - val_IoU_coef: 0.1060\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1884 - accuracy: 0.8692 - IoU_coef: 0.1884 - val_loss: -0.1043 - val_accuracy: 0.8725 - val_IoU_coef: 0.1043\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1888 - accuracy: 0.8727 - IoU_coef: 0.1888 - val_loss: -0.1044 - val_accuracy: 0.8740 - val_IoU_coef: 0.1044\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1890 - accuracy: 0.8726 - IoU_coef: 0.1890 - val_loss: -0.1052 - val_accuracy: 0.8733 - val_IoU_coef: 0.1052\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1892 - accuracy: 0.8713 - IoU_coef: 0.1892 - val_loss: -0.1052 - val_accuracy: 0.8713 - val_IoU_coef: 0.1052\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1892 - accuracy: 0.8740 - IoU_coef: 0.1892 - val_loss: -0.1068 - val_accuracy: 0.8681 - val_IoU_coef: 0.1068\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1896 - accuracy: 0.8722 - IoU_coef: 0.1896 - val_loss: -0.1064 - val_accuracy: 0.8689 - val_IoU_coef: 0.1064\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1897 - accuracy: 0.8711 - IoU_coef: 0.1897 - val_loss: -0.1029 - val_accuracy: 0.8720 - val_IoU_coef: 0.1029\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1899 - accuracy: 0.8738 - IoU_coef: 0.1899 - val_loss: -0.1036 - val_accuracy: 0.8713 - val_IoU_coef: 0.1036\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1901 - accuracy: 0.8729 - IoU_coef: 0.1901 - val_loss: -0.1051 - val_accuracy: 0.8690 - val_IoU_coef: 0.1051\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1902 - accuracy: 0.8748 - IoU_coef: 0.1902 - val_loss: -0.1056 - val_accuracy: 0.8690 - val_IoU_coef: 0.1056\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1905 - accuracy: 0.8741 - IoU_coef: 0.1905 - val_loss: -0.1073 - val_accuracy: 0.8678 - val_IoU_coef: 0.1073\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1907 - accuracy: 0.8718 - IoU_coef: 0.1907 - val_loss: -0.1086 - val_accuracy: 0.8640 - val_IoU_coef: 0.1086\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.1909 - accuracy: 0.8740 - IoU_coef: 0.1909 - val_loss: -0.1085 - val_accuracy: 0.8634 - val_IoU_coef: 0.1085\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.1911 - accuracy: 0.8750 - IoU_coef: 0.1911 - val_loss: -0.1086 - val_accuracy: 0.8657 - val_IoU_coef: 0.1086\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.1913 - accuracy: 0.8740 - IoU_coef: 0.1913 - val_loss: -0.1081 - val_accuracy: 0.8681 - val_IoU_coef: 0.1081\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1915 - accuracy: 0.8756 - IoU_coef: 0.1915 - val_loss: -0.1092 - val_accuracy: 0.8689 - val_IoU_coef: 0.1092\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1917 - accuracy: 0.8748 - IoU_coef: 0.1917 - val_loss: -0.1101 - val_accuracy: 0.8685 - val_IoU_coef: 0.1101\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1920 - accuracy: 0.8751 - IoU_coef: 0.1920 - val_loss: -0.1116 - val_accuracy: 0.8648 - val_IoU_coef: 0.1116\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1921 - accuracy: 0.8759 - IoU_coef: 0.1921 - val_loss: -0.1125 - val_accuracy: 0.8622 - val_IoU_coef: 0.1125\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1923 - accuracy: 0.8758 - IoU_coef: 0.1923 - val_loss: -0.1099 - val_accuracy: 0.8651 - val_IoU_coef: 0.1099\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.1925 - accuracy: 0.8765 - IoU_coef: 0.1925 - val_loss: -0.1094 - val_accuracy: 0.8680 - val_IoU_coef: 0.1094\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1926 - accuracy: 0.8758 - IoU_coef: 0.1926 - val_loss: -0.1109 - val_accuracy: 0.8684 - val_IoU_coef: 0.1109\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1928 - accuracy: 0.8761 - IoU_coef: 0.1928 - val_loss: -0.1113 - val_accuracy: 0.8700 - val_IoU_coef: 0.1113\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1931 - accuracy: 0.8767 - IoU_coef: 0.1931 - val_loss: -0.1109 - val_accuracy: 0.8701 - val_IoU_coef: 0.1109\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1933 - accuracy: 0.8776 - IoU_coef: 0.1933 - val_loss: -0.1116 - val_accuracy: 0.8720 - val_IoU_coef: 0.1116\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1934 - accuracy: 0.8772 - IoU_coef: 0.1934 - val_loss: -0.1113 - val_accuracy: 0.8731 - val_IoU_coef: 0.1113\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.1937 - accuracy: 0.8772 - IoU_coef: 0.1937 - val_loss: -0.1104 - val_accuracy: 0.8750 - val_IoU_coef: 0.1104\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1938 - accuracy: 0.8766 - IoU_coef: 0.1938 - val_loss: -0.1107 - val_accuracy: 0.8760 - val_IoU_coef: 0.1107\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1940 - accuracy: 0.8773 - IoU_coef: 0.1940 - val_loss: -0.1097 - val_accuracy: 0.8741 - val_IoU_coef: 0.1097\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1942 - accuracy: 0.8789 - IoU_coef: 0.1942 - val_loss: -0.1106 - val_accuracy: 0.8725 - val_IoU_coef: 0.1106\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1944 - accuracy: 0.8785 - IoU_coef: 0.1944 - val_loss: -0.1123 - val_accuracy: 0.8709 - val_IoU_coef: 0.1123\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.1947 - accuracy: 0.8784 - IoU_coef: 0.1947 - val_loss: -0.1116 - val_accuracy: 0.8720 - val_IoU_coef: 0.1116\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1948 - accuracy: 0.8782 - IoU_coef: 0.1948 - val_loss: -0.1101 - val_accuracy: 0.8737 - val_IoU_coef: 0.1101\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1950 - accuracy: 0.8779 - IoU_coef: 0.1950 - val_loss: -0.1092 - val_accuracy: 0.8738 - val_IoU_coef: 0.1092\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1952 - accuracy: 0.8783 - IoU_coef: 0.1952 - val_loss: -0.1094 - val_accuracy: 0.8720 - val_IoU_coef: 0.1094\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1953 - accuracy: 0.8800 - IoU_coef: 0.1953 - val_loss: -0.1101 - val_accuracy: 0.8719 - val_IoU_coef: 0.1101\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1956 - accuracy: 0.8803 - IoU_coef: 0.1956 - val_loss: -0.1104 - val_accuracy: 0.8727 - val_IoU_coef: 0.1104\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.1958 - accuracy: 0.8787 - IoU_coef: 0.1958 - val_loss: -0.1101 - val_accuracy: 0.8736 - val_IoU_coef: 0.1101\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1960 - accuracy: 0.8788 - IoU_coef: 0.1960 - val_loss: -0.1089 - val_accuracy: 0.8748 - val_IoU_coef: 0.1089\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1962 - accuracy: 0.8802 - IoU_coef: 0.1962 - val_loss: -0.1095 - val_accuracy: 0.8760 - val_IoU_coef: 0.1095\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.1964 - accuracy: 0.8803 - IoU_coef: 0.1964 - val_loss: -0.1110 - val_accuracy: 0.8763 - val_IoU_coef: 0.1110\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1965 - accuracy: 0.8801 - IoU_coef: 0.1965 - val_loss: -0.1107 - val_accuracy: 0.8768 - val_IoU_coef: 0.1107\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1968 - accuracy: 0.8798 - IoU_coef: 0.1968 - val_loss: -0.1130 - val_accuracy: 0.8736 - val_IoU_coef: 0.1130\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1970 - accuracy: 0.8810 - IoU_coef: 0.1970 - val_loss: -0.1147 - val_accuracy: 0.8735 - val_IoU_coef: 0.1147\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1971 - accuracy: 0.8813 - IoU_coef: 0.1971 - val_loss: -0.1150 - val_accuracy: 0.8742 - val_IoU_coef: 0.1150\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1973 - accuracy: 0.8805 - IoU_coef: 0.1973 - val_loss: -0.1120 - val_accuracy: 0.8744 - val_IoU_coef: 0.1120\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1975 - accuracy: 0.8818 - IoU_coef: 0.1975 - val_loss: -0.1115 - val_accuracy: 0.8747 - val_IoU_coef: 0.1115\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 486ms/step - loss: -0.1977 - accuracy: 0.8820 - IoU_coef: 0.1977 - val_loss: -0.1132 - val_accuracy: 0.8752 - val_IoU_coef: 0.1132\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1979 - accuracy: 0.8814 - IoU_coef: 0.1979 - val_loss: -0.1129 - val_accuracy: 0.8754 - val_IoU_coef: 0.1129\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.1982 - accuracy: 0.8807 - IoU_coef: 0.1982 - val_loss: -0.1112 - val_accuracy: 0.8734 - val_IoU_coef: 0.1112\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.1983 - accuracy: 0.8828 - IoU_coef: 0.1983 - val_loss: -0.1128 - val_accuracy: 0.8721 - val_IoU_coef: 0.1128\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: -0.1985 - accuracy: 0.8819 - IoU_coef: 0.1985 - val_loss: -0.1145 - val_accuracy: 0.8716 - val_IoU_coef: 0.1145\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.1987 - accuracy: 0.8826 - IoU_coef: 0.1987 - val_loss: -0.1143 - val_accuracy: 0.8733 - val_IoU_coef: 0.1143\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.1989 - accuracy: 0.8818 - IoU_coef: 0.1989 - val_loss: -0.1144 - val_accuracy: 0.8742 - val_IoU_coef: 0.1144\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1991 - accuracy: 0.8828 - IoU_coef: 0.1991 - val_loss: -0.1148 - val_accuracy: 0.8746 - val_IoU_coef: 0.1148\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1993 - accuracy: 0.8844 - IoU_coef: 0.1993 - val_loss: -0.1146 - val_accuracy: 0.8773 - val_IoU_coef: 0.1146\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1995 - accuracy: 0.8829 - IoU_coef: 0.1995 - val_loss: -0.1124 - val_accuracy: 0.8800 - val_IoU_coef: 0.1124\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.1997 - accuracy: 0.8817 - IoU_coef: 0.1997 - val_loss: -0.1120 - val_accuracy: 0.8799 - val_IoU_coef: 0.1120\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.1999 - accuracy: 0.8844 - IoU_coef: 0.1999 - val_loss: -0.1126 - val_accuracy: 0.8811 - val_IoU_coef: 0.1126\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2001 - accuracy: 0.8833 - IoU_coef: 0.2001 - val_loss: -0.1135 - val_accuracy: 0.8820 - val_IoU_coef: 0.1135\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2002 - accuracy: 0.8824 - IoU_coef: 0.2002 - val_loss: -0.1147 - val_accuracy: 0.8816 - val_IoU_coef: 0.1147\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2005 - accuracy: 0.8849 - IoU_coef: 0.2005 - val_loss: -0.1157 - val_accuracy: 0.8813 - val_IoU_coef: 0.1157\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2006 - accuracy: 0.8846 - IoU_coef: 0.2006 - val_loss: -0.1153 - val_accuracy: 0.8824 - val_IoU_coef: 0.1153\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2008 - accuracy: 0.8842 - IoU_coef: 0.2008 - val_loss: -0.1151 - val_accuracy: 0.8830 - val_IoU_coef: 0.1151\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2011 - accuracy: 0.8838 - IoU_coef: 0.2011 - val_loss: -0.1156 - val_accuracy: 0.8831 - val_IoU_coef: 0.1156\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2012 - accuracy: 0.8847 - IoU_coef: 0.2012 - val_loss: -0.1149 - val_accuracy: 0.8836 - val_IoU_coef: 0.1149\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2014 - accuracy: 0.8848 - IoU_coef: 0.2014 - val_loss: -0.1173 - val_accuracy: 0.8841 - val_IoU_coef: 0.1173\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2017 - accuracy: 0.8845 - IoU_coef: 0.2017 - val_loss: -0.1173 - val_accuracy: 0.8841 - val_IoU_coef: 0.1173\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2018 - accuracy: 0.8858 - IoU_coef: 0.2018 - val_loss: -0.1174 - val_accuracy: 0.8839 - val_IoU_coef: 0.1174\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2020 - accuracy: 0.8859 - IoU_coef: 0.2020 - val_loss: -0.1179 - val_accuracy: 0.8833 - val_IoU_coef: 0.1179\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2022 - accuracy: 0.8839 - IoU_coef: 0.2022 - val_loss: -0.1176 - val_accuracy: 0.8826 - val_IoU_coef: 0.1176\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2024 - accuracy: 0.8863 - IoU_coef: 0.2024 - val_loss: -0.1193 - val_accuracy: 0.8827 - val_IoU_coef: 0.1193\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2026 - accuracy: 0.8858 - IoU_coef: 0.2026 - val_loss: -0.1221 - val_accuracy: 0.8835 - val_IoU_coef: 0.1221\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2028 - accuracy: 0.8858 - IoU_coef: 0.2028 - val_loss: -0.1246 - val_accuracy: 0.8840 - val_IoU_coef: 0.1246\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2030 - accuracy: 0.8860 - IoU_coef: 0.2030 - val_loss: -0.1239 - val_accuracy: 0.8841 - val_IoU_coef: 0.1239\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2032 - accuracy: 0.8860 - IoU_coef: 0.2032 - val_loss: -0.1212 - val_accuracy: 0.8837 - val_IoU_coef: 0.1212\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2034 - accuracy: 0.8863 - IoU_coef: 0.2034 - val_loss: -0.1220 - val_accuracy: 0.8832 - val_IoU_coef: 0.1220\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2036 - accuracy: 0.8874 - IoU_coef: 0.2036 - val_loss: -0.1252 - val_accuracy: 0.8826 - val_IoU_coef: 0.1252\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2038 - accuracy: 0.8867 - IoU_coef: 0.2038 - val_loss: -0.1236 - val_accuracy: 0.8829 - val_IoU_coef: 0.1236\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2040 - accuracy: 0.8866 - IoU_coef: 0.2040 - val_loss: -0.1202 - val_accuracy: 0.8833 - val_IoU_coef: 0.1202\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2042 - accuracy: 0.8871 - IoU_coef: 0.2042 - val_loss: -0.1212 - val_accuracy: 0.8835 - val_IoU_coef: 0.1212\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2044 - accuracy: 0.8871 - IoU_coef: 0.2044 - val_loss: -0.1240 - val_accuracy: 0.8837 - val_IoU_coef: 0.1240\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2046 - accuracy: 0.8877 - IoU_coef: 0.2046 - val_loss: -0.1263 - val_accuracy: 0.8838 - val_IoU_coef: 0.1263\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2047 - accuracy: 0.8880 - IoU_coef: 0.2047 - val_loss: -0.1260 - val_accuracy: 0.8846 - val_IoU_coef: 0.1260\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2049 - accuracy: 0.8873 - IoU_coef: 0.2049 - val_loss: -0.1230 - val_accuracy: 0.8851 - val_IoU_coef: 0.1230\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2052 - accuracy: 0.8872 - IoU_coef: 0.2052 - val_loss: -0.1218 - val_accuracy: 0.8851 - val_IoU_coef: 0.1218\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2053 - accuracy: 0.8884 - IoU_coef: 0.2053 - val_loss: -0.1239 - val_accuracy: 0.8850 - val_IoU_coef: 0.1239\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2055 - accuracy: 0.8878 - IoU_coef: 0.2055 - val_loss: -0.1238 - val_accuracy: 0.8850 - val_IoU_coef: 0.1238\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2058 - accuracy: 0.8890 - IoU_coef: 0.2058 - val_loss: -0.1215 - val_accuracy: 0.8850 - val_IoU_coef: 0.1215\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2059 - accuracy: 0.8886 - IoU_coef: 0.2059 - val_loss: -0.1207 - val_accuracy: 0.8851 - val_IoU_coef: 0.1207\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2061 - accuracy: 0.8868 - IoU_coef: 0.2061 - val_loss: -0.1243 - val_accuracy: 0.8850 - val_IoU_coef: 0.1243\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2064 - accuracy: 0.8894 - IoU_coef: 0.2064 - val_loss: -0.1249 - val_accuracy: 0.8852 - val_IoU_coef: 0.1249\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2066 - accuracy: 0.8900 - IoU_coef: 0.2066 - val_loss: -0.1234 - val_accuracy: 0.8855 - val_IoU_coef: 0.1234\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2067 - accuracy: 0.8881 - IoU_coef: 0.2067 - val_loss: -0.1231 - val_accuracy: 0.8854 - val_IoU_coef: 0.1231\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2068 - accuracy: 0.8897 - IoU_coef: 0.2068 - val_loss: -0.1262 - val_accuracy: 0.8857 - val_IoU_coef: 0.1262\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2071 - accuracy: 0.8883 - IoU_coef: 0.2071 - val_loss: -0.1271 - val_accuracy: 0.8857 - val_IoU_coef: 0.1271\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2073 - accuracy: 0.8894 - IoU_coef: 0.2073 - val_loss: -0.1240 - val_accuracy: 0.8856 - val_IoU_coef: 0.1240\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2075 - accuracy: 0.8900 - IoU_coef: 0.2075 - val_loss: -0.1243 - val_accuracy: 0.8853 - val_IoU_coef: 0.1243\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2077 - accuracy: 0.8901 - IoU_coef: 0.2077 - val_loss: -0.1266 - val_accuracy: 0.8850 - val_IoU_coef: 0.1266\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2080 - accuracy: 0.8894 - IoU_coef: 0.2080 - val_loss: -0.1263 - val_accuracy: 0.8848 - val_IoU_coef: 0.1263\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2081 - accuracy: 0.8899 - IoU_coef: 0.2081 - val_loss: -0.1243 - val_accuracy: 0.8850 - val_IoU_coef: 0.1243\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2083 - accuracy: 0.8900 - IoU_coef: 0.2083 - val_loss: -0.1251 - val_accuracy: 0.8853 - val_IoU_coef: 0.1251\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2085 - accuracy: 0.8899 - IoU_coef: 0.2085 - val_loss: -0.1271 - val_accuracy: 0.8855 - val_IoU_coef: 0.1271\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2087 - accuracy: 0.8918 - IoU_coef: 0.2087 - val_loss: -0.1290 - val_accuracy: 0.8858 - val_IoU_coef: 0.1290\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2089 - accuracy: 0.8896 - IoU_coef: 0.2089 - val_loss: -0.1250 - val_accuracy: 0.8856 - val_IoU_coef: 0.1250\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2091 - accuracy: 0.8898 - IoU_coef: 0.2091 - val_loss: -0.1232 - val_accuracy: 0.8854 - val_IoU_coef: 0.1232\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2093 - accuracy: 0.8916 - IoU_coef: 0.2093 - val_loss: -0.1272 - val_accuracy: 0.8859 - val_IoU_coef: 0.1272\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2096 - accuracy: 0.8914 - IoU_coef: 0.2096 - val_loss: -0.1311 - val_accuracy: 0.8864 - val_IoU_coef: 0.1311\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2098 - accuracy: 0.8914 - IoU_coef: 0.2098 - val_loss: -0.1331 - val_accuracy: 0.8865 - val_IoU_coef: 0.1331\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2099 - accuracy: 0.8909 - IoU_coef: 0.2099 - val_loss: -0.1335 - val_accuracy: 0.8863 - val_IoU_coef: 0.1335\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2101 - accuracy: 0.8904 - IoU_coef: 0.2101 - val_loss: -0.1340 - val_accuracy: 0.8859 - val_IoU_coef: 0.1340\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2103 - accuracy: 0.8919 - IoU_coef: 0.2103 - val_loss: -0.1344 - val_accuracy: 0.8860 - val_IoU_coef: 0.1344\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2105 - accuracy: 0.8923 - IoU_coef: 0.2105 - val_loss: -0.1357 - val_accuracy: 0.8861 - val_IoU_coef: 0.1357\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2106 - accuracy: 0.8911 - IoU_coef: 0.2106 - val_loss: -0.1360 - val_accuracy: 0.8861 - val_IoU_coef: 0.1360\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2109 - accuracy: 0.8924 - IoU_coef: 0.2109 - val_loss: -0.1354 - val_accuracy: 0.8863 - val_IoU_coef: 0.1354\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2111 - accuracy: 0.8923 - IoU_coef: 0.2111 - val_loss: -0.1361 - val_accuracy: 0.8861 - val_IoU_coef: 0.1361\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2113 - accuracy: 0.8920 - IoU_coef: 0.2113 - val_loss: -0.1361 - val_accuracy: 0.8861 - val_IoU_coef: 0.1361\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2115 - accuracy: 0.8921 - IoU_coef: 0.2115 - val_loss: -0.1360 - val_accuracy: 0.8862 - val_IoU_coef: 0.1360\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2116 - accuracy: 0.8927 - IoU_coef: 0.2116 - val_loss: -0.1360 - val_accuracy: 0.8865 - val_IoU_coef: 0.1360\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2119 - accuracy: 0.8921 - IoU_coef: 0.2119 - val_loss: -0.1346 - val_accuracy: 0.8872 - val_IoU_coef: 0.1346\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2121 - accuracy: 0.8925 - IoU_coef: 0.2121 - val_loss: -0.1356 - val_accuracy: 0.8873 - val_IoU_coef: 0.1356\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2123 - accuracy: 0.8935 - IoU_coef: 0.2123 - val_loss: -0.1380 - val_accuracy: 0.8872 - val_IoU_coef: 0.1380\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2125 - accuracy: 0.8921 - IoU_coef: 0.2125 - val_loss: -0.1375 - val_accuracy: 0.8869 - val_IoU_coef: 0.1375\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2126 - accuracy: 0.8932 - IoU_coef: 0.2126 - val_loss: -0.1372 - val_accuracy: 0.8867 - val_IoU_coef: 0.1372\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2129 - accuracy: 0.8933 - IoU_coef: 0.2129 - val_loss: -0.1390 - val_accuracy: 0.8866 - val_IoU_coef: 0.1390\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2131 - accuracy: 0.8924 - IoU_coef: 0.2131 - val_loss: -0.1378 - val_accuracy: 0.8870 - val_IoU_coef: 0.1378\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2133 - accuracy: 0.8939 - IoU_coef: 0.2133 - val_loss: -0.1350 - val_accuracy: 0.8878 - val_IoU_coef: 0.1350\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2135 - accuracy: 0.8943 - IoU_coef: 0.2135 - val_loss: -0.1333 - val_accuracy: 0.8882 - val_IoU_coef: 0.1333\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2137 - accuracy: 0.8919 - IoU_coef: 0.2137 - val_loss: -0.1339 - val_accuracy: 0.8881 - val_IoU_coef: 0.1339\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2139 - accuracy: 0.8948 - IoU_coef: 0.2139 - val_loss: -0.1365 - val_accuracy: 0.8878 - val_IoU_coef: 0.1365\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2141 - accuracy: 0.8944 - IoU_coef: 0.2141 - val_loss: -0.1382 - val_accuracy: 0.8877 - val_IoU_coef: 0.1382\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2143 - accuracy: 0.8929 - IoU_coef: 0.2143 - val_loss: -0.1375 - val_accuracy: 0.8878 - val_IoU_coef: 0.1375\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2145 - accuracy: 0.8950 - IoU_coef: 0.2145 - val_loss: -0.1383 - val_accuracy: 0.8879 - val_IoU_coef: 0.1383\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2146 - accuracy: 0.8940 - IoU_coef: 0.2146 - val_loss: -0.1402 - val_accuracy: 0.8877 - val_IoU_coef: 0.1402\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2149 - accuracy: 0.8936 - IoU_coef: 0.2149 - val_loss: -0.1403 - val_accuracy: 0.8877 - val_IoU_coef: 0.1403\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2150 - accuracy: 0.8948 - IoU_coef: 0.2150 - val_loss: -0.1411 - val_accuracy: 0.8877 - val_IoU_coef: 0.1411\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2153 - accuracy: 0.8938 - IoU_coef: 0.2153 - val_loss: -0.1415 - val_accuracy: 0.8877 - val_IoU_coef: 0.1415\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2155 - accuracy: 0.8957 - IoU_coef: 0.2155 - val_loss: -0.1438 - val_accuracy: 0.8874 - val_IoU_coef: 0.1438\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2156 - accuracy: 0.8952 - IoU_coef: 0.2156 - val_loss: -0.1455 - val_accuracy: 0.8875 - val_IoU_coef: 0.1455\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2158 - accuracy: 0.8929 - IoU_coef: 0.2158 - val_loss: -0.1444 - val_accuracy: 0.8881 - val_IoU_coef: 0.1444\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2161 - accuracy: 0.8952 - IoU_coef: 0.2161 - val_loss: -0.1433 - val_accuracy: 0.8882 - val_IoU_coef: 0.1433\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2163 - accuracy: 0.8968 - IoU_coef: 0.2163 - val_loss: -0.1449 - val_accuracy: 0.8875 - val_IoU_coef: 0.1449\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2165 - accuracy: 0.8940 - IoU_coef: 0.2165 - val_loss: -0.1439 - val_accuracy: 0.8872 - val_IoU_coef: 0.1439\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2167 - accuracy: 0.8951 - IoU_coef: 0.2167 - val_loss: -0.1427 - val_accuracy: 0.8876 - val_IoU_coef: 0.1427\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2169 - accuracy: 0.8964 - IoU_coef: 0.2169 - val_loss: -0.1428 - val_accuracy: 0.8879 - val_IoU_coef: 0.1428\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2171 - accuracy: 0.8955 - IoU_coef: 0.2171 - val_loss: -0.1440 - val_accuracy: 0.8880 - val_IoU_coef: 0.1440\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2173 - accuracy: 0.8948 - IoU_coef: 0.2173 - val_loss: -0.1448 - val_accuracy: 0.8877 - val_IoU_coef: 0.1448\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2175 - accuracy: 0.8967 - IoU_coef: 0.2175 - val_loss: -0.1458 - val_accuracy: 0.8880 - val_IoU_coef: 0.1458\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2177 - accuracy: 0.8950 - IoU_coef: 0.2177 - val_loss: -0.1455 - val_accuracy: 0.8883 - val_IoU_coef: 0.1455\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2179 - accuracy: 0.8952 - IoU_coef: 0.2179 - val_loss: -0.1451 - val_accuracy: 0.8886 - val_IoU_coef: 0.1451\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2181 - accuracy: 0.8974 - IoU_coef: 0.2181 - val_loss: -0.1469 - val_accuracy: 0.8887 - val_IoU_coef: 0.1469\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2183 - accuracy: 0.8962 - IoU_coef: 0.2183 - val_loss: -0.1480 - val_accuracy: 0.8886 - val_IoU_coef: 0.1480\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2185 - accuracy: 0.8953 - IoU_coef: 0.2185 - val_loss: -0.1483 - val_accuracy: 0.8882 - val_IoU_coef: 0.1483\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2187 - accuracy: 0.8970 - IoU_coef: 0.2187 - val_loss: -0.1488 - val_accuracy: 0.8878 - val_IoU_coef: 0.1488\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2189 - accuracy: 0.8971 - IoU_coef: 0.2189 - val_loss: -0.1491 - val_accuracy: 0.8874 - val_IoU_coef: 0.1491\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2191 - accuracy: 0.8959 - IoU_coef: 0.2191 - val_loss: -0.1489 - val_accuracy: 0.8874 - val_IoU_coef: 0.1489\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2193 - accuracy: 0.8970 - IoU_coef: 0.2193 - val_loss: -0.1490 - val_accuracy: 0.8878 - val_IoU_coef: 0.1490\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2195 - accuracy: 0.8972 - IoU_coef: 0.2195 - val_loss: -0.1495 - val_accuracy: 0.8887 - val_IoU_coef: 0.1495\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2197 - accuracy: 0.8958 - IoU_coef: 0.2197 - val_loss: -0.1489 - val_accuracy: 0.8890 - val_IoU_coef: 0.1489\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.2199 - accuracy: 0.8978 - IoU_coef: 0.2199 - val_loss: -0.1504 - val_accuracy: 0.8885 - val_IoU_coef: 0.1504\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2202 - accuracy: 0.8980 - IoU_coef: 0.2202 - val_loss: -0.1530 - val_accuracy: 0.8876 - val_IoU_coef: 0.1530\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2203 - accuracy: 0.8965 - IoU_coef: 0.2203 - val_loss: -0.1544 - val_accuracy: 0.8872 - val_IoU_coef: 0.1544\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2206 - accuracy: 0.8970 - IoU_coef: 0.2206 - val_loss: -0.1544 - val_accuracy: 0.8868 - val_IoU_coef: 0.1544\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2207 - accuracy: 0.8981 - IoU_coef: 0.2207 - val_loss: -0.1540 - val_accuracy: 0.8874 - val_IoU_coef: 0.1540\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2209 - accuracy: 0.8971 - IoU_coef: 0.2209 - val_loss: -0.1515 - val_accuracy: 0.8892 - val_IoU_coef: 0.1515\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2211 - accuracy: 0.8974 - IoU_coef: 0.2211 - val_loss: -0.1514 - val_accuracy: 0.8889 - val_IoU_coef: 0.1514\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2213 - accuracy: 0.8981 - IoU_coef: 0.2213 - val_loss: -0.1543 - val_accuracy: 0.8870 - val_IoU_coef: 0.1543\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2216 - accuracy: 0.8972 - IoU_coef: 0.2216 - val_loss: -0.1569 - val_accuracy: 0.8847 - val_IoU_coef: 0.1569\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2218 - accuracy: 0.8979 - IoU_coef: 0.2218 - val_loss: -0.1576 - val_accuracy: 0.8847 - val_IoU_coef: 0.1576\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2220 - accuracy: 0.8990 - IoU_coef: 0.2220 - val_loss: -0.1562 - val_accuracy: 0.8880 - val_IoU_coef: 0.1562\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2222 - accuracy: 0.8981 - IoU_coef: 0.2222 - val_loss: -0.1545 - val_accuracy: 0.8897 - val_IoU_coef: 0.1545\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2224 - accuracy: 0.8977 - IoU_coef: 0.2224 - val_loss: -0.1545 - val_accuracy: 0.8896 - val_IoU_coef: 0.1545\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2226 - accuracy: 0.8985 - IoU_coef: 0.2226 - val_loss: -0.1557 - val_accuracy: 0.8887 - val_IoU_coef: 0.1557\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2228 - accuracy: 0.8990 - IoU_coef: 0.2228 - val_loss: -0.1570 - val_accuracy: 0.8880 - val_IoU_coef: 0.1570\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2230 - accuracy: 0.8980 - IoU_coef: 0.2230 - val_loss: -0.1558 - val_accuracy: 0.8888 - val_IoU_coef: 0.1558\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2232 - accuracy: 0.8990 - IoU_coef: 0.2232 - val_loss: -0.1551 - val_accuracy: 0.8892 - val_IoU_coef: 0.1551\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2234 - accuracy: 0.8995 - IoU_coef: 0.2234 - val_loss: -0.1557 - val_accuracy: 0.8903 - val_IoU_coef: 0.1557\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2237 - accuracy: 0.8980 - IoU_coef: 0.2237 - val_loss: -0.1567 - val_accuracy: 0.8903 - val_IoU_coef: 0.1567\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2237 - accuracy: 0.8984 - IoU_coef: 0.2237 - val_loss: -0.1564 - val_accuracy: 0.8904 - val_IoU_coef: 0.1564\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2241 - accuracy: 0.8995 - IoU_coef: 0.2241 - val_loss: -0.1564 - val_accuracy: 0.8906 - val_IoU_coef: 0.1564\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2243 - accuracy: 0.8995 - IoU_coef: 0.2243 - val_loss: -0.1563 - val_accuracy: 0.8907 - val_IoU_coef: 0.1563\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2244 - accuracy: 0.8988 - IoU_coef: 0.2244 - val_loss: -0.1568 - val_accuracy: 0.8898 - val_IoU_coef: 0.1568\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2247 - accuracy: 0.8993 - IoU_coef: 0.2247 - val_loss: -0.1564 - val_accuracy: 0.8902 - val_IoU_coef: 0.1564\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2248 - accuracy: 0.8998 - IoU_coef: 0.2248 - val_loss: -0.1550 - val_accuracy: 0.8924 - val_IoU_coef: 0.1550\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2251 - accuracy: 0.8989 - IoU_coef: 0.2251 - val_loss: -0.1556 - val_accuracy: 0.8926 - val_IoU_coef: 0.1556\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2253 - accuracy: 0.8994 - IoU_coef: 0.2253 - val_loss: -0.1585 - val_accuracy: 0.8912 - val_IoU_coef: 0.1585\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2255 - accuracy: 0.9001 - IoU_coef: 0.2255 - val_loss: -0.1612 - val_accuracy: 0.8883 - val_IoU_coef: 0.1612\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2257 - accuracy: 0.8997 - IoU_coef: 0.2257 - val_loss: -0.1622 - val_accuracy: 0.8866 - val_IoU_coef: 0.1622\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2259 - accuracy: 0.8997 - IoU_coef: 0.2259 - val_loss: -0.1606 - val_accuracy: 0.8897 - val_IoU_coef: 0.1606\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2261 - accuracy: 0.9003 - IoU_coef: 0.2261 - val_loss: -0.1607 - val_accuracy: 0.8904 - val_IoU_coef: 0.1607\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2264 - accuracy: 0.8996 - IoU_coef: 0.2264 - val_loss: -0.1616 - val_accuracy: 0.8898 - val_IoU_coef: 0.1616\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2265 - accuracy: 0.9002 - IoU_coef: 0.2265 - val_loss: -0.1620 - val_accuracy: 0.8901 - val_IoU_coef: 0.1620\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2267 - accuracy: 0.9004 - IoU_coef: 0.2267 - val_loss: -0.1613 - val_accuracy: 0.8912 - val_IoU_coef: 0.1613\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2269 - accuracy: 0.9000 - IoU_coef: 0.2269 - val_loss: -0.1618 - val_accuracy: 0.8908 - val_IoU_coef: 0.1618\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2272 - accuracy: 0.9005 - IoU_coef: 0.2272 - val_loss: -0.1625 - val_accuracy: 0.8888 - val_IoU_coef: 0.1625\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2274 - accuracy: 0.9007 - IoU_coef: 0.2274 - val_loss: -0.1626 - val_accuracy: 0.8881 - val_IoU_coef: 0.1626\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2276 - accuracy: 0.9004 - IoU_coef: 0.2276 - val_loss: -0.1631 - val_accuracy: 0.8866 - val_IoU_coef: 0.1631\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2277 - accuracy: 0.9005 - IoU_coef: 0.2277 - val_loss: -0.1638 - val_accuracy: 0.8830 - val_IoU_coef: 0.1638\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2279 - accuracy: 0.9016 - IoU_coef: 0.2279 - val_loss: -0.1655 - val_accuracy: 0.8818 - val_IoU_coef: 0.1655\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2282 - accuracy: 0.9006 - IoU_coef: 0.2282 - val_loss: -0.1661 - val_accuracy: 0.8825 - val_IoU_coef: 0.1661\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2284 - accuracy: 0.9005 - IoU_coef: 0.2284 - val_loss: -0.1661 - val_accuracy: 0.8825 - val_IoU_coef: 0.1661\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2286 - accuracy: 0.9013 - IoU_coef: 0.2286 - val_loss: -0.1659 - val_accuracy: 0.8837 - val_IoU_coef: 0.1659\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2289 - accuracy: 0.9011 - IoU_coef: 0.2289 - val_loss: -0.1644 - val_accuracy: 0.8861 - val_IoU_coef: 0.1644\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2290 - accuracy: 0.9012 - IoU_coef: 0.2290 - val_loss: -0.1626 - val_accuracy: 0.8879 - val_IoU_coef: 0.1626\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2291 - accuracy: 0.9016 - IoU_coef: 0.2291 - val_loss: -0.1647 - val_accuracy: 0.8883 - val_IoU_coef: 0.1647\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2294 - accuracy: 0.9007 - IoU_coef: 0.2294 - val_loss: -0.1661 - val_accuracy: 0.8858 - val_IoU_coef: 0.1661\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2297 - accuracy: 0.9018 - IoU_coef: 0.2297 - val_loss: -0.1653 - val_accuracy: 0.8863 - val_IoU_coef: 0.1653\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2298 - accuracy: 0.9019 - IoU_coef: 0.2298 - val_loss: -0.1657 - val_accuracy: 0.8878 - val_IoU_coef: 0.1657\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2301 - accuracy: 0.9011 - IoU_coef: 0.2301 - val_loss: -0.1664 - val_accuracy: 0.8882 - val_IoU_coef: 0.1664\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2303 - accuracy: 0.9018 - IoU_coef: 0.2303 - val_loss: -0.1666 - val_accuracy: 0.8885 - val_IoU_coef: 0.1666\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2304 - accuracy: 0.9022 - IoU_coef: 0.2304 - val_loss: -0.1668 - val_accuracy: 0.8898 - val_IoU_coef: 0.1668\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2307 - accuracy: 0.9011 - IoU_coef: 0.2307 - val_loss: -0.1665 - val_accuracy: 0.8904 - val_IoU_coef: 0.1665\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2308 - accuracy: 0.9015 - IoU_coef: 0.2308 - val_loss: -0.1676 - val_accuracy: 0.8889 - val_IoU_coef: 0.1676\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: -0.2311 - accuracy: 0.9027 - IoU_coef: 0.2311 - val_loss: -0.1684 - val_accuracy: 0.8889 - val_IoU_coef: 0.1684\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: -0.2313 - accuracy: 0.9024 - IoU_coef: 0.2313 - val_loss: -0.1696 - val_accuracy: 0.8896 - val_IoU_coef: 0.1696\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: -0.2315 - accuracy: 0.9012 - IoU_coef: 0.2315 - val_loss: -0.1705 - val_accuracy: 0.8884 - val_IoU_coef: 0.1705\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 498ms/step - loss: -0.2318 - accuracy: 0.9018 - IoU_coef: 0.2318 - val_loss: -0.1704 - val_accuracy: 0.8893 - val_IoU_coef: 0.1704\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2319 - accuracy: 0.9033 - IoU_coef: 0.2319 - val_loss: -0.1709 - val_accuracy: 0.8915 - val_IoU_coef: 0.1709\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: -0.2322 - accuracy: 0.9024 - IoU_coef: 0.2322 - val_loss: -0.1715 - val_accuracy: 0.8920 - val_IoU_coef: 0.1715\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: -0.2324 - accuracy: 0.9020 - IoU_coef: 0.2324 - val_loss: -0.1708 - val_accuracy: 0.8918 - val_IoU_coef: 0.1708\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: -0.2325 - accuracy: 0.9029 - IoU_coef: 0.2325 - val_loss: -0.1703 - val_accuracy: 0.8924 - val_IoU_coef: 0.1703\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 485ms/step - loss: -0.2329 - accuracy: 0.9027 - IoU_coef: 0.2329 - val_loss: -0.1705 - val_accuracy: 0.8934 - val_IoU_coef: 0.1705\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 474ms/step - loss: -0.2330 - accuracy: 0.9016 - IoU_coef: 0.2330 - val_loss: -0.1707 - val_accuracy: 0.8922 - val_IoU_coef: 0.1707\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 1s 511ms/step - loss: -0.2332 - accuracy: 0.9034 - IoU_coef: 0.2332 - val_loss: -0.1717 - val_accuracy: 0.8918 - val_IoU_coef: 0.1717\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: -0.2334 - accuracy: 0.9036 - IoU_coef: 0.2334 - val_loss: -0.1726 - val_accuracy: 0.8933 - val_IoU_coef: 0.1726\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.2336 - accuracy: 0.9020 - IoU_coef: 0.2336 - val_loss: -0.1730 - val_accuracy: 0.8935 - val_IoU_coef: 0.1730\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: -0.2339 - accuracy: 0.9026 - IoU_coef: 0.2339 - val_loss: -0.1728 - val_accuracy: 0.8935 - val_IoU_coef: 0.1728\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: -0.2341 - accuracy: 0.9037 - IoU_coef: 0.2341 - val_loss: -0.1735 - val_accuracy: 0.8936 - val_IoU_coef: 0.1735\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: -0.2343 - accuracy: 0.9031 - IoU_coef: 0.2343 - val_loss: -0.1740 - val_accuracy: 0.8933 - val_IoU_coef: 0.1740\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: -0.2345 - accuracy: 0.9029 - IoU_coef: 0.2345 - val_loss: -0.1739 - val_accuracy: 0.8936 - val_IoU_coef: 0.1739\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2348 - accuracy: 0.9035 - IoU_coef: 0.2348 - val_loss: -0.1751 - val_accuracy: 0.8932 - val_IoU_coef: 0.1751\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2349 - accuracy: 0.9035 - IoU_coef: 0.2349 - val_loss: -0.1758 - val_accuracy: 0.8934 - val_IoU_coef: 0.1758\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2352 - accuracy: 0.9033 - IoU_coef: 0.2352 - val_loss: -0.1753 - val_accuracy: 0.8929 - val_IoU_coef: 0.1753\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2353 - accuracy: 0.9038 - IoU_coef: 0.2353 - val_loss: -0.1756 - val_accuracy: 0.8924 - val_IoU_coef: 0.1756\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2356 - accuracy: 0.9037 - IoU_coef: 0.2356 - val_loss: -0.1759 - val_accuracy: 0.8924 - val_IoU_coef: 0.1759\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2357 - accuracy: 0.9037 - IoU_coef: 0.2357 - val_loss: -0.1762 - val_accuracy: 0.8925 - val_IoU_coef: 0.1762\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2359 - accuracy: 0.9029 - IoU_coef: 0.2359 - val_loss: -0.1768 - val_accuracy: 0.8924 - val_IoU_coef: 0.1768\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2362 - accuracy: 0.9039 - IoU_coef: 0.2362 - val_loss: -0.1775 - val_accuracy: 0.8907 - val_IoU_coef: 0.1775\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2365 - accuracy: 0.9046 - IoU_coef: 0.2365 - val_loss: -0.1788 - val_accuracy: 0.8886 - val_IoU_coef: 0.1788\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2366 - accuracy: 0.9041 - IoU_coef: 0.2366 - val_loss: -0.1798 - val_accuracy: 0.8907 - val_IoU_coef: 0.1798\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2368 - accuracy: 0.9033 - IoU_coef: 0.2368 - val_loss: -0.1791 - val_accuracy: 0.8925 - val_IoU_coef: 0.1791\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2370 - accuracy: 0.9044 - IoU_coef: 0.2370 - val_loss: -0.1792 - val_accuracy: 0.8919 - val_IoU_coef: 0.1792\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2373 - accuracy: 0.9046 - IoU_coef: 0.2373 - val_loss: -0.1802 - val_accuracy: 0.8916 - val_IoU_coef: 0.1802\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2375 - accuracy: 0.9037 - IoU_coef: 0.2375 - val_loss: -0.1801 - val_accuracy: 0.8920 - val_IoU_coef: 0.1801\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2378 - accuracy: 0.9041 - IoU_coef: 0.2378 - val_loss: -0.1802 - val_accuracy: 0.8915 - val_IoU_coef: 0.1802\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2380 - accuracy: 0.9052 - IoU_coef: 0.2380 - val_loss: -0.1816 - val_accuracy: 0.8916 - val_IoU_coef: 0.1816\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2382 - accuracy: 0.9044 - IoU_coef: 0.2382 - val_loss: -0.1820 - val_accuracy: 0.8926 - val_IoU_coef: 0.1820\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2384 - accuracy: 0.9041 - IoU_coef: 0.2384 - val_loss: -0.1814 - val_accuracy: 0.8940 - val_IoU_coef: 0.1814\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2386 - accuracy: 0.9047 - IoU_coef: 0.2386 - val_loss: -0.1823 - val_accuracy: 0.8936 - val_IoU_coef: 0.1823\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2388 - accuracy: 0.9046 - IoU_coef: 0.2388 - val_loss: -0.1837 - val_accuracy: 0.8925 - val_IoU_coef: 0.1837\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2390 - accuracy: 0.9045 - IoU_coef: 0.2390 - val_loss: -0.1843 - val_accuracy: 0.8914 - val_IoU_coef: 0.1843\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2392 - accuracy: 0.9053 - IoU_coef: 0.2392 - val_loss: -0.1848 - val_accuracy: 0.8916 - val_IoU_coef: 0.1848\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2394 - accuracy: 0.9051 - IoU_coef: 0.2394 - val_loss: -0.1847 - val_accuracy: 0.8925 - val_IoU_coef: 0.1847\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2397 - accuracy: 0.9043 - IoU_coef: 0.2397 - val_loss: -0.1835 - val_accuracy: 0.8937 - val_IoU_coef: 0.1835\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2399 - accuracy: 0.9052 - IoU_coef: 0.2399 - val_loss: -0.1836 - val_accuracy: 0.8937 - val_IoU_coef: 0.1836\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2401 - accuracy: 0.9050 - IoU_coef: 0.2401 - val_loss: -0.1847 - val_accuracy: 0.8920 - val_IoU_coef: 0.1847\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2403 - accuracy: 0.9050 - IoU_coef: 0.2403 - val_loss: -0.1854 - val_accuracy: 0.8911 - val_IoU_coef: 0.1854\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2405 - accuracy: 0.9057 - IoU_coef: 0.2405 - val_loss: -0.1859 - val_accuracy: 0.8898 - val_IoU_coef: 0.1859\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2408 - accuracy: 0.9053 - IoU_coef: 0.2408 - val_loss: -0.1866 - val_accuracy: 0.8887 - val_IoU_coef: 0.1866\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2409 - accuracy: 0.9048 - IoU_coef: 0.2409 - val_loss: -0.1870 - val_accuracy: 0.8905 - val_IoU_coef: 0.1870\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2412 - accuracy: 0.9054 - IoU_coef: 0.2412 - val_loss: -0.1868 - val_accuracy: 0.8918 - val_IoU_coef: 0.1868\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2414 - accuracy: 0.9056 - IoU_coef: 0.2414 - val_loss: -0.1875 - val_accuracy: 0.8934 - val_IoU_coef: 0.1875\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2417 - accuracy: 0.9055 - IoU_coef: 0.2417 - val_loss: -0.1885 - val_accuracy: 0.8935 - val_IoU_coef: 0.1885\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2419 - accuracy: 0.9054 - IoU_coef: 0.2419 - val_loss: -0.1880 - val_accuracy: 0.8936 - val_IoU_coef: 0.1880\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2421 - accuracy: 0.9059 - IoU_coef: 0.2421 - val_loss: -0.1880 - val_accuracy: 0.8943 - val_IoU_coef: 0.1880\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2423 - accuracy: 0.9058 - IoU_coef: 0.2423 - val_loss: -0.1881 - val_accuracy: 0.8947 - val_IoU_coef: 0.1881\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: -0.2425 - accuracy: 0.9054 - IoU_coef: 0.2425 - val_loss: -0.1869 - val_accuracy: 0.8958 - val_IoU_coef: 0.1869\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2426 - accuracy: 0.9061 - IoU_coef: 0.2426 - val_loss: -0.1870 - val_accuracy: 0.8970 - val_IoU_coef: 0.1870\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2430 - accuracy: 0.9061 - IoU_coef: 0.2430 - val_loss: -0.1866 - val_accuracy: 0.8981 - val_IoU_coef: 0.1866\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2431 - accuracy: 0.9062 - IoU_coef: 0.2431 - val_loss: -0.1868 - val_accuracy: 0.8981 - val_IoU_coef: 0.1868\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2434 - accuracy: 0.9057 - IoU_coef: 0.2434 - val_loss: -0.1875 - val_accuracy: 0.8980 - val_IoU_coef: 0.1875\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2436 - accuracy: 0.9062 - IoU_coef: 0.2436 - val_loss: -0.1891 - val_accuracy: 0.8971 - val_IoU_coef: 0.1891\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2438 - accuracy: 0.9063 - IoU_coef: 0.2438 - val_loss: -0.1896 - val_accuracy: 0.8963 - val_IoU_coef: 0.1896\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2441 - accuracy: 0.9064 - IoU_coef: 0.2441 - val_loss: -0.1906 - val_accuracy: 0.8949 - val_IoU_coef: 0.1906\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2443 - accuracy: 0.9063 - IoU_coef: 0.2443 - val_loss: -0.1919 - val_accuracy: 0.8929 - val_IoU_coef: 0.1919\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2445 - accuracy: 0.9065 - IoU_coef: 0.2445 - val_loss: -0.1930 - val_accuracy: 0.8919 - val_IoU_coef: 0.1930\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2447 - accuracy: 0.9063 - IoU_coef: 0.2447 - val_loss: -0.1930 - val_accuracy: 0.8944 - val_IoU_coef: 0.1930\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2449 - accuracy: 0.9063 - IoU_coef: 0.2449 - val_loss: -0.1922 - val_accuracy: 0.8971 - val_IoU_coef: 0.1922\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2452 - accuracy: 0.9071 - IoU_coef: 0.2452 - val_loss: -0.1921 - val_accuracy: 0.8971 - val_IoU_coef: 0.1921\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2454 - accuracy: 0.9067 - IoU_coef: 0.2454 - val_loss: -0.1926 - val_accuracy: 0.8956 - val_IoU_coef: 0.1926\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2456 - accuracy: 0.9067 - IoU_coef: 0.2456 - val_loss: -0.1934 - val_accuracy: 0.8943 - val_IoU_coef: 0.1934\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2458 - accuracy: 0.9066 - IoU_coef: 0.2458 - val_loss: -0.1938 - val_accuracy: 0.8946 - val_IoU_coef: 0.1938\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2460 - accuracy: 0.9066 - IoU_coef: 0.2460 - val_loss: -0.1938 - val_accuracy: 0.8948 - val_IoU_coef: 0.1938\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2463 - accuracy: 0.9074 - IoU_coef: 0.2463 - val_loss: -0.1944 - val_accuracy: 0.8911 - val_IoU_coef: 0.1944\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2465 - accuracy: 0.9073 - IoU_coef: 0.2465 - val_loss: -0.1947 - val_accuracy: 0.8875 - val_IoU_coef: 0.1947\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2467 - accuracy: 0.9065 - IoU_coef: 0.2467 - val_loss: -0.1955 - val_accuracy: 0.8883 - val_IoU_coef: 0.1955\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2469 - accuracy: 0.9073 - IoU_coef: 0.2469 - val_loss: -0.1962 - val_accuracy: 0.8909 - val_IoU_coef: 0.1962\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2471 - accuracy: 0.9074 - IoU_coef: 0.2471 - val_loss: -0.1966 - val_accuracy: 0.8929 - val_IoU_coef: 0.1966\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2474 - accuracy: 0.9068 - IoU_coef: 0.2474 - val_loss: -0.1965 - val_accuracy: 0.8944 - val_IoU_coef: 0.1965\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2476 - accuracy: 0.9076 - IoU_coef: 0.2476 - val_loss: -0.1966 - val_accuracy: 0.8965 - val_IoU_coef: 0.1966\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2478 - accuracy: 0.9079 - IoU_coef: 0.2478 - val_loss: -0.1967 - val_accuracy: 0.8986 - val_IoU_coef: 0.1967\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2481 - accuracy: 0.9075 - IoU_coef: 0.2481 - val_loss: -0.1970 - val_accuracy: 0.8985 - val_IoU_coef: 0.1970\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2483 - accuracy: 0.9074 - IoU_coef: 0.2483 - val_loss: -0.1976 - val_accuracy: 0.8979 - val_IoU_coef: 0.1976\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2485 - accuracy: 0.9078 - IoU_coef: 0.2485 - val_loss: -0.1980 - val_accuracy: 0.8983 - val_IoU_coef: 0.1980\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2488 - accuracy: 0.9070 - IoU_coef: 0.2488 - val_loss: -0.1977 - val_accuracy: 0.8993 - val_IoU_coef: 0.1977\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2490 - accuracy: 0.9084 - IoU_coef: 0.2490 - val_loss: -0.1983 - val_accuracy: 0.8990 - val_IoU_coef: 0.1983\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2492 - accuracy: 0.9081 - IoU_coef: 0.2492 - val_loss: -0.1988 - val_accuracy: 0.8986 - val_IoU_coef: 0.1988\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2494 - accuracy: 0.9070 - IoU_coef: 0.2494 - val_loss: -0.1989 - val_accuracy: 0.8984 - val_IoU_coef: 0.1989\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2496 - accuracy: 0.9083 - IoU_coef: 0.2496 - val_loss: -0.1997 - val_accuracy: 0.8989 - val_IoU_coef: 0.1997\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2498 - accuracy: 0.9085 - IoU_coef: 0.2498 - val_loss: -0.2011 - val_accuracy: 0.8985 - val_IoU_coef: 0.2011\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2501 - accuracy: 0.9073 - IoU_coef: 0.2501 - val_loss: -0.2012 - val_accuracy: 0.8975 - val_IoU_coef: 0.2012\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2503 - accuracy: 0.9082 - IoU_coef: 0.2503 - val_loss: -0.2011 - val_accuracy: 0.8963 - val_IoU_coef: 0.2011\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2506 - accuracy: 0.9086 - IoU_coef: 0.2506 - val_loss: -0.2015 - val_accuracy: 0.8967 - val_IoU_coef: 0.2015\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2508 - accuracy: 0.9081 - IoU_coef: 0.2508 - val_loss: -0.2015 - val_accuracy: 0.8958 - val_IoU_coef: 0.2015\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2510 - accuracy: 0.9079 - IoU_coef: 0.2510 - val_loss: -0.2013 - val_accuracy: 0.8946 - val_IoU_coef: 0.2013\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2512 - accuracy: 0.9088 - IoU_coef: 0.2512 - val_loss: -0.2019 - val_accuracy: 0.8962 - val_IoU_coef: 0.2019\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2514 - accuracy: 0.9084 - IoU_coef: 0.2514 - val_loss: -0.2024 - val_accuracy: 0.8967 - val_IoU_coef: 0.2024\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2516 - accuracy: 0.9085 - IoU_coef: 0.2516 - val_loss: -0.2028 - val_accuracy: 0.8947 - val_IoU_coef: 0.2028\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2519 - accuracy: 0.9091 - IoU_coef: 0.2519 - val_loss: -0.2039 - val_accuracy: 0.8943 - val_IoU_coef: 0.2039\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2521 - accuracy: 0.9078 - IoU_coef: 0.2521 - val_loss: -0.2039 - val_accuracy: 0.8965 - val_IoU_coef: 0.2039\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2523 - accuracy: 0.9084 - IoU_coef: 0.2523 - val_loss: -0.2034 - val_accuracy: 0.8971 - val_IoU_coef: 0.2034\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2525 - accuracy: 0.9095 - IoU_coef: 0.2525 - val_loss: -0.2043 - val_accuracy: 0.8959 - val_IoU_coef: 0.2043\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2527 - accuracy: 0.9083 - IoU_coef: 0.2527 - val_loss: -0.2051 - val_accuracy: 0.8956 - val_IoU_coef: 0.2051\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2530 - accuracy: 0.9082 - IoU_coef: 0.2530 - val_loss: -0.2051 - val_accuracy: 0.8971 - val_IoU_coef: 0.2051\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2532 - accuracy: 0.9094 - IoU_coef: 0.2532 - val_loss: -0.2053 - val_accuracy: 0.8986 - val_IoU_coef: 0.2053\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2535 - accuracy: 0.9088 - IoU_coef: 0.2535 - val_loss: -0.2057 - val_accuracy: 0.8990 - val_IoU_coef: 0.2057\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2537 - accuracy: 0.9085 - IoU_coef: 0.2537 - val_loss: -0.2057 - val_accuracy: 0.8976 - val_IoU_coef: 0.2057\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2539 - accuracy: 0.9095 - IoU_coef: 0.2539 - val_loss: -0.2060 - val_accuracy: 0.8964 - val_IoU_coef: 0.2060\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2541 - accuracy: 0.9090 - IoU_coef: 0.2541 - val_loss: -0.2058 - val_accuracy: 0.8983 - val_IoU_coef: 0.2058\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2544 - accuracy: 0.9086 - IoU_coef: 0.2544 - val_loss: -0.2058 - val_accuracy: 0.8990 - val_IoU_coef: 0.2058\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2546 - accuracy: 0.9095 - IoU_coef: 0.2546 - val_loss: -0.2068 - val_accuracy: 0.8981 - val_IoU_coef: 0.2068\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2548 - accuracy: 0.9092 - IoU_coef: 0.2548 - val_loss: -0.2070 - val_accuracy: 0.8979 - val_IoU_coef: 0.2070\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2550 - accuracy: 0.9091 - IoU_coef: 0.2550 - val_loss: -0.2075 - val_accuracy: 0.8990 - val_IoU_coef: 0.2075\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2552 - accuracy: 0.9093 - IoU_coef: 0.2552 - val_loss: -0.2070 - val_accuracy: 0.9003 - val_IoU_coef: 0.2070\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2555 - accuracy: 0.9092 - IoU_coef: 0.2555 - val_loss: -0.2066 - val_accuracy: 0.8998 - val_IoU_coef: 0.2066\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2558 - accuracy: 0.9096 - IoU_coef: 0.2558 - val_loss: -0.2074 - val_accuracy: 0.8993 - val_IoU_coef: 0.2074\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2559 - accuracy: 0.9094 - IoU_coef: 0.2559 - val_loss: -0.2071 - val_accuracy: 0.9000 - val_IoU_coef: 0.2071\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2562 - accuracy: 0.9093 - IoU_coef: 0.2562 - val_loss: -0.2063 - val_accuracy: 0.9008 - val_IoU_coef: 0.2063\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2564 - accuracy: 0.9103 - IoU_coef: 0.2564 - val_loss: -0.2075 - val_accuracy: 0.9011 - val_IoU_coef: 0.2075\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2567 - accuracy: 0.9093 - IoU_coef: 0.2567 - val_loss: -0.2089 - val_accuracy: 0.8999 - val_IoU_coef: 0.2089\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2569 - accuracy: 0.9091 - IoU_coef: 0.2569 - val_loss: -0.2094 - val_accuracy: 0.8988 - val_IoU_coef: 0.2094\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2571 - accuracy: 0.9103 - IoU_coef: 0.2571 - val_loss: -0.2101 - val_accuracy: 0.8999 - val_IoU_coef: 0.2101\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2573 - accuracy: 0.9104 - IoU_coef: 0.2573 - val_loss: -0.2105 - val_accuracy: 0.9003 - val_IoU_coef: 0.2105\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2576 - accuracy: 0.9091 - IoU_coef: 0.2576 - val_loss: -0.2102 - val_accuracy: 0.9004 - val_IoU_coef: 0.2102\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2578 - accuracy: 0.9097 - IoU_coef: 0.2578 - val_loss: -0.2105 - val_accuracy: 0.9008 - val_IoU_coef: 0.2105\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2580 - accuracy: 0.9107 - IoU_coef: 0.2580 - val_loss: -0.2111 - val_accuracy: 0.9002 - val_IoU_coef: 0.2111\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2582 - accuracy: 0.9098 - IoU_coef: 0.2582 - val_loss: -0.2112 - val_accuracy: 0.8981 - val_IoU_coef: 0.2112\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2585 - accuracy: 0.9093 - IoU_coef: 0.2585 - val_loss: -0.2107 - val_accuracy: 0.8963 - val_IoU_coef: 0.2107\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2588 - accuracy: 0.9111 - IoU_coef: 0.2588 - val_loss: -0.2115 - val_accuracy: 0.8960 - val_IoU_coef: 0.2115\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2589 - accuracy: 0.9102 - IoU_coef: 0.2589 - val_loss: -0.2125 - val_accuracy: 0.8947 - val_IoU_coef: 0.2125\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2591 - accuracy: 0.9093 - IoU_coef: 0.2591 - val_loss: -0.2124 - val_accuracy: 0.8933 - val_IoU_coef: 0.2124\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2594 - accuracy: 0.9106 - IoU_coef: 0.2594 - val_loss: -0.2125 - val_accuracy: 0.8948 - val_IoU_coef: 0.2125\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2596 - accuracy: 0.9109 - IoU_coef: 0.2596 - val_loss: -0.2132 - val_accuracy: 0.8975 - val_IoU_coef: 0.2132\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2598 - accuracy: 0.9096 - IoU_coef: 0.2598 - val_loss: -0.2129 - val_accuracy: 0.8975 - val_IoU_coef: 0.2129\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2601 - accuracy: 0.9102 - IoU_coef: 0.2601 - val_loss: -0.2129 - val_accuracy: 0.8955 - val_IoU_coef: 0.2129\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2604 - accuracy: 0.9113 - IoU_coef: 0.2604 - val_loss: -0.2142 - val_accuracy: 0.8959 - val_IoU_coef: 0.2142\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2606 - accuracy: 0.9102 - IoU_coef: 0.2606 - val_loss: -0.2143 - val_accuracy: 0.8974 - val_IoU_coef: 0.2143\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2607 - accuracy: 0.9101 - IoU_coef: 0.2607 - val_loss: -0.2139 - val_accuracy: 0.8982 - val_IoU_coef: 0.2139\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2611 - accuracy: 0.9111 - IoU_coef: 0.2611 - val_loss: -0.2142 - val_accuracy: 0.8986 - val_IoU_coef: 0.2142\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2613 - accuracy: 0.9107 - IoU_coef: 0.2613 - val_loss: -0.2141 - val_accuracy: 0.8997 - val_IoU_coef: 0.2141\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2614 - accuracy: 0.9102 - IoU_coef: 0.2614 - val_loss: -0.2145 - val_accuracy: 0.9000 - val_IoU_coef: 0.2145\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2618 - accuracy: 0.9107 - IoU_coef: 0.2618 - val_loss: -0.2151 - val_accuracy: 0.9006 - val_IoU_coef: 0.2151\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2621 - accuracy: 0.9117 - IoU_coef: 0.2621 - val_loss: -0.2162 - val_accuracy: 0.9001 - val_IoU_coef: 0.2162\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2622 - accuracy: 0.9110 - IoU_coef: 0.2622 - val_loss: -0.2169 - val_accuracy: 0.8982 - val_IoU_coef: 0.2169\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2625 - accuracy: 0.9104 - IoU_coef: 0.2625 - val_loss: -0.2167 - val_accuracy: 0.8973 - val_IoU_coef: 0.2167\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2626 - accuracy: 0.9112 - IoU_coef: 0.2626 - val_loss: -0.2169 - val_accuracy: 0.8987 - val_IoU_coef: 0.2169\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2629 - accuracy: 0.9115 - IoU_coef: 0.2629 - val_loss: -0.2176 - val_accuracy: 0.8994 - val_IoU_coef: 0.2176\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2632 - accuracy: 0.9102 - IoU_coef: 0.2632 - val_loss: -0.2175 - val_accuracy: 0.9000 - val_IoU_coef: 0.2175\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2634 - accuracy: 0.9116 - IoU_coef: 0.2634 - val_loss: -0.2182 - val_accuracy: 0.8998 - val_IoU_coef: 0.2182\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2637 - accuracy: 0.9115 - IoU_coef: 0.2637 - val_loss: -0.2186 - val_accuracy: 0.9000 - val_IoU_coef: 0.2186\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2639 - accuracy: 0.9108 - IoU_coef: 0.2639 - val_loss: -0.2179 - val_accuracy: 0.8997 - val_IoU_coef: 0.2179\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2641 - accuracy: 0.9119 - IoU_coef: 0.2641 - val_loss: -0.2177 - val_accuracy: 0.8985 - val_IoU_coef: 0.2177\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2643 - accuracy: 0.9113 - IoU_coef: 0.2643 - val_loss: -0.2180 - val_accuracy: 0.8988 - val_IoU_coef: 0.2180\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2646 - accuracy: 0.9109 - IoU_coef: 0.2646 - val_loss: -0.2180 - val_accuracy: 0.8992 - val_IoU_coef: 0.2180\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2648 - accuracy: 0.9118 - IoU_coef: 0.2648 - val_loss: -0.2186 - val_accuracy: 0.8992 - val_IoU_coef: 0.2186\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2650 - accuracy: 0.9115 - IoU_coef: 0.2650 - val_loss: -0.2187 - val_accuracy: 0.9006 - val_IoU_coef: 0.2187\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2653 - accuracy: 0.9112 - IoU_coef: 0.2653 - val_loss: -0.2182 - val_accuracy: 0.9017 - val_IoU_coef: 0.2182\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2655 - accuracy: 0.9121 - IoU_coef: 0.2655 - val_loss: -0.2189 - val_accuracy: 0.9016 - val_IoU_coef: 0.2189\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2657 - accuracy: 0.9112 - IoU_coef: 0.2657 - val_loss: -0.2192 - val_accuracy: 0.9017 - val_IoU_coef: 0.2192\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2660 - accuracy: 0.9113 - IoU_coef: 0.2660 - val_loss: -0.2191 - val_accuracy: 0.9025 - val_IoU_coef: 0.2191\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2662 - accuracy: 0.9123 - IoU_coef: 0.2662 - val_loss: -0.2196 - val_accuracy: 0.9022 - val_IoU_coef: 0.2196\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2665 - accuracy: 0.9118 - IoU_coef: 0.2665 - val_loss: -0.2196 - val_accuracy: 0.9024 - val_IoU_coef: 0.2196\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2667 - accuracy: 0.9116 - IoU_coef: 0.2667 - val_loss: -0.2193 - val_accuracy: 0.9017 - val_IoU_coef: 0.2193\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2670 - accuracy: 0.9121 - IoU_coef: 0.2670 - val_loss: -0.2196 - val_accuracy: 0.9020 - val_IoU_coef: 0.2196\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2672 - accuracy: 0.9121 - IoU_coef: 0.2672 - val_loss: -0.2201 - val_accuracy: 0.9022 - val_IoU_coef: 0.2201\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2674 - accuracy: 0.9119 - IoU_coef: 0.2674 - val_loss: -0.2206 - val_accuracy: 0.9013 - val_IoU_coef: 0.2206\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2677 - accuracy: 0.9121 - IoU_coef: 0.2677 - val_loss: -0.2209 - val_accuracy: 0.9007 - val_IoU_coef: 0.2209\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2678 - accuracy: 0.9121 - IoU_coef: 0.2678 - val_loss: -0.2208 - val_accuracy: 0.9020 - val_IoU_coef: 0.2208\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2682 - accuracy: 0.9125 - IoU_coef: 0.2682 - val_loss: -0.2210 - val_accuracy: 0.9011 - val_IoU_coef: 0.2210\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2685 - accuracy: 0.9121 - IoU_coef: 0.2685 - val_loss: -0.2213 - val_accuracy: 0.8990 - val_IoU_coef: 0.2213\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2686 - accuracy: 0.9120 - IoU_coef: 0.2686 - val_loss: -0.2215 - val_accuracy: 0.8983 - val_IoU_coef: 0.2215\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2688 - accuracy: 0.9124 - IoU_coef: 0.2688 - val_loss: -0.2223 - val_accuracy: 0.8982 - val_IoU_coef: 0.2223\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2691 - accuracy: 0.9124 - IoU_coef: 0.2691 - val_loss: -0.2226 - val_accuracy: 0.8983 - val_IoU_coef: 0.2226\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2693 - accuracy: 0.9117 - IoU_coef: 0.2693 - val_loss: -0.2219 - val_accuracy: 0.8997 - val_IoU_coef: 0.2219\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2695 - accuracy: 0.9129 - IoU_coef: 0.2695 - val_loss: -0.2226 - val_accuracy: 0.9012 - val_IoU_coef: 0.2226\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2698 - accuracy: 0.9125 - IoU_coef: 0.2698 - val_loss: -0.2229 - val_accuracy: 0.9006 - val_IoU_coef: 0.2229\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2700 - accuracy: 0.9119 - IoU_coef: 0.2700 - val_loss: -0.2223 - val_accuracy: 0.9014 - val_IoU_coef: 0.2223\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2703 - accuracy: 0.9129 - IoU_coef: 0.2703 - val_loss: -0.2231 - val_accuracy: 0.9037 - val_IoU_coef: 0.2231\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2705 - accuracy: 0.9129 - IoU_coef: 0.2705 - val_loss: -0.2246 - val_accuracy: 0.9038 - val_IoU_coef: 0.2246\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2707 - accuracy: 0.9120 - IoU_coef: 0.2707 - val_loss: -0.2251 - val_accuracy: 0.9025 - val_IoU_coef: 0.2251\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2710 - accuracy: 0.9127 - IoU_coef: 0.2710 - val_loss: -0.2248 - val_accuracy: 0.9007 - val_IoU_coef: 0.2248\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2712 - accuracy: 0.9135 - IoU_coef: 0.2712 - val_loss: -0.2251 - val_accuracy: 0.9003 - val_IoU_coef: 0.2251\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2715 - accuracy: 0.9121 - IoU_coef: 0.2715 - val_loss: -0.2248 - val_accuracy: 0.9017 - val_IoU_coef: 0.2248\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2717 - accuracy: 0.9125 - IoU_coef: 0.2717 - val_loss: -0.2240 - val_accuracy: 0.9016 - val_IoU_coef: 0.2240\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2720 - accuracy: 0.9136 - IoU_coef: 0.2720 - val_loss: -0.2249 - val_accuracy: 0.8992 - val_IoU_coef: 0.2249\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2722 - accuracy: 0.9125 - IoU_coef: 0.2722 - val_loss: -0.2252 - val_accuracy: 0.8987 - val_IoU_coef: 0.2252\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2724 - accuracy: 0.9124 - IoU_coef: 0.2724 - val_loss: -0.2250 - val_accuracy: 0.8992 - val_IoU_coef: 0.2250\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2726 - accuracy: 0.9137 - IoU_coef: 0.2726 - val_loss: -0.2255 - val_accuracy: 0.8985 - val_IoU_coef: 0.2255\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2729 - accuracy: 0.9125 - IoU_coef: 0.2729 - val_loss: -0.2257 - val_accuracy: 0.8972 - val_IoU_coef: 0.2257\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2732 - accuracy: 0.9126 - IoU_coef: 0.2732 - val_loss: -0.2254 - val_accuracy: 0.8978 - val_IoU_coef: 0.2254\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2734 - accuracy: 0.9139 - IoU_coef: 0.2734 - val_loss: -0.2259 - val_accuracy: 0.8991 - val_IoU_coef: 0.2259\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2736 - accuracy: 0.9129 - IoU_coef: 0.2736 - val_loss: -0.2263 - val_accuracy: 0.9004 - val_IoU_coef: 0.2263\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2738 - accuracy: 0.9124 - IoU_coef: 0.2738 - val_loss: -0.2260 - val_accuracy: 0.9007 - val_IoU_coef: 0.2260\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2741 - accuracy: 0.9136 - IoU_coef: 0.2741 - val_loss: -0.2265 - val_accuracy: 0.8979 - val_IoU_coef: 0.2265\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2743 - accuracy: 0.9132 - IoU_coef: 0.2743 - val_loss: -0.2269 - val_accuracy: 0.8970 - val_IoU_coef: 0.2269\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2746 - accuracy: 0.9132 - IoU_coef: 0.2746 - val_loss: -0.2269 - val_accuracy: 0.8985 - val_IoU_coef: 0.2269\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2749 - accuracy: 0.9136 - IoU_coef: 0.2749 - val_loss: -0.2272 - val_accuracy: 0.9000 - val_IoU_coef: 0.2272\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2750 - accuracy: 0.9129 - IoU_coef: 0.2750 - val_loss: -0.2275 - val_accuracy: 0.9021 - val_IoU_coef: 0.2275\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2752 - accuracy: 0.9132 - IoU_coef: 0.2752 - val_loss: -0.2279 - val_accuracy: 0.9028 - val_IoU_coef: 0.2279\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2756 - accuracy: 0.9139 - IoU_coef: 0.2756 - val_loss: -0.2282 - val_accuracy: 0.9022 - val_IoU_coef: 0.2282\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2757 - accuracy: 0.9133 - IoU_coef: 0.2757 - val_loss: -0.2275 - val_accuracy: 0.9034 - val_IoU_coef: 0.2275\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2760 - accuracy: 0.9133 - IoU_coef: 0.2760 - val_loss: -0.2268 - val_accuracy: 0.9047 - val_IoU_coef: 0.2268\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2763 - accuracy: 0.9141 - IoU_coef: 0.2763 - val_loss: -0.2273 - val_accuracy: 0.9032 - val_IoU_coef: 0.2273\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2765 - accuracy: 0.9131 - IoU_coef: 0.2765 - val_loss: -0.2277 - val_accuracy: 0.9017 - val_IoU_coef: 0.2277\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2767 - accuracy: 0.9131 - IoU_coef: 0.2767 - val_loss: -0.2278 - val_accuracy: 0.9021 - val_IoU_coef: 0.2278\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2770 - accuracy: 0.9146 - IoU_coef: 0.2770 - val_loss: -0.2283 - val_accuracy: 0.9015 - val_IoU_coef: 0.2283\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2773 - accuracy: 0.9135 - IoU_coef: 0.2773 - val_loss: -0.2281 - val_accuracy: 0.9008 - val_IoU_coef: 0.2281\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2775 - accuracy: 0.9133 - IoU_coef: 0.2775 - val_loss: -0.2282 - val_accuracy: 0.9012 - val_IoU_coef: 0.2282\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2778 - accuracy: 0.9143 - IoU_coef: 0.2778 - val_loss: -0.2292 - val_accuracy: 0.9004 - val_IoU_coef: 0.2292\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2780 - accuracy: 0.9139 - IoU_coef: 0.2780 - val_loss: -0.2292 - val_accuracy: 0.8992 - val_IoU_coef: 0.2292\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2782 - accuracy: 0.9134 - IoU_coef: 0.2782 - val_loss: -0.2292 - val_accuracy: 0.8997 - val_IoU_coef: 0.2292\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2785 - accuracy: 0.9142 - IoU_coef: 0.2785 - val_loss: -0.2294 - val_accuracy: 0.8989 - val_IoU_coef: 0.2294\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2787 - accuracy: 0.9146 - IoU_coef: 0.2787 - val_loss: -0.2292 - val_accuracy: 0.8976 - val_IoU_coef: 0.2292\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2790 - accuracy: 0.9135 - IoU_coef: 0.2790 - val_loss: -0.2289 - val_accuracy: 0.8974 - val_IoU_coef: 0.2289\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2793 - accuracy: 0.9140 - IoU_coef: 0.2793 - val_loss: -0.2291 - val_accuracy: 0.8985 - val_IoU_coef: 0.2291\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2794 - accuracy: 0.9147 - IoU_coef: 0.2794 - val_loss: -0.2298 - val_accuracy: 0.9001 - val_IoU_coef: 0.2298\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2797 - accuracy: 0.9136 - IoU_coef: 0.2797 - val_loss: -0.2297 - val_accuracy: 0.9016 - val_IoU_coef: 0.2297\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2799 - accuracy: 0.9139 - IoU_coef: 0.2799 - val_loss: -0.2298 - val_accuracy: 0.9018 - val_IoU_coef: 0.2298\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2802 - accuracy: 0.9149 - IoU_coef: 0.2802 - val_loss: -0.2304 - val_accuracy: 0.9016 - val_IoU_coef: 0.2304\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2805 - accuracy: 0.9141 - IoU_coef: 0.2805 - val_loss: -0.2310 - val_accuracy: 0.9018 - val_IoU_coef: 0.2310\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2807 - accuracy: 0.9139 - IoU_coef: 0.2807 - val_loss: -0.2314 - val_accuracy: 0.9017 - val_IoU_coef: 0.2314\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2809 - accuracy: 0.9147 - IoU_coef: 0.2809 - val_loss: -0.2313 - val_accuracy: 0.9020 - val_IoU_coef: 0.2313\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2812 - accuracy: 0.9143 - IoU_coef: 0.2812 - val_loss: -0.2314 - val_accuracy: 0.9029 - val_IoU_coef: 0.2314\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2814 - accuracy: 0.9143 - IoU_coef: 0.2814 - val_loss: -0.2316 - val_accuracy: 0.9030 - val_IoU_coef: 0.2316\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2817 - accuracy: 0.9147 - IoU_coef: 0.2817 - val_loss: -0.2312 - val_accuracy: 0.9038 - val_IoU_coef: 0.2312\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2819 - accuracy: 0.9143 - IoU_coef: 0.2819 - val_loss: -0.2315 - val_accuracy: 0.9044 - val_IoU_coef: 0.2315\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2822 - accuracy: 0.9144 - IoU_coef: 0.2822 - val_loss: -0.2323 - val_accuracy: 0.9039 - val_IoU_coef: 0.2323\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.2824 - accuracy: 0.9148 - IoU_coef: 0.2824 - val_loss: -0.2326 - val_accuracy: 0.9027 - val_IoU_coef: 0.2326\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2827 - accuracy: 0.9145 - IoU_coef: 0.2827 - val_loss: -0.2328 - val_accuracy: 0.9031 - val_IoU_coef: 0.2328\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2829 - accuracy: 0.9148 - IoU_coef: 0.2829 - val_loss: -0.2335 - val_accuracy: 0.9030 - val_IoU_coef: 0.2335\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2832 - accuracy: 0.9148 - IoU_coef: 0.2832 - val_loss: -0.2340 - val_accuracy: 0.9027 - val_IoU_coef: 0.2340\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2835 - accuracy: 0.9144 - IoU_coef: 0.2835 - val_loss: -0.2335 - val_accuracy: 0.9035 - val_IoU_coef: 0.2335\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2837 - accuracy: 0.9149 - IoU_coef: 0.2837 - val_loss: -0.2337 - val_accuracy: 0.9036 - val_IoU_coef: 0.2337\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2839 - accuracy: 0.9150 - IoU_coef: 0.2839 - val_loss: -0.2344 - val_accuracy: 0.9026 - val_IoU_coef: 0.2344\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2842 - accuracy: 0.9143 - IoU_coef: 0.2842 - val_loss: -0.2338 - val_accuracy: 0.9027 - val_IoU_coef: 0.2338\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2844 - accuracy: 0.9151 - IoU_coef: 0.2844 - val_loss: -0.2335 - val_accuracy: 0.9016 - val_IoU_coef: 0.2335\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2846 - accuracy: 0.9150 - IoU_coef: 0.2846 - val_loss: -0.2341 - val_accuracy: 0.9016 - val_IoU_coef: 0.2341\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2849 - accuracy: 0.9146 - IoU_coef: 0.2849 - val_loss: -0.2340 - val_accuracy: 0.9024 - val_IoU_coef: 0.2340\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2852 - accuracy: 0.9150 - IoU_coef: 0.2852 - val_loss: -0.2341 - val_accuracy: 0.9033 - val_IoU_coef: 0.2341\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2855 - accuracy: 0.9153 - IoU_coef: 0.2855 - val_loss: -0.2350 - val_accuracy: 0.9040 - val_IoU_coef: 0.2350\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2857 - accuracy: 0.9149 - IoU_coef: 0.2857 - val_loss: -0.2355 - val_accuracy: 0.9043 - val_IoU_coef: 0.2355\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2859 - accuracy: 0.9155 - IoU_coef: 0.2859 - val_loss: -0.2358 - val_accuracy: 0.9037 - val_IoU_coef: 0.2358\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2862 - accuracy: 0.9150 - IoU_coef: 0.2862 - val_loss: -0.2358 - val_accuracy: 0.9028 - val_IoU_coef: 0.2358\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2864 - accuracy: 0.9146 - IoU_coef: 0.2864 - val_loss: -0.2357 - val_accuracy: 0.9036 - val_IoU_coef: 0.2357\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.2866 - accuracy: 0.9159 - IoU_coef: 0.2866 - val_loss: -0.2354 - val_accuracy: 0.9034 - val_IoU_coef: 0.2354\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2869 - accuracy: 0.9151 - IoU_coef: 0.2869 - val_loss: -0.2352 - val_accuracy: 0.9032 - val_IoU_coef: 0.2352\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2872 - accuracy: 0.9148 - IoU_coef: 0.2872 - val_loss: -0.2350 - val_accuracy: 0.9049 - val_IoU_coef: 0.2350\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2874 - accuracy: 0.9157 - IoU_coef: 0.2874 - val_loss: -0.2356 - val_accuracy: 0.9051 - val_IoU_coef: 0.2356\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2877 - accuracy: 0.9150 - IoU_coef: 0.2877 - val_loss: -0.2354 - val_accuracy: 0.9056 - val_IoU_coef: 0.2354\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2879 - accuracy: 0.9151 - IoU_coef: 0.2879 - val_loss: -0.2352 - val_accuracy: 0.9059 - val_IoU_coef: 0.2352\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2882 - accuracy: 0.9160 - IoU_coef: 0.2882 - val_loss: -0.2359 - val_accuracy: 0.9046 - val_IoU_coef: 0.2359\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2884 - accuracy: 0.9152 - IoU_coef: 0.2884 - val_loss: -0.2360 - val_accuracy: 0.9027 - val_IoU_coef: 0.2360\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2887 - accuracy: 0.9149 - IoU_coef: 0.2887 - val_loss: -0.2359 - val_accuracy: 0.9026 - val_IoU_coef: 0.2359\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2889 - accuracy: 0.9163 - IoU_coef: 0.2889 - val_loss: -0.2370 - val_accuracy: 0.9030 - val_IoU_coef: 0.2370\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2891 - accuracy: 0.9156 - IoU_coef: 0.2891 - val_loss: -0.2378 - val_accuracy: 0.9039 - val_IoU_coef: 0.2378\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2894 - accuracy: 0.9146 - IoU_coef: 0.2894 - val_loss: -0.2370 - val_accuracy: 0.9058 - val_IoU_coef: 0.2370\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2896 - accuracy: 0.9164 - IoU_coef: 0.2896 - val_loss: -0.2374 - val_accuracy: 0.9053 - val_IoU_coef: 0.2374\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2899 - accuracy: 0.9158 - IoU_coef: 0.2899 - val_loss: -0.2383 - val_accuracy: 0.9036 - val_IoU_coef: 0.2383\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.2901 - accuracy: 0.9147 - IoU_coef: 0.2901 - val_loss: -0.2379 - val_accuracy: 0.9036 - val_IoU_coef: 0.2379\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.2904 - accuracy: 0.9161 - IoU_coef: 0.2904 - val_loss: -0.2380 - val_accuracy: 0.9028 - val_IoU_coef: 0.2380\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2907 - accuracy: 0.9164 - IoU_coef: 0.2907 - val_loss: -0.2388 - val_accuracy: 0.9008 - val_IoU_coef: 0.2388\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2909 - accuracy: 0.9152 - IoU_coef: 0.2909 - val_loss: -0.2388 - val_accuracy: 0.9028 - val_IoU_coef: 0.2388\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.2912 - accuracy: 0.9157 - IoU_coef: 0.2912 - val_loss: -0.2383 - val_accuracy: 0.9032 - val_IoU_coef: 0.2383\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2914 - accuracy: 0.9163 - IoU_coef: 0.2914 - val_loss: -0.2390 - val_accuracy: 0.9016 - val_IoU_coef: 0.2390\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2917 - accuracy: 0.9153 - IoU_coef: 0.2917 - val_loss: -0.2389 - val_accuracy: 0.9020 - val_IoU_coef: 0.2389\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2920 - accuracy: 0.9159 - IoU_coef: 0.2920 - val_loss: -0.2390 - val_accuracy: 0.9031 - val_IoU_coef: 0.2390\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2922 - accuracy: 0.9166 - IoU_coef: 0.2922 - val_loss: -0.2398 - val_accuracy: 0.9023 - val_IoU_coef: 0.2398\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2925 - accuracy: 0.9155 - IoU_coef: 0.2925 - val_loss: -0.2402 - val_accuracy: 0.9031 - val_IoU_coef: 0.2402\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2927 - accuracy: 0.9160 - IoU_coef: 0.2927 - val_loss: -0.2401 - val_accuracy: 0.9033 - val_IoU_coef: 0.2401\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2930 - accuracy: 0.9161 - IoU_coef: 0.2930 - val_loss: -0.2401 - val_accuracy: 0.9027 - val_IoU_coef: 0.2401\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2933 - accuracy: 0.9160 - IoU_coef: 0.2933 - val_loss: -0.2402 - val_accuracy: 0.9024 - val_IoU_coef: 0.2402\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.2935 - accuracy: 0.9165 - IoU_coef: 0.2935 - val_loss: -0.2401 - val_accuracy: 0.9010 - val_IoU_coef: 0.2401\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2938 - accuracy: 0.9161 - IoU_coef: 0.2938 - val_loss: -0.2399 - val_accuracy: 0.8998 - val_IoU_coef: 0.2399\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2940 - accuracy: 0.9160 - IoU_coef: 0.2940 - val_loss: -0.2405 - val_accuracy: 0.9011 - val_IoU_coef: 0.2405\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2943 - accuracy: 0.9164 - IoU_coef: 0.2943 - val_loss: -0.2411 - val_accuracy: 0.9017 - val_IoU_coef: 0.2411\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.2944 - accuracy: 0.9159 - IoU_coef: 0.2944 - val_loss: -0.2414 - val_accuracy: 0.9020 - val_IoU_coef: 0.2414\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2947 - accuracy: 0.9166 - IoU_coef: 0.2947 - val_loss: -0.2417 - val_accuracy: 0.9018 - val_IoU_coef: 0.2417\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2950 - accuracy: 0.9163 - IoU_coef: 0.2950 - val_loss: -0.2418 - val_accuracy: 0.9022 - val_IoU_coef: 0.2418\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.2952 - accuracy: 0.9161 - IoU_coef: 0.2952 - val_loss: -0.2420 - val_accuracy: 0.9011 - val_IoU_coef: 0.2420\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2955 - accuracy: 0.9161 - IoU_coef: 0.2955 - val_loss: -0.2419 - val_accuracy: 0.9016 - val_IoU_coef: 0.2419\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.2958 - accuracy: 0.9166 - IoU_coef: 0.2958 - val_loss: -0.2414 - val_accuracy: 0.9024 - val_IoU_coef: 0.2414\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2959 - accuracy: 0.9169 - IoU_coef: 0.2959 - val_loss: -0.2417 - val_accuracy: 0.9007 - val_IoU_coef: 0.2417\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2963 - accuracy: 0.9160 - IoU_coef: 0.2963 - val_loss: -0.2411 - val_accuracy: 0.8997 - val_IoU_coef: 0.2411\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.2964 - accuracy: 0.9164 - IoU_coef: 0.2964 - val_loss: -0.2416 - val_accuracy: 0.8992 - val_IoU_coef: 0.2416\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2968 - accuracy: 0.9165 - IoU_coef: 0.2968 - val_loss: -0.2425 - val_accuracy: 0.8978 - val_IoU_coef: 0.2425\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2970 - accuracy: 0.9162 - IoU_coef: 0.2970 - val_loss: -0.2424 - val_accuracy: 0.8992 - val_IoU_coef: 0.2424\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2973 - accuracy: 0.9169 - IoU_coef: 0.2973 - val_loss: -0.2417 - val_accuracy: 0.9011 - val_IoU_coef: 0.2417\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2975 - accuracy: 0.9171 - IoU_coef: 0.2975 - val_loss: -0.2419 - val_accuracy: 0.9005 - val_IoU_coef: 0.2419\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.2978 - accuracy: 0.9160 - IoU_coef: 0.2978 - val_loss: -0.2422 - val_accuracy: 0.9016 - val_IoU_coef: 0.2422\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.2980 - accuracy: 0.9166 - IoU_coef: 0.2980 - val_loss: -0.2424 - val_accuracy: 0.9017 - val_IoU_coef: 0.2424\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.2983 - accuracy: 0.9171 - IoU_coef: 0.2983 - val_loss: -0.2432 - val_accuracy: 0.9008 - val_IoU_coef: 0.2432\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.2986 - accuracy: 0.9165 - IoU_coef: 0.2986 - val_loss: -0.2440 - val_accuracy: 0.9016 - val_IoU_coef: 0.2440\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.2989 - accuracy: 0.9168 - IoU_coef: 0.2989 - val_loss: -0.2441 - val_accuracy: 0.9017 - val_IoU_coef: 0.2441\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.2991 - accuracy: 0.9170 - IoU_coef: 0.2991 - val_loss: -0.2440 - val_accuracy: 0.9014 - val_IoU_coef: 0.2440\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2994 - accuracy: 0.9166 - IoU_coef: 0.2994 - val_loss: -0.2447 - val_accuracy: 0.9019 - val_IoU_coef: 0.2447\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.2997 - accuracy: 0.9166 - IoU_coef: 0.2997 - val_loss: -0.2450 - val_accuracy: 0.9033 - val_IoU_coef: 0.2450\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.2998 - accuracy: 0.9171 - IoU_coef: 0.2998 - val_loss: -0.2444 - val_accuracy: 0.9037 - val_IoU_coef: 0.2444\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3002 - accuracy: 0.9172 - IoU_coef: 0.3002 - val_loss: -0.2448 - val_accuracy: 0.9043 - val_IoU_coef: 0.2448\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3004 - accuracy: 0.9166 - IoU_coef: 0.3004 - val_loss: -0.2452 - val_accuracy: 0.9068 - val_IoU_coef: 0.2452\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3006 - accuracy: 0.9169 - IoU_coef: 0.3006 - val_loss: -0.2456 - val_accuracy: 0.9064 - val_IoU_coef: 0.2456\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3009 - accuracy: 0.9171 - IoU_coef: 0.3009 - val_loss: -0.2456 - val_accuracy: 0.9063 - val_IoU_coef: 0.2456\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3010 - accuracy: 0.9169 - IoU_coef: 0.3010 - val_loss: -0.2457 - val_accuracy: 0.9077 - val_IoU_coef: 0.2457\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3013 - accuracy: 0.9171 - IoU_coef: 0.3013 - val_loss: -0.2459 - val_accuracy: 0.9079 - val_IoU_coef: 0.2459\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3016 - accuracy: 0.9168 - IoU_coef: 0.3016 - val_loss: -0.2459 - val_accuracy: 0.9078 - val_IoU_coef: 0.2459\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3018 - accuracy: 0.9172 - IoU_coef: 0.3018 - val_loss: -0.2459 - val_accuracy: 0.9079 - val_IoU_coef: 0.2459\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3021 - accuracy: 0.9168 - IoU_coef: 0.3021 - val_loss: -0.2463 - val_accuracy: 0.9083 - val_IoU_coef: 0.2463\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3023 - accuracy: 0.9168 - IoU_coef: 0.3023 - val_loss: -0.2469 - val_accuracy: 0.9083 - val_IoU_coef: 0.2469\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3026 - accuracy: 0.9171 - IoU_coef: 0.3026 - val_loss: -0.2477 - val_accuracy: 0.9073 - val_IoU_coef: 0.2477\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3029 - accuracy: 0.9172 - IoU_coef: 0.3029 - val_loss: -0.2481 - val_accuracy: 0.9064 - val_IoU_coef: 0.2481\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3031 - accuracy: 0.9176 - IoU_coef: 0.3031 - val_loss: -0.2481 - val_accuracy: 0.9060 - val_IoU_coef: 0.2481\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3034 - accuracy: 0.9172 - IoU_coef: 0.3034 - val_loss: -0.2484 - val_accuracy: 0.9058 - val_IoU_coef: 0.2484\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3038 - accuracy: 0.9170 - IoU_coef: 0.3038 - val_loss: -0.2490 - val_accuracy: 0.9060 - val_IoU_coef: 0.2490\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3040 - accuracy: 0.9173 - IoU_coef: 0.3040 - val_loss: -0.2493 - val_accuracy: 0.9064 - val_IoU_coef: 0.2493\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3043 - accuracy: 0.9173 - IoU_coef: 0.3043 - val_loss: -0.2492 - val_accuracy: 0.9051 - val_IoU_coef: 0.2492\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3046 - accuracy: 0.9175 - IoU_coef: 0.3046 - val_loss: -0.2487 - val_accuracy: 0.9048 - val_IoU_coef: 0.2487\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3048 - accuracy: 0.9176 - IoU_coef: 0.3048 - val_loss: -0.2487 - val_accuracy: 0.9053 - val_IoU_coef: 0.2487\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3051 - accuracy: 0.9173 - IoU_coef: 0.3051 - val_loss: -0.2489 - val_accuracy: 0.9051 - val_IoU_coef: 0.2489\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3053 - accuracy: 0.9174 - IoU_coef: 0.3053 - val_loss: -0.2493 - val_accuracy: 0.9048 - val_IoU_coef: 0.2493\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.3056 - accuracy: 0.9178 - IoU_coef: 0.3056 - val_loss: -0.2499 - val_accuracy: 0.9045 - val_IoU_coef: 0.2499\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3058 - accuracy: 0.9172 - IoU_coef: 0.3058 - val_loss: -0.2504 - val_accuracy: 0.9043 - val_IoU_coef: 0.2504\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3061 - accuracy: 0.9177 - IoU_coef: 0.3061 - val_loss: -0.2499 - val_accuracy: 0.9045 - val_IoU_coef: 0.2499\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3064 - accuracy: 0.9182 - IoU_coef: 0.3064 - val_loss: -0.2497 - val_accuracy: 0.9040 - val_IoU_coef: 0.2497\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3066 - accuracy: 0.9170 - IoU_coef: 0.3066 - val_loss: -0.2504 - val_accuracy: 0.9047 - val_IoU_coef: 0.2504\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3069 - accuracy: 0.9175 - IoU_coef: 0.3069 - val_loss: -0.2504 - val_accuracy: 0.9056 - val_IoU_coef: 0.2504\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3070 - accuracy: 0.9184 - IoU_coef: 0.3070 - val_loss: -0.2504 - val_accuracy: 0.9044 - val_IoU_coef: 0.2504\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3073 - accuracy: 0.9170 - IoU_coef: 0.3073 - val_loss: -0.2505 - val_accuracy: 0.9049 - val_IoU_coef: 0.2505\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.3077 - accuracy: 0.9177 - IoU_coef: 0.3077 - val_loss: -0.2505 - val_accuracy: 0.9048 - val_IoU_coef: 0.2505\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3079 - accuracy: 0.9181 - IoU_coef: 0.3079 - val_loss: -0.2507 - val_accuracy: 0.9040 - val_IoU_coef: 0.2507\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3082 - accuracy: 0.9174 - IoU_coef: 0.3082 - val_loss: -0.2507 - val_accuracy: 0.9039 - val_IoU_coef: 0.2507\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3084 - accuracy: 0.9178 - IoU_coef: 0.3084 - val_loss: -0.2510 - val_accuracy: 0.9050 - val_IoU_coef: 0.2510\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3086 - accuracy: 0.9184 - IoU_coef: 0.3086 - val_loss: -0.2513 - val_accuracy: 0.9041 - val_IoU_coef: 0.2513\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3089 - accuracy: 0.9174 - IoU_coef: 0.3089 - val_loss: -0.2512 - val_accuracy: 0.9029 - val_IoU_coef: 0.2512\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3093 - accuracy: 0.9176 - IoU_coef: 0.3093 - val_loss: -0.2511 - val_accuracy: 0.9030 - val_IoU_coef: 0.2511\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3094 - accuracy: 0.9184 - IoU_coef: 0.3094 - val_loss: -0.2516 - val_accuracy: 0.9036 - val_IoU_coef: 0.2516\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3097 - accuracy: 0.9176 - IoU_coef: 0.3097 - val_loss: -0.2521 - val_accuracy: 0.9042 - val_IoU_coef: 0.2521\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3100 - accuracy: 0.9176 - IoU_coef: 0.3100 - val_loss: -0.2522 - val_accuracy: 0.9050 - val_IoU_coef: 0.2522\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3102 - accuracy: 0.9186 - IoU_coef: 0.3102 - val_loss: -0.2523 - val_accuracy: 0.9031 - val_IoU_coef: 0.2523\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3105 - accuracy: 0.9177 - IoU_coef: 0.3105 - val_loss: -0.2520 - val_accuracy: 0.9020 - val_IoU_coef: 0.2520\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3107 - accuracy: 0.9175 - IoU_coef: 0.3107 - val_loss: -0.2527 - val_accuracy: 0.9026 - val_IoU_coef: 0.2527\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3112 - accuracy: 0.9184 - IoU_coef: 0.3112 - val_loss: -0.2532 - val_accuracy: 0.9028 - val_IoU_coef: 0.2532\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3113 - accuracy: 0.9185 - IoU_coef: 0.3113 - val_loss: -0.2531 - val_accuracy: 0.9032 - val_IoU_coef: 0.2531\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3116 - accuracy: 0.9176 - IoU_coef: 0.3116 - val_loss: -0.2533 - val_accuracy: 0.9038 - val_IoU_coef: 0.2533\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3119 - accuracy: 0.9183 - IoU_coef: 0.3119 - val_loss: -0.2537 - val_accuracy: 0.9035 - val_IoU_coef: 0.2537\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3121 - accuracy: 0.9182 - IoU_coef: 0.3121 - val_loss: -0.2534 - val_accuracy: 0.9025 - val_IoU_coef: 0.2534\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3123 - accuracy: 0.9180 - IoU_coef: 0.3123 - val_loss: -0.2531 - val_accuracy: 0.9020 - val_IoU_coef: 0.2531\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3126 - accuracy: 0.9180 - IoU_coef: 0.3126 - val_loss: -0.2535 - val_accuracy: 0.9034 - val_IoU_coef: 0.2535\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3129 - accuracy: 0.9187 - IoU_coef: 0.3129 - val_loss: -0.2544 - val_accuracy: 0.9031 - val_IoU_coef: 0.2544\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3132 - accuracy: 0.9182 - IoU_coef: 0.3132 - val_loss: -0.2540 - val_accuracy: 0.9013 - val_IoU_coef: 0.2540\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3134 - accuracy: 0.9180 - IoU_coef: 0.3134 - val_loss: -0.2541 - val_accuracy: 0.9029 - val_IoU_coef: 0.2541\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3137 - accuracy: 0.9186 - IoU_coef: 0.3137 - val_loss: -0.2554 - val_accuracy: 0.9040 - val_IoU_coef: 0.2554\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3140 - accuracy: 0.9182 - IoU_coef: 0.3140 - val_loss: -0.2558 - val_accuracy: 0.9043 - val_IoU_coef: 0.2558\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3143 - accuracy: 0.9183 - IoU_coef: 0.3143 - val_loss: -0.2552 - val_accuracy: 0.9037 - val_IoU_coef: 0.2552\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3145 - accuracy: 0.9187 - IoU_coef: 0.3145 - val_loss: -0.2553 - val_accuracy: 0.9032 - val_IoU_coef: 0.2553\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3147 - accuracy: 0.9184 - IoU_coef: 0.3147 - val_loss: -0.2556 - val_accuracy: 0.9029 - val_IoU_coef: 0.2556\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3150 - accuracy: 0.9179 - IoU_coef: 0.3150 - val_loss: -0.2560 - val_accuracy: 0.9043 - val_IoU_coef: 0.2560\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3153 - accuracy: 0.9186 - IoU_coef: 0.3153 - val_loss: -0.2554 - val_accuracy: 0.9032 - val_IoU_coef: 0.2554\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.3155 - accuracy: 0.9183 - IoU_coef: 0.3155 - val_loss: -0.2554 - val_accuracy: 0.9033 - val_IoU_coef: 0.2554\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3159 - accuracy: 0.9184 - IoU_coef: 0.3159 - val_loss: -0.2562 - val_accuracy: 0.9045 - val_IoU_coef: 0.2562\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3161 - accuracy: 0.9190 - IoU_coef: 0.3161 - val_loss: -0.2558 - val_accuracy: 0.9036 - val_IoU_coef: 0.2558\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3164 - accuracy: 0.9182 - IoU_coef: 0.3164 - val_loss: -0.2554 - val_accuracy: 0.9041 - val_IoU_coef: 0.2554\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3167 - accuracy: 0.9186 - IoU_coef: 0.3167 - val_loss: -0.2553 - val_accuracy: 0.9047 - val_IoU_coef: 0.2553\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.3169 - accuracy: 0.9190 - IoU_coef: 0.3169 - val_loss: -0.2555 - val_accuracy: 0.9056 - val_IoU_coef: 0.2555\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3171 - accuracy: 0.9184 - IoU_coef: 0.3171 - val_loss: -0.2556 - val_accuracy: 0.9059 - val_IoU_coef: 0.2556\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3174 - accuracy: 0.9185 - IoU_coef: 0.3174 - val_loss: -0.2562 - val_accuracy: 0.9050 - val_IoU_coef: 0.2562\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3177 - accuracy: 0.9188 - IoU_coef: 0.3177 - val_loss: -0.2566 - val_accuracy: 0.9039 - val_IoU_coef: 0.2566\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3181 - accuracy: 0.9186 - IoU_coef: 0.3181 - val_loss: -0.2567 - val_accuracy: 0.9036 - val_IoU_coef: 0.2567\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3183 - accuracy: 0.9189 - IoU_coef: 0.3183 - val_loss: -0.2565 - val_accuracy: 0.9036 - val_IoU_coef: 0.2565\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3186 - accuracy: 0.9189 - IoU_coef: 0.3186 - val_loss: -0.2561 - val_accuracy: 0.9033 - val_IoU_coef: 0.2561\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3188 - accuracy: 0.9188 - IoU_coef: 0.3188 - val_loss: -0.2558 - val_accuracy: 0.9033 - val_IoU_coef: 0.2558\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3189 - accuracy: 0.9186 - IoU_coef: 0.3189 - val_loss: -0.2560 - val_accuracy: 0.9027 - val_IoU_coef: 0.2560\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3194 - accuracy: 0.9189 - IoU_coef: 0.3194 - val_loss: -0.2561 - val_accuracy: 0.9022 - val_IoU_coef: 0.2561\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3196 - accuracy: 0.9191 - IoU_coef: 0.3196 - val_loss: -0.2562 - val_accuracy: 0.9016 - val_IoU_coef: 0.2562\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3198 - accuracy: 0.9183 - IoU_coef: 0.3198 - val_loss: -0.2572 - val_accuracy: 0.9029 - val_IoU_coef: 0.2572\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3202 - accuracy: 0.9192 - IoU_coef: 0.3202 - val_loss: -0.2573 - val_accuracy: 0.9038 - val_IoU_coef: 0.2573\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3205 - accuracy: 0.9193 - IoU_coef: 0.3205 - val_loss: -0.2572 - val_accuracy: 0.9042 - val_IoU_coef: 0.2572\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3206 - accuracy: 0.9185 - IoU_coef: 0.3206 - val_loss: -0.2573 - val_accuracy: 0.9047 - val_IoU_coef: 0.2573\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3209 - accuracy: 0.9188 - IoU_coef: 0.3209 - val_loss: -0.2578 - val_accuracy: 0.9050 - val_IoU_coef: 0.2578\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3211 - accuracy: 0.9195 - IoU_coef: 0.3211 - val_loss: -0.2578 - val_accuracy: 0.9038 - val_IoU_coef: 0.2578\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3214 - accuracy: 0.9185 - IoU_coef: 0.3214 - val_loss: -0.2575 - val_accuracy: 0.9043 - val_IoU_coef: 0.2575\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3217 - accuracy: 0.9190 - IoU_coef: 0.3217 - val_loss: -0.2584 - val_accuracy: 0.9047 - val_IoU_coef: 0.2584\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3220 - accuracy: 0.9192 - IoU_coef: 0.3220 - val_loss: -0.2588 - val_accuracy: 0.9046 - val_IoU_coef: 0.2588\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3222 - accuracy: 0.9189 - IoU_coef: 0.3222 - val_loss: -0.2582 - val_accuracy: 0.9038 - val_IoU_coef: 0.2582\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3225 - accuracy: 0.9191 - IoU_coef: 0.3225 - val_loss: -0.2571 - val_accuracy: 0.9029 - val_IoU_coef: 0.2571\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3228 - accuracy: 0.9194 - IoU_coef: 0.3228 - val_loss: -0.2577 - val_accuracy: 0.9022 - val_IoU_coef: 0.2577\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3231 - accuracy: 0.9188 - IoU_coef: 0.3231 - val_loss: -0.2583 - val_accuracy: 0.9032 - val_IoU_coef: 0.2583\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3233 - accuracy: 0.9193 - IoU_coef: 0.3233 - val_loss: -0.2579 - val_accuracy: 0.9040 - val_IoU_coef: 0.2579\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3235 - accuracy: 0.9194 - IoU_coef: 0.3235 - val_loss: -0.2586 - val_accuracy: 0.9027 - val_IoU_coef: 0.2586\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3239 - accuracy: 0.9186 - IoU_coef: 0.3239 - val_loss: -0.2589 - val_accuracy: 0.9025 - val_IoU_coef: 0.2589\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3241 - accuracy: 0.9195 - IoU_coef: 0.3241 - val_loss: -0.2586 - val_accuracy: 0.9016 - val_IoU_coef: 0.2586\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3242 - accuracy: 0.9197 - IoU_coef: 0.3242 - val_loss: -0.2591 - val_accuracy: 0.9008 - val_IoU_coef: 0.2591\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3247 - accuracy: 0.9185 - IoU_coef: 0.3247 - val_loss: -0.2594 - val_accuracy: 0.9034 - val_IoU_coef: 0.2594\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3248 - accuracy: 0.9195 - IoU_coef: 0.3248 - val_loss: -0.2594 - val_accuracy: 0.9040 - val_IoU_coef: 0.2594\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.3251 - accuracy: 0.9193 - IoU_coef: 0.3251 - val_loss: -0.2604 - val_accuracy: 0.9034 - val_IoU_coef: 0.2604\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3254 - accuracy: 0.9188 - IoU_coef: 0.3254 - val_loss: -0.2604 - val_accuracy: 0.9039 - val_IoU_coef: 0.2604\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3257 - accuracy: 0.9196 - IoU_coef: 0.3257 - val_loss: -0.2601 - val_accuracy: 0.9035 - val_IoU_coef: 0.2601\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3259 - accuracy: 0.9197 - IoU_coef: 0.3259 - val_loss: -0.2604 - val_accuracy: 0.9020 - val_IoU_coef: 0.2604\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3262 - accuracy: 0.9192 - IoU_coef: 0.3262 - val_loss: -0.2607 - val_accuracy: 0.9014 - val_IoU_coef: 0.2607\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3265 - accuracy: 0.9192 - IoU_coef: 0.3265 - val_loss: -0.2610 - val_accuracy: 0.9026 - val_IoU_coef: 0.2610\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3268 - accuracy: 0.9196 - IoU_coef: 0.3268 - val_loss: -0.2610 - val_accuracy: 0.9023 - val_IoU_coef: 0.2610\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3271 - accuracy: 0.9195 - IoU_coef: 0.3271 - val_loss: -0.2608 - val_accuracy: 0.9012 - val_IoU_coef: 0.2608\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3272 - accuracy: 0.9190 - IoU_coef: 0.3272 - val_loss: -0.2617 - val_accuracy: 0.9022 - val_IoU_coef: 0.2617\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3275 - accuracy: 0.9197 - IoU_coef: 0.3275 - val_loss: -0.2623 - val_accuracy: 0.9033 - val_IoU_coef: 0.2623\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.3280 - accuracy: 0.9198 - IoU_coef: 0.3280 - val_loss: -0.2619 - val_accuracy: 0.9031 - val_IoU_coef: 0.2619\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3282 - accuracy: 0.9193 - IoU_coef: 0.3282 - val_loss: -0.2615 - val_accuracy: 0.9022 - val_IoU_coef: 0.2615\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3285 - accuracy: 0.9194 - IoU_coef: 0.3285 - val_loss: -0.2608 - val_accuracy: 0.9013 - val_IoU_coef: 0.2608\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3287 - accuracy: 0.9199 - IoU_coef: 0.3287 - val_loss: -0.2605 - val_accuracy: 0.8987 - val_IoU_coef: 0.2605\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3290 - accuracy: 0.9194 - IoU_coef: 0.3290 - val_loss: -0.2610 - val_accuracy: 0.8992 - val_IoU_coef: 0.2610\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3292 - accuracy: 0.9195 - IoU_coef: 0.3292 - val_loss: -0.2620 - val_accuracy: 0.9004 - val_IoU_coef: 0.2620\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3295 - accuracy: 0.9199 - IoU_coef: 0.3295 - val_loss: -0.2626 - val_accuracy: 0.9002 - val_IoU_coef: 0.2626\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3297 - accuracy: 0.9196 - IoU_coef: 0.3297 - val_loss: -0.2625 - val_accuracy: 0.9000 - val_IoU_coef: 0.2625\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3301 - accuracy: 0.9195 - IoU_coef: 0.3301 - val_loss: -0.2632 - val_accuracy: 0.9009 - val_IoU_coef: 0.2632\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3302 - accuracy: 0.9202 - IoU_coef: 0.3302 - val_loss: -0.2633 - val_accuracy: 0.8983 - val_IoU_coef: 0.2633\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3305 - accuracy: 0.9193 - IoU_coef: 0.3305 - val_loss: -0.2623 - val_accuracy: 0.8958 - val_IoU_coef: 0.2623\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3309 - accuracy: 0.9195 - IoU_coef: 0.3309 - val_loss: -0.2620 - val_accuracy: 0.8969 - val_IoU_coef: 0.2620\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.3313 - accuracy: 0.9204 - IoU_coef: 0.3313 - val_loss: -0.2624 - val_accuracy: 0.8979 - val_IoU_coef: 0.2624\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3314 - accuracy: 0.9197 - IoU_coef: 0.3314 - val_loss: -0.2629 - val_accuracy: 0.9001 - val_IoU_coef: 0.2629\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3316 - accuracy: 0.9194 - IoU_coef: 0.3316 - val_loss: -0.2637 - val_accuracy: 0.9015 - val_IoU_coef: 0.2637\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3319 - accuracy: 0.9200 - IoU_coef: 0.3319 - val_loss: -0.2641 - val_accuracy: 0.9009 - val_IoU_coef: 0.2641\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3323 - accuracy: 0.9200 - IoU_coef: 0.3323 - val_loss: -0.2637 - val_accuracy: 0.8997 - val_IoU_coef: 0.2637\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3325 - accuracy: 0.9196 - IoU_coef: 0.3325 - val_loss: -0.2643 - val_accuracy: 0.9011 - val_IoU_coef: 0.2643\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3328 - accuracy: 0.9199 - IoU_coef: 0.3328 - val_loss: -0.2652 - val_accuracy: 0.9028 - val_IoU_coef: 0.2652\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3330 - accuracy: 0.9201 - IoU_coef: 0.3330 - val_loss: -0.2647 - val_accuracy: 0.9020 - val_IoU_coef: 0.2647\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3332 - accuracy: 0.9195 - IoU_coef: 0.3332 - val_loss: -0.2646 - val_accuracy: 0.9024 - val_IoU_coef: 0.2646\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3337 - accuracy: 0.9200 - IoU_coef: 0.3337 - val_loss: -0.2651 - val_accuracy: 0.9034 - val_IoU_coef: 0.2651\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3339 - accuracy: 0.9204 - IoU_coef: 0.3339 - val_loss: -0.2656 - val_accuracy: 0.9025 - val_IoU_coef: 0.2656\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3341 - accuracy: 0.9197 - IoU_coef: 0.3341 - val_loss: -0.2662 - val_accuracy: 0.9022 - val_IoU_coef: 0.2662\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3344 - accuracy: 0.9198 - IoU_coef: 0.3344 - val_loss: -0.2665 - val_accuracy: 0.9021 - val_IoU_coef: 0.2665\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3347 - accuracy: 0.9202 - IoU_coef: 0.3347 - val_loss: -0.2663 - val_accuracy: 0.9007 - val_IoU_coef: 0.2663\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3350 - accuracy: 0.9201 - IoU_coef: 0.3350 - val_loss: -0.2669 - val_accuracy: 0.9008 - val_IoU_coef: 0.2669\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3352 - accuracy: 0.9201 - IoU_coef: 0.3352 - val_loss: -0.2672 - val_accuracy: 0.9027 - val_IoU_coef: 0.2672\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3355 - accuracy: 0.9201 - IoU_coef: 0.3355 - val_loss: -0.2678 - val_accuracy: 0.9037 - val_IoU_coef: 0.2678\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3357 - accuracy: 0.9198 - IoU_coef: 0.3357 - val_loss: -0.2679 - val_accuracy: 0.9029 - val_IoU_coef: 0.2679\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3362 - accuracy: 0.9201 - IoU_coef: 0.3362 - val_loss: -0.2677 - val_accuracy: 0.9030 - val_IoU_coef: 0.2677\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3364 - accuracy: 0.9205 - IoU_coef: 0.3364 - val_loss: -0.2678 - val_accuracy: 0.9030 - val_IoU_coef: 0.2678\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3365 - accuracy: 0.9196 - IoU_coef: 0.3365 - val_loss: -0.2682 - val_accuracy: 0.9037 - val_IoU_coef: 0.2682\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3369 - accuracy: 0.9203 - IoU_coef: 0.3369 - val_loss: -0.2683 - val_accuracy: 0.9035 - val_IoU_coef: 0.2683\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3372 - accuracy: 0.9206 - IoU_coef: 0.3372 - val_loss: -0.2685 - val_accuracy: 0.9030 - val_IoU_coef: 0.2685\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3374 - accuracy: 0.9197 - IoU_coef: 0.3374 - val_loss: -0.2686 - val_accuracy: 0.9037 - val_IoU_coef: 0.2686\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3377 - accuracy: 0.9202 - IoU_coef: 0.3377 - val_loss: -0.2688 - val_accuracy: 0.9030 - val_IoU_coef: 0.2688\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3378 - accuracy: 0.9204 - IoU_coef: 0.3378 - val_loss: -0.2691 - val_accuracy: 0.9021 - val_IoU_coef: 0.2691\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3381 - accuracy: 0.9198 - IoU_coef: 0.3381 - val_loss: -0.2689 - val_accuracy: 0.9024 - val_IoU_coef: 0.2689\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3385 - accuracy: 0.9205 - IoU_coef: 0.3385 - val_loss: -0.2687 - val_accuracy: 0.9023 - val_IoU_coef: 0.2687\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3386 - accuracy: 0.9206 - IoU_coef: 0.3386 - val_loss: -0.2692 - val_accuracy: 0.9026 - val_IoU_coef: 0.2692\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3388 - accuracy: 0.9194 - IoU_coef: 0.3388 - val_loss: -0.2694 - val_accuracy: 0.9037 - val_IoU_coef: 0.2694\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3393 - accuracy: 0.9205 - IoU_coef: 0.3393 - val_loss: -0.2691 - val_accuracy: 0.9041 - val_IoU_coef: 0.2691\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3395 - accuracy: 0.9207 - IoU_coef: 0.3395 - val_loss: -0.2690 - val_accuracy: 0.9040 - val_IoU_coef: 0.2690\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3397 - accuracy: 0.9198 - IoU_coef: 0.3397 - val_loss: -0.2693 - val_accuracy: 0.9049 - val_IoU_coef: 0.2693\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3402 - accuracy: 0.9204 - IoU_coef: 0.3402 - val_loss: -0.2697 - val_accuracy: 0.9048 - val_IoU_coef: 0.2697\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3403 - accuracy: 0.9208 - IoU_coef: 0.3403 - val_loss: -0.2692 - val_accuracy: 0.9024 - val_IoU_coef: 0.2692\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.3407 - accuracy: 0.9199 - IoU_coef: 0.3407 - val_loss: -0.2690 - val_accuracy: 0.9025 - val_IoU_coef: 0.2690\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3410 - accuracy: 0.9205 - IoU_coef: 0.3410 - val_loss: -0.2700 - val_accuracy: 0.9037 - val_IoU_coef: 0.2700\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3412 - accuracy: 0.9206 - IoU_coef: 0.3412 - val_loss: -0.2710 - val_accuracy: 0.9035 - val_IoU_coef: 0.2710\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3413 - accuracy: 0.9201 - IoU_coef: 0.3413 - val_loss: -0.2709 - val_accuracy: 0.9034 - val_IoU_coef: 0.2709\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3417 - accuracy: 0.9205 - IoU_coef: 0.3417 - val_loss: -0.2711 - val_accuracy: 0.9021 - val_IoU_coef: 0.2711\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3420 - accuracy: 0.9205 - IoU_coef: 0.3420 - val_loss: -0.2719 - val_accuracy: 0.9029 - val_IoU_coef: 0.2719\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3423 - accuracy: 0.9203 - IoU_coef: 0.3423 - val_loss: -0.2719 - val_accuracy: 0.9039 - val_IoU_coef: 0.2719\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.3426 - accuracy: 0.9206 - IoU_coef: 0.3426 - val_loss: -0.2718 - val_accuracy: 0.9031 - val_IoU_coef: 0.2718\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.3429 - accuracy: 0.9207 - IoU_coef: 0.3429 - val_loss: -0.2719 - val_accuracy: 0.9018 - val_IoU_coef: 0.2719\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3432 - accuracy: 0.9204 - IoU_coef: 0.3432 - val_loss: -0.2720 - val_accuracy: 0.9017 - val_IoU_coef: 0.2720\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3435 - accuracy: 0.9207 - IoU_coef: 0.3435 - val_loss: -0.2724 - val_accuracy: 0.9023 - val_IoU_coef: 0.2724\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3437 - accuracy: 0.9206 - IoU_coef: 0.3437 - val_loss: -0.2731 - val_accuracy: 0.9029 - val_IoU_coef: 0.2731\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3440 - accuracy: 0.9205 - IoU_coef: 0.3440 - val_loss: -0.2732 - val_accuracy: 0.9029 - val_IoU_coef: 0.2732\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3443 - accuracy: 0.9204 - IoU_coef: 0.3443 - val_loss: -0.2731 - val_accuracy: 0.9043 - val_IoU_coef: 0.2731\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3446 - accuracy: 0.9210 - IoU_coef: 0.3446 - val_loss: -0.2736 - val_accuracy: 0.9053 - val_IoU_coef: 0.2736\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3448 - accuracy: 0.9208 - IoU_coef: 0.3448 - val_loss: -0.2741 - val_accuracy: 0.9056 - val_IoU_coef: 0.2741\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3450 - accuracy: 0.9204 - IoU_coef: 0.3450 - val_loss: -0.2744 - val_accuracy: 0.9060 - val_IoU_coef: 0.2744\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3454 - accuracy: 0.9208 - IoU_coef: 0.3454 - val_loss: -0.2739 - val_accuracy: 0.9043 - val_IoU_coef: 0.2739\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3457 - accuracy: 0.9208 - IoU_coef: 0.3457 - val_loss: -0.2738 - val_accuracy: 0.9027 - val_IoU_coef: 0.2738\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3460 - accuracy: 0.9205 - IoU_coef: 0.3460 - val_loss: -0.2741 - val_accuracy: 0.9033 - val_IoU_coef: 0.2741\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3461 - accuracy: 0.9211 - IoU_coef: 0.3461 - val_loss: -0.2741 - val_accuracy: 0.9021 - val_IoU_coef: 0.2741\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3464 - accuracy: 0.9204 - IoU_coef: 0.3464 - val_loss: -0.2747 - val_accuracy: 0.9030 - val_IoU_coef: 0.2747\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.3467 - accuracy: 0.9210 - IoU_coef: 0.3467 - val_loss: -0.2758 - val_accuracy: 0.9041 - val_IoU_coef: 0.2758\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3470 - accuracy: 0.9207 - IoU_coef: 0.3470 - val_loss: -0.2761 - val_accuracy: 0.9039 - val_IoU_coef: 0.2761\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3472 - accuracy: 0.9204 - IoU_coef: 0.3472 - val_loss: -0.2760 - val_accuracy: 0.9051 - val_IoU_coef: 0.2760\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.3475 - accuracy: 0.9210 - IoU_coef: 0.3475 - val_loss: -0.2763 - val_accuracy: 0.9059 - val_IoU_coef: 0.2763\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3479 - accuracy: 0.9209 - IoU_coef: 0.3479 - val_loss: -0.2761 - val_accuracy: 0.9064 - val_IoU_coef: 0.2761\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3481 - accuracy: 0.9207 - IoU_coef: 0.3481 - val_loss: -0.2756 - val_accuracy: 0.9067 - val_IoU_coef: 0.2756\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3484 - accuracy: 0.9211 - IoU_coef: 0.3484 - val_loss: -0.2762 - val_accuracy: 0.9071 - val_IoU_coef: 0.2762\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3487 - accuracy: 0.9206 - IoU_coef: 0.3487 - val_loss: -0.2769 - val_accuracy: 0.9066 - val_IoU_coef: 0.2769\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3489 - accuracy: 0.9207 - IoU_coef: 0.3489 - val_loss: -0.2774 - val_accuracy: 0.9060 - val_IoU_coef: 0.2774\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3493 - accuracy: 0.9212 - IoU_coef: 0.3493 - val_loss: -0.2776 - val_accuracy: 0.9049 - val_IoU_coef: 0.2776\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3496 - accuracy: 0.9209 - IoU_coef: 0.3496 - val_loss: -0.2779 - val_accuracy: 0.9052 - val_IoU_coef: 0.2779\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3498 - accuracy: 0.9212 - IoU_coef: 0.3498 - val_loss: -0.2776 - val_accuracy: 0.9050 - val_IoU_coef: 0.2776\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3500 - accuracy: 0.9210 - IoU_coef: 0.3500 - val_loss: -0.2781 - val_accuracy: 0.9051 - val_IoU_coef: 0.2781\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3503 - accuracy: 0.9207 - IoU_coef: 0.3503 - val_loss: -0.2787 - val_accuracy: 0.9052 - val_IoU_coef: 0.2787\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3505 - accuracy: 0.9211 - IoU_coef: 0.3505 - val_loss: -0.2788 - val_accuracy: 0.9039 - val_IoU_coef: 0.2788\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3509 - accuracy: 0.9210 - IoU_coef: 0.3509 - val_loss: -0.2780 - val_accuracy: 0.9025 - val_IoU_coef: 0.2780\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3510 - accuracy: 0.9210 - IoU_coef: 0.3510 - val_loss: -0.2789 - val_accuracy: 0.9034 - val_IoU_coef: 0.2789\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3514 - accuracy: 0.9210 - IoU_coef: 0.3514 - val_loss: -0.2797 - val_accuracy: 0.9034 - val_IoU_coef: 0.2797\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.3516 - accuracy: 0.9207 - IoU_coef: 0.3516 - val_loss: -0.2803 - val_accuracy: 0.9042 - val_IoU_coef: 0.2803\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3521 - accuracy: 0.9212 - IoU_coef: 0.3521 - val_loss: -0.2807 - val_accuracy: 0.9052 - val_IoU_coef: 0.2807\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3521 - accuracy: 0.9214 - IoU_coef: 0.3521 - val_loss: -0.2812 - val_accuracy: 0.9045 - val_IoU_coef: 0.2812\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3525 - accuracy: 0.9206 - IoU_coef: 0.3525 - val_loss: -0.2820 - val_accuracy: 0.9055 - val_IoU_coef: 0.2820\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3529 - accuracy: 0.9214 - IoU_coef: 0.3529 - val_loss: -0.2823 - val_accuracy: 0.9057 - val_IoU_coef: 0.2823\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3531 - accuracy: 0.9212 - IoU_coef: 0.3531 - val_loss: -0.2821 - val_accuracy: 0.9045 - val_IoU_coef: 0.2821\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3533 - accuracy: 0.9208 - IoU_coef: 0.3533 - val_loss: -0.2825 - val_accuracy: 0.9049 - val_IoU_coef: 0.2825\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3537 - accuracy: 0.9213 - IoU_coef: 0.3537 - val_loss: -0.2831 - val_accuracy: 0.9056 - val_IoU_coef: 0.2831\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3540 - accuracy: 0.9213 - IoU_coef: 0.3540 - val_loss: -0.2833 - val_accuracy: 0.9051 - val_IoU_coef: 0.2833\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3541 - accuracy: 0.9208 - IoU_coef: 0.3541 - val_loss: -0.2837 - val_accuracy: 0.9049 - val_IoU_coef: 0.2837\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3545 - accuracy: 0.9213 - IoU_coef: 0.3545 - val_loss: -0.2835 - val_accuracy: 0.9044 - val_IoU_coef: 0.2835\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3548 - accuracy: 0.9214 - IoU_coef: 0.3548 - val_loss: -0.2829 - val_accuracy: 0.9023 - val_IoU_coef: 0.2829\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3550 - accuracy: 0.9209 - IoU_coef: 0.3550 - val_loss: -0.2835 - val_accuracy: 0.9031 - val_IoU_coef: 0.2835\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3554 - accuracy: 0.9212 - IoU_coef: 0.3554 - val_loss: -0.2841 - val_accuracy: 0.9046 - val_IoU_coef: 0.2841\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3556 - accuracy: 0.9215 - IoU_coef: 0.3556 - val_loss: -0.2842 - val_accuracy: 0.9048 - val_IoU_coef: 0.2842\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3560 - accuracy: 0.9214 - IoU_coef: 0.3560 - val_loss: -0.2846 - val_accuracy: 0.9040 - val_IoU_coef: 0.2846\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3562 - accuracy: 0.9212 - IoU_coef: 0.3562 - val_loss: -0.2851 - val_accuracy: 0.9037 - val_IoU_coef: 0.2851\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3564 - accuracy: 0.9216 - IoU_coef: 0.3564 - val_loss: -0.2856 - val_accuracy: 0.9044 - val_IoU_coef: 0.2856\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3568 - accuracy: 0.9213 - IoU_coef: 0.3568 - val_loss: -0.2858 - val_accuracy: 0.9047 - val_IoU_coef: 0.2858\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3570 - accuracy: 0.9211 - IoU_coef: 0.3570 - val_loss: -0.2862 - val_accuracy: 0.9053 - val_IoU_coef: 0.2862\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3574 - accuracy: 0.9216 - IoU_coef: 0.3574 - val_loss: -0.2871 - val_accuracy: 0.9061 - val_IoU_coef: 0.2871\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3576 - accuracy: 0.9216 - IoU_coef: 0.3576 - val_loss: -0.2874 - val_accuracy: 0.9066 - val_IoU_coef: 0.2874\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3579 - accuracy: 0.9212 - IoU_coef: 0.3579 - val_loss: -0.2877 - val_accuracy: 0.9063 - val_IoU_coef: 0.2877\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3582 - accuracy: 0.9215 - IoU_coef: 0.3582 - val_loss: -0.2878 - val_accuracy: 0.9056 - val_IoU_coef: 0.2878\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3585 - accuracy: 0.9215 - IoU_coef: 0.3585 - val_loss: -0.2879 - val_accuracy: 0.9051 - val_IoU_coef: 0.2879\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3587 - accuracy: 0.9214 - IoU_coef: 0.3587 - val_loss: -0.2881 - val_accuracy: 0.9053 - val_IoU_coef: 0.2881\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3590 - accuracy: 0.9216 - IoU_coef: 0.3590 - val_loss: -0.2885 - val_accuracy: 0.9062 - val_IoU_coef: 0.2885\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3593 - accuracy: 0.9214 - IoU_coef: 0.3593 - val_loss: -0.2888 - val_accuracy: 0.9066 - val_IoU_coef: 0.2888\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3595 - accuracy: 0.9216 - IoU_coef: 0.3595 - val_loss: -0.2889 - val_accuracy: 0.9062 - val_IoU_coef: 0.2889\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3598 - accuracy: 0.9215 - IoU_coef: 0.3598 - val_loss: -0.2894 - val_accuracy: 0.9056 - val_IoU_coef: 0.2894\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3600 - accuracy: 0.9213 - IoU_coef: 0.3600 - val_loss: -0.2892 - val_accuracy: 0.9055 - val_IoU_coef: 0.2892\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3604 - accuracy: 0.9217 - IoU_coef: 0.3604 - val_loss: -0.2888 - val_accuracy: 0.9054 - val_IoU_coef: 0.2888\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3607 - accuracy: 0.9216 - IoU_coef: 0.3607 - val_loss: -0.2891 - val_accuracy: 0.9051 - val_IoU_coef: 0.2891\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3609 - accuracy: 0.9213 - IoU_coef: 0.3609 - val_loss: -0.2896 - val_accuracy: 0.9053 - val_IoU_coef: 0.2896\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3611 - accuracy: 0.9214 - IoU_coef: 0.3611 - val_loss: -0.2904 - val_accuracy: 0.9052 - val_IoU_coef: 0.2904\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3615 - accuracy: 0.9216 - IoU_coef: 0.3615 - val_loss: -0.2906 - val_accuracy: 0.9060 - val_IoU_coef: 0.2906\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3617 - accuracy: 0.9216 - IoU_coef: 0.3617 - val_loss: -0.2906 - val_accuracy: 0.9065 - val_IoU_coef: 0.2906\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3621 - accuracy: 0.9214 - IoU_coef: 0.3621 - val_loss: -0.2908 - val_accuracy: 0.9070 - val_IoU_coef: 0.2908\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3624 - accuracy: 0.9216 - IoU_coef: 0.3624 - val_loss: -0.2906 - val_accuracy: 0.9074 - val_IoU_coef: 0.2906\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3626 - accuracy: 0.9220 - IoU_coef: 0.3626 - val_loss: -0.2905 - val_accuracy: 0.9067 - val_IoU_coef: 0.2905\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3629 - accuracy: 0.9215 - IoU_coef: 0.3629 - val_loss: -0.2909 - val_accuracy: 0.9064 - val_IoU_coef: 0.2909\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3631 - accuracy: 0.9215 - IoU_coef: 0.3631 - val_loss: -0.2917 - val_accuracy: 0.9069 - val_IoU_coef: 0.2917\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3634 - accuracy: 0.9218 - IoU_coef: 0.3634 - val_loss: -0.2930 - val_accuracy: 0.9061 - val_IoU_coef: 0.2930\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3637 - accuracy: 0.9215 - IoU_coef: 0.3637 - val_loss: -0.2932 - val_accuracy: 0.9055 - val_IoU_coef: 0.2932\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3640 - accuracy: 0.9218 - IoU_coef: 0.3640 - val_loss: -0.2927 - val_accuracy: 0.9042 - val_IoU_coef: 0.2927\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3641 - accuracy: 0.9214 - IoU_coef: 0.3641 - val_loss: -0.2928 - val_accuracy: 0.9044 - val_IoU_coef: 0.2928\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3645 - accuracy: 0.9218 - IoU_coef: 0.3645 - val_loss: -0.2933 - val_accuracy: 0.9054 - val_IoU_coef: 0.2933\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3648 - accuracy: 0.9218 - IoU_coef: 0.3648 - val_loss: -0.2934 - val_accuracy: 0.9056 - val_IoU_coef: 0.2934\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3651 - accuracy: 0.9215 - IoU_coef: 0.3651 - val_loss: -0.2934 - val_accuracy: 0.9053 - val_IoU_coef: 0.2934\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3654 - accuracy: 0.9218 - IoU_coef: 0.3654 - val_loss: -0.2935 - val_accuracy: 0.9048 - val_IoU_coef: 0.2935\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3655 - accuracy: 0.9222 - IoU_coef: 0.3655 - val_loss: -0.2938 - val_accuracy: 0.9043 - val_IoU_coef: 0.2938\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3658 - accuracy: 0.9213 - IoU_coef: 0.3658 - val_loss: -0.2949 - val_accuracy: 0.9042 - val_IoU_coef: 0.2949\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3662 - accuracy: 0.9216 - IoU_coef: 0.3662 - val_loss: -0.2958 - val_accuracy: 0.9045 - val_IoU_coef: 0.2958\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3666 - accuracy: 0.9222 - IoU_coef: 0.3666 - val_loss: -0.2958 - val_accuracy: 0.9047 - val_IoU_coef: 0.2958\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3667 - accuracy: 0.9218 - IoU_coef: 0.3667 - val_loss: -0.2962 - val_accuracy: 0.9059 - val_IoU_coef: 0.2962\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3670 - accuracy: 0.9216 - IoU_coef: 0.3670 - val_loss: -0.2972 - val_accuracy: 0.9067 - val_IoU_coef: 0.2972\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3673 - accuracy: 0.9219 - IoU_coef: 0.3673 - val_loss: -0.2980 - val_accuracy: 0.9066 - val_IoU_coef: 0.2980\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3676 - accuracy: 0.9219 - IoU_coef: 0.3676 - val_loss: -0.2972 - val_accuracy: 0.9066 - val_IoU_coef: 0.2972\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3679 - accuracy: 0.9219 - IoU_coef: 0.3679 - val_loss: -0.2973 - val_accuracy: 0.9061 - val_IoU_coef: 0.2973\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3681 - accuracy: 0.9219 - IoU_coef: 0.3681 - val_loss: -0.2984 - val_accuracy: 0.9057 - val_IoU_coef: 0.2984\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3684 - accuracy: 0.9216 - IoU_coef: 0.3684 - val_loss: -0.2992 - val_accuracy: 0.9067 - val_IoU_coef: 0.2992\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3687 - accuracy: 0.9221 - IoU_coef: 0.3687 - val_loss: -0.2989 - val_accuracy: 0.9067 - val_IoU_coef: 0.2989\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3689 - accuracy: 0.9220 - IoU_coef: 0.3689 - val_loss: -0.2996 - val_accuracy: 0.9063 - val_IoU_coef: 0.2996\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3691 - accuracy: 0.9214 - IoU_coef: 0.3691 - val_loss: -0.3003 - val_accuracy: 0.9070 - val_IoU_coef: 0.3003\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3693 - accuracy: 0.9223 - IoU_coef: 0.3693 - val_loss: -0.3003 - val_accuracy: 0.9045 - val_IoU_coef: 0.3003\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3698 - accuracy: 0.9218 - IoU_coef: 0.3698 - val_loss: -0.3002 - val_accuracy: 0.9051 - val_IoU_coef: 0.3002\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3702 - accuracy: 0.9219 - IoU_coef: 0.3702 - val_loss: -0.3008 - val_accuracy: 0.9069 - val_IoU_coef: 0.3008\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3702 - accuracy: 0.9224 - IoU_coef: 0.3702 - val_loss: -0.3021 - val_accuracy: 0.9048 - val_IoU_coef: 0.3021\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3705 - accuracy: 0.9213 - IoU_coef: 0.3705 - val_loss: -0.3022 - val_accuracy: 0.9053 - val_IoU_coef: 0.3022\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3710 - accuracy: 0.9221 - IoU_coef: 0.3710 - val_loss: -0.3014 - val_accuracy: 0.9060 - val_IoU_coef: 0.3014\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3710 - accuracy: 0.9224 - IoU_coef: 0.3710 - val_loss: -0.3026 - val_accuracy: 0.9044 - val_IoU_coef: 0.3026\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3714 - accuracy: 0.9214 - IoU_coef: 0.3714 - val_loss: -0.3041 - val_accuracy: 0.9053 - val_IoU_coef: 0.3041\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3718 - accuracy: 0.9219 - IoU_coef: 0.3718 - val_loss: -0.3044 - val_accuracy: 0.9071 - val_IoU_coef: 0.3044\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3719 - accuracy: 0.9227 - IoU_coef: 0.3719 - val_loss: -0.3042 - val_accuracy: 0.9065 - val_IoU_coef: 0.3042\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3722 - accuracy: 0.9213 - IoU_coef: 0.3722 - val_loss: -0.3040 - val_accuracy: 0.9080 - val_IoU_coef: 0.3040\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3725 - accuracy: 0.9216 - IoU_coef: 0.3725 - val_loss: -0.3042 - val_accuracy: 0.9095 - val_IoU_coef: 0.3042\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3727 - accuracy: 0.9227 - IoU_coef: 0.3727 - val_loss: -0.3050 - val_accuracy: 0.9087 - val_IoU_coef: 0.3050\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3729 - accuracy: 0.9217 - IoU_coef: 0.3729 - val_loss: -0.3055 - val_accuracy: 0.9078 - val_IoU_coef: 0.3055\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3733 - accuracy: 0.9215 - IoU_coef: 0.3733 - val_loss: -0.3051 - val_accuracy: 0.9077 - val_IoU_coef: 0.3051\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3734 - accuracy: 0.9226 - IoU_coef: 0.3734 - val_loss: -0.3054 - val_accuracy: 0.9070 - val_IoU_coef: 0.3054\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3739 - accuracy: 0.9220 - IoU_coef: 0.3739 - val_loss: -0.3061 - val_accuracy: 0.9071 - val_IoU_coef: 0.3061\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.3740 - accuracy: 0.9216 - IoU_coef: 0.3740 - val_loss: -0.3067 - val_accuracy: 0.9077 - val_IoU_coef: 0.3067\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.3744 - accuracy: 0.9224 - IoU_coef: 0.3744 - val_loss: -0.3068 - val_accuracy: 0.9076 - val_IoU_coef: 0.3068\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3749 - accuracy: 0.9222 - IoU_coef: 0.3749 - val_loss: -0.3063 - val_accuracy: 0.9061 - val_IoU_coef: 0.3063\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3751 - accuracy: 0.9218 - IoU_coef: 0.3751 - val_loss: -0.3066 - val_accuracy: 0.9052 - val_IoU_coef: 0.3066\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3754 - accuracy: 0.9223 - IoU_coef: 0.3754 - val_loss: -0.3073 - val_accuracy: 0.9050 - val_IoU_coef: 0.3073\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3757 - accuracy: 0.9225 - IoU_coef: 0.3757 - val_loss: -0.3077 - val_accuracy: 0.9050 - val_IoU_coef: 0.3077\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3760 - accuracy: 0.9220 - IoU_coef: 0.3760 - val_loss: -0.3076 - val_accuracy: 0.9055 - val_IoU_coef: 0.3076\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3764 - accuracy: 0.9220 - IoU_coef: 0.3764 - val_loss: -0.3079 - val_accuracy: 0.9065 - val_IoU_coef: 0.3079\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3764 - accuracy: 0.9226 - IoU_coef: 0.3764 - val_loss: -0.3088 - val_accuracy: 0.9065 - val_IoU_coef: 0.3088\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3768 - accuracy: 0.9222 - IoU_coef: 0.3768 - val_loss: -0.3089 - val_accuracy: 0.9066 - val_IoU_coef: 0.3089\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.3771 - accuracy: 0.9221 - IoU_coef: 0.3771 - val_loss: -0.3092 - val_accuracy: 0.9075 - val_IoU_coef: 0.3092\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3773 - accuracy: 0.9225 - IoU_coef: 0.3773 - val_loss: -0.3099 - val_accuracy: 0.9081 - val_IoU_coef: 0.3099\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3777 - accuracy: 0.9224 - IoU_coef: 0.3777 - val_loss: -0.3100 - val_accuracy: 0.9082 - val_IoU_coef: 0.3100\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3780 - accuracy: 0.9220 - IoU_coef: 0.3780 - val_loss: -0.3100 - val_accuracy: 0.9080 - val_IoU_coef: 0.3100\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3782 - accuracy: 0.9221 - IoU_coef: 0.3782 - val_loss: -0.3103 - val_accuracy: 0.9073 - val_IoU_coef: 0.3103\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3785 - accuracy: 0.9226 - IoU_coef: 0.3785 - val_loss: -0.3108 - val_accuracy: 0.9065 - val_IoU_coef: 0.3108\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3788 - accuracy: 0.9221 - IoU_coef: 0.3788 - val_loss: -0.3109 - val_accuracy: 0.9062 - val_IoU_coef: 0.3109\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3791 - accuracy: 0.9223 - IoU_coef: 0.3791 - val_loss: -0.3103 - val_accuracy: 0.9060 - val_IoU_coef: 0.3103\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3793 - accuracy: 0.9226 - IoU_coef: 0.3793 - val_loss: -0.3107 - val_accuracy: 0.9057 - val_IoU_coef: 0.3107\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3796 - accuracy: 0.9220 - IoU_coef: 0.3796 - val_loss: -0.3111 - val_accuracy: 0.9071 - val_IoU_coef: 0.3111\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3800 - accuracy: 0.9223 - IoU_coef: 0.3800 - val_loss: -0.3107 - val_accuracy: 0.9074 - val_IoU_coef: 0.3107\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3801 - accuracy: 0.9228 - IoU_coef: 0.3801 - val_loss: -0.3111 - val_accuracy: 0.9061 - val_IoU_coef: 0.3111\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3804 - accuracy: 0.9220 - IoU_coef: 0.3804 - val_loss: -0.3122 - val_accuracy: 0.9064 - val_IoU_coef: 0.3122\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3808 - accuracy: 0.9223 - IoU_coef: 0.3808 - val_loss: -0.3120 - val_accuracy: 0.9068 - val_IoU_coef: 0.3120\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3809 - accuracy: 0.9228 - IoU_coef: 0.3809 - val_loss: -0.3126 - val_accuracy: 0.9059 - val_IoU_coef: 0.3126\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3812 - accuracy: 0.9222 - IoU_coef: 0.3812 - val_loss: -0.3126 - val_accuracy: 0.9041 - val_IoU_coef: 0.3126\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3816 - accuracy: 0.9219 - IoU_coef: 0.3816 - val_loss: -0.3127 - val_accuracy: 0.9049 - val_IoU_coef: 0.3127\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3819 - accuracy: 0.9229 - IoU_coef: 0.3819 - val_loss: -0.3131 - val_accuracy: 0.9047 - val_IoU_coef: 0.3131\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3821 - accuracy: 0.9225 - IoU_coef: 0.3821 - val_loss: -0.3131 - val_accuracy: 0.9039 - val_IoU_coef: 0.3131\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: -0.3824 - accuracy: 0.9220 - IoU_coef: 0.3824 - val_loss: -0.3132 - val_accuracy: 0.9044 - val_IoU_coef: 0.3132\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.3827 - accuracy: 0.9225 - IoU_coef: 0.3827 - val_loss: -0.3136 - val_accuracy: 0.9048 - val_IoU_coef: 0.3136\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3829 - accuracy: 0.9229 - IoU_coef: 0.3829 - val_loss: -0.3141 - val_accuracy: 0.9046 - val_IoU_coef: 0.3141\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3833 - accuracy: 0.9222 - IoU_coef: 0.3833 - val_loss: -0.3146 - val_accuracy: 0.9055 - val_IoU_coef: 0.3146\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3835 - accuracy: 0.9223 - IoU_coef: 0.3835 - val_loss: -0.3154 - val_accuracy: 0.9062 - val_IoU_coef: 0.3154\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3837 - accuracy: 0.9228 - IoU_coef: 0.3837 - val_loss: -0.3151 - val_accuracy: 0.9051 - val_IoU_coef: 0.3151\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3841 - accuracy: 0.9223 - IoU_coef: 0.3841 - val_loss: -0.3152 - val_accuracy: 0.9059 - val_IoU_coef: 0.3152\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3844 - accuracy: 0.9225 - IoU_coef: 0.3844 - val_loss: -0.3163 - val_accuracy: 0.9072 - val_IoU_coef: 0.3163\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3846 - accuracy: 0.9228 - IoU_coef: 0.3846 - val_loss: -0.3164 - val_accuracy: 0.9062 - val_IoU_coef: 0.3164\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3849 - accuracy: 0.9224 - IoU_coef: 0.3849 - val_loss: -0.3168 - val_accuracy: 0.9052 - val_IoU_coef: 0.3168\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3854 - accuracy: 0.9222 - IoU_coef: 0.3854 - val_loss: -0.3171 - val_accuracy: 0.9061 - val_IoU_coef: 0.3171\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3854 - accuracy: 0.9228 - IoU_coef: 0.3854 - val_loss: -0.3171 - val_accuracy: 0.9059 - val_IoU_coef: 0.3171\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3857 - accuracy: 0.9228 - IoU_coef: 0.3857 - val_loss: -0.3183 - val_accuracy: 0.9053 - val_IoU_coef: 0.3183\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3861 - accuracy: 0.9222 - IoU_coef: 0.3861 - val_loss: -0.3184 - val_accuracy: 0.9057 - val_IoU_coef: 0.3184\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3865 - accuracy: 0.9226 - IoU_coef: 0.3865 - val_loss: -0.3181 - val_accuracy: 0.9063 - val_IoU_coef: 0.3181\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3865 - accuracy: 0.9228 - IoU_coef: 0.3865 - val_loss: -0.3190 - val_accuracy: 0.9064 - val_IoU_coef: 0.3190\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3870 - accuracy: 0.9226 - IoU_coef: 0.3870 - val_loss: -0.3193 - val_accuracy: 0.9066 - val_IoU_coef: 0.3193\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3872 - accuracy: 0.9226 - IoU_coef: 0.3872 - val_loss: -0.3188 - val_accuracy: 0.9065 - val_IoU_coef: 0.3188\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3872 - accuracy: 0.9228 - IoU_coef: 0.3872 - val_loss: -0.3190 - val_accuracy: 0.9056 - val_IoU_coef: 0.3190\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3877 - accuracy: 0.9224 - IoU_coef: 0.3877 - val_loss: -0.3196 - val_accuracy: 0.9063 - val_IoU_coef: 0.3196\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3881 - accuracy: 0.9227 - IoU_coef: 0.3881 - val_loss: -0.3203 - val_accuracy: 0.9068 - val_IoU_coef: 0.3203\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3883 - accuracy: 0.9229 - IoU_coef: 0.3883 - val_loss: -0.3207 - val_accuracy: 0.9064 - val_IoU_coef: 0.3207\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3887 - accuracy: 0.9225 - IoU_coef: 0.3887 - val_loss: -0.3208 - val_accuracy: 0.9067 - val_IoU_coef: 0.3208\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: -0.3890 - accuracy: 0.9226 - IoU_coef: 0.3890 - val_loss: -0.3207 - val_accuracy: 0.9076 - val_IoU_coef: 0.3207\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3891 - accuracy: 0.9229 - IoU_coef: 0.3891 - val_loss: -0.3215 - val_accuracy: 0.9077 - val_IoU_coef: 0.3215\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3895 - accuracy: 0.9227 - IoU_coef: 0.3895 - val_loss: -0.3223 - val_accuracy: 0.9074 - val_IoU_coef: 0.3223\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3899 - accuracy: 0.9225 - IoU_coef: 0.3899 - val_loss: -0.3222 - val_accuracy: 0.9069 - val_IoU_coef: 0.3222\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3900 - accuracy: 0.9228 - IoU_coef: 0.3900 - val_loss: -0.3221 - val_accuracy: 0.9067 - val_IoU_coef: 0.3221\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3903 - accuracy: 0.9229 - IoU_coef: 0.3903 - val_loss: -0.3225 - val_accuracy: 0.9072 - val_IoU_coef: 0.3225\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3907 - accuracy: 0.9227 - IoU_coef: 0.3907 - val_loss: -0.3228 - val_accuracy: 0.9080 - val_IoU_coef: 0.3228\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3910 - accuracy: 0.9227 - IoU_coef: 0.3910 - val_loss: -0.3230 - val_accuracy: 0.9083 - val_IoU_coef: 0.3230\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3912 - accuracy: 0.9229 - IoU_coef: 0.3912 - val_loss: -0.3227 - val_accuracy: 0.9085 - val_IoU_coef: 0.3227\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3915 - accuracy: 0.9229 - IoU_coef: 0.3915 - val_loss: -0.3227 - val_accuracy: 0.9088 - val_IoU_coef: 0.3227\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3917 - accuracy: 0.9227 - IoU_coef: 0.3917 - val_loss: -0.3230 - val_accuracy: 0.9092 - val_IoU_coef: 0.3230\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3921 - accuracy: 0.9228 - IoU_coef: 0.3921 - val_loss: -0.3237 - val_accuracy: 0.9091 - val_IoU_coef: 0.3237\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3922 - accuracy: 0.9229 - IoU_coef: 0.3922 - val_loss: -0.3244 - val_accuracy: 0.9087 - val_IoU_coef: 0.3244\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3926 - accuracy: 0.9228 - IoU_coef: 0.3926 - val_loss: -0.3245 - val_accuracy: 0.9082 - val_IoU_coef: 0.3245\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3929 - accuracy: 0.9228 - IoU_coef: 0.3929 - val_loss: -0.3252 - val_accuracy: 0.9077 - val_IoU_coef: 0.3252\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3931 - accuracy: 0.9228 - IoU_coef: 0.3931 - val_loss: -0.3265 - val_accuracy: 0.9072 - val_IoU_coef: 0.3265\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3934 - accuracy: 0.9228 - IoU_coef: 0.3934 - val_loss: -0.3269 - val_accuracy: 0.9071 - val_IoU_coef: 0.3269\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.3937 - accuracy: 0.9230 - IoU_coef: 0.3937 - val_loss: -0.3262 - val_accuracy: 0.9073 - val_IoU_coef: 0.3262\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3940 - accuracy: 0.9229 - IoU_coef: 0.3940 - val_loss: -0.3269 - val_accuracy: 0.9076 - val_IoU_coef: 0.3269\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.3944 - accuracy: 0.9228 - IoU_coef: 0.3944 - val_loss: -0.3272 - val_accuracy: 0.9083 - val_IoU_coef: 0.3272\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.3945 - accuracy: 0.9230 - IoU_coef: 0.3945 - val_loss: -0.3268 - val_accuracy: 0.9084 - val_IoU_coef: 0.3268\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.3949 - accuracy: 0.9231 - IoU_coef: 0.3949 - val_loss: -0.3265 - val_accuracy: 0.9076 - val_IoU_coef: 0.3265\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3950 - accuracy: 0.9226 - IoU_coef: 0.3950 - val_loss: -0.3266 - val_accuracy: 0.9076 - val_IoU_coef: 0.3266\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3954 - accuracy: 0.9232 - IoU_coef: 0.3954 - val_loss: -0.3269 - val_accuracy: 0.9077 - val_IoU_coef: 0.3269\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.3957 - accuracy: 0.9233 - IoU_coef: 0.3957 - val_loss: -0.3276 - val_accuracy: 0.9072 - val_IoU_coef: 0.3276\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.3959 - accuracy: 0.9227 - IoU_coef: 0.3959 - val_loss: -0.3281 - val_accuracy: 0.9069 - val_IoU_coef: 0.3281\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3963 - accuracy: 0.9228 - IoU_coef: 0.3963 - val_loss: -0.3286 - val_accuracy: 0.9074 - val_IoU_coef: 0.3286\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.3966 - accuracy: 0.9234 - IoU_coef: 0.3966 - val_loss: -0.3291 - val_accuracy: 0.9068 - val_IoU_coef: 0.3291\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3970 - accuracy: 0.9229 - IoU_coef: 0.3970 - val_loss: -0.3290 - val_accuracy: 0.9071 - val_IoU_coef: 0.3290\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.3972 - accuracy: 0.9229 - IoU_coef: 0.3972 - val_loss: -0.3287 - val_accuracy: 0.9074 - val_IoU_coef: 0.3287\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3974 - accuracy: 0.9232 - IoU_coef: 0.3974 - val_loss: -0.3291 - val_accuracy: 0.9072 - val_IoU_coef: 0.3291\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.3978 - accuracy: 0.9231 - IoU_coef: 0.3978 - val_loss: -0.3284 - val_accuracy: 0.9064 - val_IoU_coef: 0.3284\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3981 - accuracy: 0.9231 - IoU_coef: 0.3981 - val_loss: -0.3277 - val_accuracy: 0.9060 - val_IoU_coef: 0.3277\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3980 - accuracy: 0.9231 - IoU_coef: 0.3980 - val_loss: -0.3292 - val_accuracy: 0.9055 - val_IoU_coef: 0.3292\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.3984 - accuracy: 0.9228 - IoU_coef: 0.3984 - val_loss: -0.3299 - val_accuracy: 0.9060 - val_IoU_coef: 0.3299\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.3988 - accuracy: 0.9230 - IoU_coef: 0.3988 - val_loss: -0.3304 - val_accuracy: 0.9069 - val_IoU_coef: 0.3304\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3990 - accuracy: 0.9233 - IoU_coef: 0.3990 - val_loss: -0.3309 - val_accuracy: 0.9063 - val_IoU_coef: 0.3309\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3994 - accuracy: 0.9229 - IoU_coef: 0.3994 - val_loss: -0.3309 - val_accuracy: 0.9061 - val_IoU_coef: 0.3309\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.3995 - accuracy: 0.9230 - IoU_coef: 0.3995 - val_loss: -0.3308 - val_accuracy: 0.9069 - val_IoU_coef: 0.3308\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.3998 - accuracy: 0.9234 - IoU_coef: 0.3998 - val_loss: -0.3309 - val_accuracy: 0.9069 - val_IoU_coef: 0.3309\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4001 - accuracy: 0.9229 - IoU_coef: 0.4001 - val_loss: -0.3316 - val_accuracy: 0.9070 - val_IoU_coef: 0.3316\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4005 - accuracy: 0.9228 - IoU_coef: 0.4005 - val_loss: -0.3320 - val_accuracy: 0.9080 - val_IoU_coef: 0.3320\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4007 - accuracy: 0.9234 - IoU_coef: 0.4007 - val_loss: -0.3323 - val_accuracy: 0.9077 - val_IoU_coef: 0.3323\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4011 - accuracy: 0.9232 - IoU_coef: 0.4011 - val_loss: -0.3329 - val_accuracy: 0.9071 - val_IoU_coef: 0.3329\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4013 - accuracy: 0.9228 - IoU_coef: 0.4013 - val_loss: -0.3326 - val_accuracy: 0.9077 - val_IoU_coef: 0.3326\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4014 - accuracy: 0.9234 - IoU_coef: 0.4014 - val_loss: -0.3324 - val_accuracy: 0.9078 - val_IoU_coef: 0.3324\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4017 - accuracy: 0.9231 - IoU_coef: 0.4017 - val_loss: -0.3328 - val_accuracy: 0.9079 - val_IoU_coef: 0.3328\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4021 - accuracy: 0.9228 - IoU_coef: 0.4021 - val_loss: -0.3331 - val_accuracy: 0.9089 - val_IoU_coef: 0.3331\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4024 - accuracy: 0.9234 - IoU_coef: 0.4024 - val_loss: -0.3334 - val_accuracy: 0.9093 - val_IoU_coef: 0.3334\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.4027 - accuracy: 0.9233 - IoU_coef: 0.4027 - val_loss: -0.3342 - val_accuracy: 0.9086 - val_IoU_coef: 0.3342\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4029 - accuracy: 0.9228 - IoU_coef: 0.4029 - val_loss: -0.3350 - val_accuracy: 0.9088 - val_IoU_coef: 0.3350\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4031 - accuracy: 0.9233 - IoU_coef: 0.4031 - val_loss: -0.3352 - val_accuracy: 0.9079 - val_IoU_coef: 0.3352\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4035 - accuracy: 0.9234 - IoU_coef: 0.4035 - val_loss: -0.3343 - val_accuracy: 0.9064 - val_IoU_coef: 0.3343\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4038 - accuracy: 0.9229 - IoU_coef: 0.4038 - val_loss: -0.3344 - val_accuracy: 0.9067 - val_IoU_coef: 0.3344\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4042 - accuracy: 0.9234 - IoU_coef: 0.4042 - val_loss: -0.3351 - val_accuracy: 0.9077 - val_IoU_coef: 0.3351\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4044 - accuracy: 0.9235 - IoU_coef: 0.4044 - val_loss: -0.3359 - val_accuracy: 0.9077 - val_IoU_coef: 0.3359\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4046 - accuracy: 0.9229 - IoU_coef: 0.4046 - val_loss: -0.3364 - val_accuracy: 0.9082 - val_IoU_coef: 0.3364\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4049 - accuracy: 0.9231 - IoU_coef: 0.4049 - val_loss: -0.3365 - val_accuracy: 0.9080 - val_IoU_coef: 0.3365\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4053 - accuracy: 0.9236 - IoU_coef: 0.4053 - val_loss: -0.3363 - val_accuracy: 0.9067 - val_IoU_coef: 0.3363\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.4056 - accuracy: 0.9233 - IoU_coef: 0.4056 - val_loss: -0.3363 - val_accuracy: 0.9065 - val_IoU_coef: 0.3363\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4057 - accuracy: 0.9232 - IoU_coef: 0.4057 - val_loss: -0.3361 - val_accuracy: 0.9072 - val_IoU_coef: 0.3361\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4060 - accuracy: 0.9234 - IoU_coef: 0.4060 - val_loss: -0.3365 - val_accuracy: 0.9073 - val_IoU_coef: 0.3365\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4062 - accuracy: 0.9233 - IoU_coef: 0.4062 - val_loss: -0.3367 - val_accuracy: 0.9071 - val_IoU_coef: 0.3367\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4063 - accuracy: 0.9230 - IoU_coef: 0.4063 - val_loss: -0.3368 - val_accuracy: 0.9065 - val_IoU_coef: 0.3368\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4069 - accuracy: 0.9233 - IoU_coef: 0.4069 - val_loss: -0.3376 - val_accuracy: 0.9067 - val_IoU_coef: 0.3376\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4071 - accuracy: 0.9236 - IoU_coef: 0.4071 - val_loss: -0.3378 - val_accuracy: 0.9064 - val_IoU_coef: 0.3378\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4073 - accuracy: 0.9231 - IoU_coef: 0.4073 - val_loss: -0.3374 - val_accuracy: 0.9066 - val_IoU_coef: 0.3374\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4078 - accuracy: 0.9231 - IoU_coef: 0.4078 - val_loss: -0.3374 - val_accuracy: 0.9076 - val_IoU_coef: 0.3374\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4080 - accuracy: 0.9236 - IoU_coef: 0.4080 - val_loss: -0.3382 - val_accuracy: 0.9070 - val_IoU_coef: 0.3382\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4083 - accuracy: 0.9233 - IoU_coef: 0.4083 - val_loss: -0.3383 - val_accuracy: 0.9067 - val_IoU_coef: 0.3383\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4086 - accuracy: 0.9233 - IoU_coef: 0.4086 - val_loss: -0.3374 - val_accuracy: 0.9062 - val_IoU_coef: 0.3374\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4087 - accuracy: 0.9233 - IoU_coef: 0.4087 - val_loss: -0.3375 - val_accuracy: 0.9052 - val_IoU_coef: 0.3375\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.4091 - accuracy: 0.9232 - IoU_coef: 0.4091 - val_loss: -0.3383 - val_accuracy: 0.9056 - val_IoU_coef: 0.3383\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4093 - accuracy: 0.9232 - IoU_coef: 0.4093 - val_loss: -0.3385 - val_accuracy: 0.9072 - val_IoU_coef: 0.3385\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4096 - accuracy: 0.9236 - IoU_coef: 0.4096 - val_loss: -0.3391 - val_accuracy: 0.9078 - val_IoU_coef: 0.3391\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4098 - accuracy: 0.9233 - IoU_coef: 0.4098 - val_loss: -0.3395 - val_accuracy: 0.9073 - val_IoU_coef: 0.3395\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4103 - accuracy: 0.9230 - IoU_coef: 0.4103 - val_loss: -0.3399 - val_accuracy: 0.9080 - val_IoU_coef: 0.3399\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4105 - accuracy: 0.9237 - IoU_coef: 0.4105 - val_loss: -0.3400 - val_accuracy: 0.9079 - val_IoU_coef: 0.3400\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4108 - accuracy: 0.9236 - IoU_coef: 0.4108 - val_loss: -0.3407 - val_accuracy: 0.9075 - val_IoU_coef: 0.3407\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4110 - accuracy: 0.9231 - IoU_coef: 0.4110 - val_loss: -0.3415 - val_accuracy: 0.9081 - val_IoU_coef: 0.3415\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4113 - accuracy: 0.9234 - IoU_coef: 0.4113 - val_loss: -0.3417 - val_accuracy: 0.9080 - val_IoU_coef: 0.3417\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4117 - accuracy: 0.9238 - IoU_coef: 0.4117 - val_loss: -0.3418 - val_accuracy: 0.9073 - val_IoU_coef: 0.3418\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4118 - accuracy: 0.9232 - IoU_coef: 0.4118 - val_loss: -0.3432 - val_accuracy: 0.9085 - val_IoU_coef: 0.3432\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4122 - accuracy: 0.9234 - IoU_coef: 0.4122 - val_loss: -0.3438 - val_accuracy: 0.9095 - val_IoU_coef: 0.3438\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4125 - accuracy: 0.9235 - IoU_coef: 0.4125 - val_loss: -0.3435 - val_accuracy: 0.9091 - val_IoU_coef: 0.3435\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4128 - accuracy: 0.9234 - IoU_coef: 0.4128 - val_loss: -0.3435 - val_accuracy: 0.9082 - val_IoU_coef: 0.3435\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4130 - accuracy: 0.9234 - IoU_coef: 0.4130 - val_loss: -0.3433 - val_accuracy: 0.9076 - val_IoU_coef: 0.3433\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4134 - accuracy: 0.9238 - IoU_coef: 0.4134 - val_loss: -0.3442 - val_accuracy: 0.9084 - val_IoU_coef: 0.3442\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4136 - accuracy: 0.9236 - IoU_coef: 0.4136 - val_loss: -0.3445 - val_accuracy: 0.9085 - val_IoU_coef: 0.3445\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4137 - accuracy: 0.9232 - IoU_coef: 0.4137 - val_loss: -0.3440 - val_accuracy: 0.9091 - val_IoU_coef: 0.3440\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4141 - accuracy: 0.9237 - IoU_coef: 0.4141 - val_loss: -0.3441 - val_accuracy: 0.9091 - val_IoU_coef: 0.3441\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4145 - accuracy: 0.9237 - IoU_coef: 0.4145 - val_loss: -0.3448 - val_accuracy: 0.9085 - val_IoU_coef: 0.3448\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4147 - accuracy: 0.9233 - IoU_coef: 0.4147 - val_loss: -0.3448 - val_accuracy: 0.9089 - val_IoU_coef: 0.3448\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4151 - accuracy: 0.9236 - IoU_coef: 0.4151 - val_loss: -0.3447 - val_accuracy: 0.9091 - val_IoU_coef: 0.3447\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4153 - accuracy: 0.9238 - IoU_coef: 0.4153 - val_loss: -0.3451 - val_accuracy: 0.9086 - val_IoU_coef: 0.3451\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4156 - accuracy: 0.9234 - IoU_coef: 0.4156 - val_loss: -0.3455 - val_accuracy: 0.9085 - val_IoU_coef: 0.3455\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4157 - accuracy: 0.9235 - IoU_coef: 0.4157 - val_loss: -0.3460 - val_accuracy: 0.9087 - val_IoU_coef: 0.3460\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4161 - accuracy: 0.9237 - IoU_coef: 0.4161 - val_loss: -0.3460 - val_accuracy: 0.9081 - val_IoU_coef: 0.3460\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4165 - accuracy: 0.9236 - IoU_coef: 0.4165 - val_loss: -0.3458 - val_accuracy: 0.9074 - val_IoU_coef: 0.3458\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4166 - accuracy: 0.9235 - IoU_coef: 0.4166 - val_loss: -0.3451 - val_accuracy: 0.9066 - val_IoU_coef: 0.3451\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4170 - accuracy: 0.9236 - IoU_coef: 0.4170 - val_loss: -0.3451 - val_accuracy: 0.9067 - val_IoU_coef: 0.3451\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4172 - accuracy: 0.9237 - IoU_coef: 0.4172 - val_loss: -0.3460 - val_accuracy: 0.9072 - val_IoU_coef: 0.3460\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4175 - accuracy: 0.9236 - IoU_coef: 0.4175 - val_loss: -0.3463 - val_accuracy: 0.9073 - val_IoU_coef: 0.3463\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4178 - accuracy: 0.9235 - IoU_coef: 0.4178 - val_loss: -0.3460 - val_accuracy: 0.9069 - val_IoU_coef: 0.3460\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4180 - accuracy: 0.9236 - IoU_coef: 0.4180 - val_loss: -0.3457 - val_accuracy: 0.9070 - val_IoU_coef: 0.3457\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4183 - accuracy: 0.9237 - IoU_coef: 0.4183 - val_loss: -0.3463 - val_accuracy: 0.9076 - val_IoU_coef: 0.3463\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4186 - accuracy: 0.9236 - IoU_coef: 0.4186 - val_loss: -0.3471 - val_accuracy: 0.9088 - val_IoU_coef: 0.3471\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4190 - accuracy: 0.9236 - IoU_coef: 0.4190 - val_loss: -0.3474 - val_accuracy: 0.9087 - val_IoU_coef: 0.3474\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4192 - accuracy: 0.9237 - IoU_coef: 0.4192 - val_loss: -0.3471 - val_accuracy: 0.9076 - val_IoU_coef: 0.3471\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4196 - accuracy: 0.9237 - IoU_coef: 0.4196 - val_loss: -0.3473 - val_accuracy: 0.9075 - val_IoU_coef: 0.3473\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4198 - accuracy: 0.9238 - IoU_coef: 0.4198 - val_loss: -0.3480 - val_accuracy: 0.9079 - val_IoU_coef: 0.3480\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4201 - accuracy: 0.9237 - IoU_coef: 0.4201 - val_loss: -0.3479 - val_accuracy: 0.9081 - val_IoU_coef: 0.3479\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4204 - accuracy: 0.9237 - IoU_coef: 0.4204 - val_loss: -0.3474 - val_accuracy: 0.9083 - val_IoU_coef: 0.3474\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4205 - accuracy: 0.9237 - IoU_coef: 0.4205 - val_loss: -0.3477 - val_accuracy: 0.9086 - val_IoU_coef: 0.3477\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4209 - accuracy: 0.9237 - IoU_coef: 0.4209 - val_loss: -0.3480 - val_accuracy: 0.9087 - val_IoU_coef: 0.3480\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4211 - accuracy: 0.9237 - IoU_coef: 0.4211 - val_loss: -0.3480 - val_accuracy: 0.9077 - val_IoU_coef: 0.3480\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4214 - accuracy: 0.9236 - IoU_coef: 0.4214 - val_loss: -0.3487 - val_accuracy: 0.9076 - val_IoU_coef: 0.3487\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4218 - accuracy: 0.9238 - IoU_coef: 0.4218 - val_loss: -0.3493 - val_accuracy: 0.9078 - val_IoU_coef: 0.3493\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4220 - accuracy: 0.9238 - IoU_coef: 0.4220 - val_loss: -0.3500 - val_accuracy: 0.9082 - val_IoU_coef: 0.3500\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4223 - accuracy: 0.9237 - IoU_coef: 0.4223 - val_loss: -0.3502 - val_accuracy: 0.9088 - val_IoU_coef: 0.3502\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4226 - accuracy: 0.9239 - IoU_coef: 0.4226 - val_loss: -0.3502 - val_accuracy: 0.9086 - val_IoU_coef: 0.3502\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4227 - accuracy: 0.9237 - IoU_coef: 0.4227 - val_loss: -0.3498 - val_accuracy: 0.9082 - val_IoU_coef: 0.3498\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4232 - accuracy: 0.9238 - IoU_coef: 0.4232 - val_loss: -0.3501 - val_accuracy: 0.9085 - val_IoU_coef: 0.3501\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4235 - accuracy: 0.9240 - IoU_coef: 0.4235 - val_loss: -0.3500 - val_accuracy: 0.9079 - val_IoU_coef: 0.3500\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4236 - accuracy: 0.9235 - IoU_coef: 0.4236 - val_loss: -0.3500 - val_accuracy: 0.9086 - val_IoU_coef: 0.3500\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4240 - accuracy: 0.9239 - IoU_coef: 0.4240 - val_loss: -0.3504 - val_accuracy: 0.9094 - val_IoU_coef: 0.3504\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4243 - accuracy: 0.9239 - IoU_coef: 0.4243 - val_loss: -0.3507 - val_accuracy: 0.9094 - val_IoU_coef: 0.3507\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4244 - accuracy: 0.9237 - IoU_coef: 0.4244 - val_loss: -0.3511 - val_accuracy: 0.9093 - val_IoU_coef: 0.3511\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4248 - accuracy: 0.9238 - IoU_coef: 0.4248 - val_loss: -0.3511 - val_accuracy: 0.9094 - val_IoU_coef: 0.3511\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4250 - accuracy: 0.9239 - IoU_coef: 0.4250 - val_loss: -0.3516 - val_accuracy: 0.9097 - val_IoU_coef: 0.3516\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4252 - accuracy: 0.9238 - IoU_coef: 0.4252 - val_loss: -0.3522 - val_accuracy: 0.9096 - val_IoU_coef: 0.3522\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4256 - accuracy: 0.9238 - IoU_coef: 0.4256 - val_loss: -0.3523 - val_accuracy: 0.9095 - val_IoU_coef: 0.3523\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4259 - accuracy: 0.9241 - IoU_coef: 0.4259 - val_loss: -0.3526 - val_accuracy: 0.9090 - val_IoU_coef: 0.3526\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4261 - accuracy: 0.9239 - IoU_coef: 0.4261 - val_loss: -0.3529 - val_accuracy: 0.9088 - val_IoU_coef: 0.3529\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4262 - accuracy: 0.9238 - IoU_coef: 0.4262 - val_loss: -0.3528 - val_accuracy: 0.9083 - val_IoU_coef: 0.3528\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4267 - accuracy: 0.9239 - IoU_coef: 0.4267 - val_loss: -0.3535 - val_accuracy: 0.9087 - val_IoU_coef: 0.3535\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4270 - accuracy: 0.9239 - IoU_coef: 0.4270 - val_loss: -0.3545 - val_accuracy: 0.9091 - val_IoU_coef: 0.3545\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4272 - accuracy: 0.9239 - IoU_coef: 0.4272 - val_loss: -0.3544 - val_accuracy: 0.9092 - val_IoU_coef: 0.3544\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4275 - accuracy: 0.9240 - IoU_coef: 0.4275 - val_loss: -0.3545 - val_accuracy: 0.9093 - val_IoU_coef: 0.3545\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4280 - accuracy: 0.9239 - IoU_coef: 0.4280 - val_loss: -0.3545 - val_accuracy: 0.9094 - val_IoU_coef: 0.3545\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4280 - accuracy: 0.9239 - IoU_coef: 0.4280 - val_loss: -0.3543 - val_accuracy: 0.9084 - val_IoU_coef: 0.3543\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4283 - accuracy: 0.9239 - IoU_coef: 0.4283 - val_loss: -0.3541 - val_accuracy: 0.9082 - val_IoU_coef: 0.3541\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4287 - accuracy: 0.9239 - IoU_coef: 0.4287 - val_loss: -0.3542 - val_accuracy: 0.9079 - val_IoU_coef: 0.3542\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4289 - accuracy: 0.9241 - IoU_coef: 0.4289 - val_loss: -0.3547 - val_accuracy: 0.9068 - val_IoU_coef: 0.3547\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4292 - accuracy: 0.9239 - IoU_coef: 0.4292 - val_loss: -0.3549 - val_accuracy: 0.9075 - val_IoU_coef: 0.3549\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4295 - accuracy: 0.9239 - IoU_coef: 0.4295 - val_loss: -0.3554 - val_accuracy: 0.9083 - val_IoU_coef: 0.3554\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4298 - accuracy: 0.9241 - IoU_coef: 0.4298 - val_loss: -0.3556 - val_accuracy: 0.9077 - val_IoU_coef: 0.3556\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4299 - accuracy: 0.9238 - IoU_coef: 0.4299 - val_loss: -0.3555 - val_accuracy: 0.9084 - val_IoU_coef: 0.3555\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4302 - accuracy: 0.9240 - IoU_coef: 0.4302 - val_loss: -0.3561 - val_accuracy: 0.9092 - val_IoU_coef: 0.3561\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 491ms/step - loss: -0.4303 - accuracy: 0.9241 - IoU_coef: 0.4303 - val_loss: -0.3569 - val_accuracy: 0.9090 - val_IoU_coef: 0.3569\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4309 - accuracy: 0.9237 - IoU_coef: 0.4309 - val_loss: -0.3569 - val_accuracy: 0.9091 - val_IoU_coef: 0.3569\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4310 - accuracy: 0.9242 - IoU_coef: 0.4310 - val_loss: -0.3563 - val_accuracy: 0.9088 - val_IoU_coef: 0.3563\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4315 - accuracy: 0.9241 - IoU_coef: 0.4315 - val_loss: -0.3564 - val_accuracy: 0.9086 - val_IoU_coef: 0.3564\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4314 - accuracy: 0.9238 - IoU_coef: 0.4314 - val_loss: -0.3575 - val_accuracy: 0.9088 - val_IoU_coef: 0.3575\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4319 - accuracy: 0.9241 - IoU_coef: 0.4319 - val_loss: -0.3582 - val_accuracy: 0.9091 - val_IoU_coef: 0.3582\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4323 - accuracy: 0.9242 - IoU_coef: 0.4323 - val_loss: -0.3583 - val_accuracy: 0.9094 - val_IoU_coef: 0.3583\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4324 - accuracy: 0.9238 - IoU_coef: 0.4324 - val_loss: -0.3583 - val_accuracy: 0.9095 - val_IoU_coef: 0.3583\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4327 - accuracy: 0.9240 - IoU_coef: 0.4327 - val_loss: -0.3588 - val_accuracy: 0.9092 - val_IoU_coef: 0.3588\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4330 - accuracy: 0.9241 - IoU_coef: 0.4330 - val_loss: -0.3597 - val_accuracy: 0.9088 - val_IoU_coef: 0.3597\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4332 - accuracy: 0.9239 - IoU_coef: 0.4332 - val_loss: -0.3591 - val_accuracy: 0.9087 - val_IoU_coef: 0.3591\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.4337 - accuracy: 0.9241 - IoU_coef: 0.4337 - val_loss: -0.3583 - val_accuracy: 0.9090 - val_IoU_coef: 0.3583\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4337 - accuracy: 0.9244 - IoU_coef: 0.4337 - val_loss: -0.3587 - val_accuracy: 0.9082 - val_IoU_coef: 0.3587\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4341 - accuracy: 0.9237 - IoU_coef: 0.4341 - val_loss: -0.3594 - val_accuracy: 0.9084 - val_IoU_coef: 0.3594\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4343 - accuracy: 0.9240 - IoU_coef: 0.4343 - val_loss: -0.3592 - val_accuracy: 0.9088 - val_IoU_coef: 0.3592\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4346 - accuracy: 0.9244 - IoU_coef: 0.4346 - val_loss: -0.3596 - val_accuracy: 0.9081 - val_IoU_coef: 0.3596\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4348 - accuracy: 0.9236 - IoU_coef: 0.4348 - val_loss: -0.3605 - val_accuracy: 0.9083 - val_IoU_coef: 0.3605\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4351 - accuracy: 0.9239 - IoU_coef: 0.4351 - val_loss: -0.3614 - val_accuracy: 0.9097 - val_IoU_coef: 0.3614\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4354 - accuracy: 0.9246 - IoU_coef: 0.4354 - val_loss: -0.3614 - val_accuracy: 0.9091 - val_IoU_coef: 0.3614\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4358 - accuracy: 0.9239 - IoU_coef: 0.4358 - val_loss: -0.3606 - val_accuracy: 0.9087 - val_IoU_coef: 0.3606\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4361 - accuracy: 0.9237 - IoU_coef: 0.4361 - val_loss: -0.3606 - val_accuracy: 0.9102 - val_IoU_coef: 0.3606\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4361 - accuracy: 0.9247 - IoU_coef: 0.4361 - val_loss: -0.3617 - val_accuracy: 0.9094 - val_IoU_coef: 0.3617\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4366 - accuracy: 0.9240 - IoU_coef: 0.4366 - val_loss: -0.3619 - val_accuracy: 0.9092 - val_IoU_coef: 0.3619\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4368 - accuracy: 0.9237 - IoU_coef: 0.4368 - val_loss: -0.3617 - val_accuracy: 0.9105 - val_IoU_coef: 0.3617\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4371 - accuracy: 0.9244 - IoU_coef: 0.4371 - val_loss: -0.3622 - val_accuracy: 0.9109 - val_IoU_coef: 0.3622\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4376 - accuracy: 0.9243 - IoU_coef: 0.4376 - val_loss: -0.3628 - val_accuracy: 0.9106 - val_IoU_coef: 0.3628\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4376 - accuracy: 0.9239 - IoU_coef: 0.4376 - val_loss: -0.3625 - val_accuracy: 0.9106 - val_IoU_coef: 0.3625\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4380 - accuracy: 0.9241 - IoU_coef: 0.4380 - val_loss: -0.3623 - val_accuracy: 0.9106 - val_IoU_coef: 0.3623\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4382 - accuracy: 0.9244 - IoU_coef: 0.4382 - val_loss: -0.3626 - val_accuracy: 0.9096 - val_IoU_coef: 0.3626\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4385 - accuracy: 0.9240 - IoU_coef: 0.4385 - val_loss: -0.3624 - val_accuracy: 0.9092 - val_IoU_coef: 0.3624\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4388 - accuracy: 0.9240 - IoU_coef: 0.4388 - val_loss: -0.3625 - val_accuracy: 0.9097 - val_IoU_coef: 0.3625\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4389 - accuracy: 0.9244 - IoU_coef: 0.4389 - val_loss: -0.3628 - val_accuracy: 0.9093 - val_IoU_coef: 0.3628\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4394 - accuracy: 0.9242 - IoU_coef: 0.4394 - val_loss: -0.3629 - val_accuracy: 0.9083 - val_IoU_coef: 0.3629\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4395 - accuracy: 0.9239 - IoU_coef: 0.4395 - val_loss: -0.3629 - val_accuracy: 0.9087 - val_IoU_coef: 0.3629\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4399 - accuracy: 0.9243 - IoU_coef: 0.4399 - val_loss: -0.3639 - val_accuracy: 0.9093 - val_IoU_coef: 0.3639\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4402 - accuracy: 0.9244 - IoU_coef: 0.4402 - val_loss: -0.3646 - val_accuracy: 0.9093 - val_IoU_coef: 0.3646\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4404 - accuracy: 0.9240 - IoU_coef: 0.4404 - val_loss: -0.3648 - val_accuracy: 0.9100 - val_IoU_coef: 0.3648\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4407 - accuracy: 0.9242 - IoU_coef: 0.4407 - val_loss: -0.3649 - val_accuracy: 0.9103 - val_IoU_coef: 0.3649\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4410 - accuracy: 0.9243 - IoU_coef: 0.4410 - val_loss: -0.3651 - val_accuracy: 0.9094 - val_IoU_coef: 0.3651\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4412 - accuracy: 0.9240 - IoU_coef: 0.4412 - val_loss: -0.3655 - val_accuracy: 0.9098 - val_IoU_coef: 0.3655\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4416 - accuracy: 0.9242 - IoU_coef: 0.4416 - val_loss: -0.3656 - val_accuracy: 0.9104 - val_IoU_coef: 0.3656\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4419 - accuracy: 0.9244 - IoU_coef: 0.4419 - val_loss: -0.3656 - val_accuracy: 0.9103 - val_IoU_coef: 0.3656\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4420 - accuracy: 0.9243 - IoU_coef: 0.4420 - val_loss: -0.3665 - val_accuracy: 0.9102 - val_IoU_coef: 0.3665\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4424 - accuracy: 0.9242 - IoU_coef: 0.4424 - val_loss: -0.3665 - val_accuracy: 0.9097 - val_IoU_coef: 0.3665\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4427 - accuracy: 0.9243 - IoU_coef: 0.4427 - val_loss: -0.3667 - val_accuracy: 0.9093 - val_IoU_coef: 0.3667\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4430 - accuracy: 0.9243 - IoU_coef: 0.4430 - val_loss: -0.3665 - val_accuracy: 0.9089 - val_IoU_coef: 0.3665\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4431 - accuracy: 0.9242 - IoU_coef: 0.4431 - val_loss: -0.3663 - val_accuracy: 0.9092 - val_IoU_coef: 0.3663\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4434 - accuracy: 0.9243 - IoU_coef: 0.4434 - val_loss: -0.3667 - val_accuracy: 0.9098 - val_IoU_coef: 0.3667\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4437 - accuracy: 0.9244 - IoU_coef: 0.4437 - val_loss: -0.3669 - val_accuracy: 0.9096 - val_IoU_coef: 0.3669\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4440 - accuracy: 0.9242 - IoU_coef: 0.4440 - val_loss: -0.3664 - val_accuracy: 0.9097 - val_IoU_coef: 0.3664\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4442 - accuracy: 0.9242 - IoU_coef: 0.4442 - val_loss: -0.3664 - val_accuracy: 0.9100 - val_IoU_coef: 0.3664\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4447 - accuracy: 0.9246 - IoU_coef: 0.4447 - val_loss: -0.3670 - val_accuracy: 0.9098 - val_IoU_coef: 0.3670\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4449 - accuracy: 0.9243 - IoU_coef: 0.4449 - val_loss: -0.3675 - val_accuracy: 0.9100 - val_IoU_coef: 0.3675\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4451 - accuracy: 0.9242 - IoU_coef: 0.4451 - val_loss: -0.3675 - val_accuracy: 0.9103 - val_IoU_coef: 0.3675\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4454 - accuracy: 0.9245 - IoU_coef: 0.4454 - val_loss: -0.3679 - val_accuracy: 0.9103 - val_IoU_coef: 0.3679\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4456 - accuracy: 0.9244 - IoU_coef: 0.4456 - val_loss: -0.3689 - val_accuracy: 0.9102 - val_IoU_coef: 0.3689\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4460 - accuracy: 0.9242 - IoU_coef: 0.4460 - val_loss: -0.3690 - val_accuracy: 0.9105 - val_IoU_coef: 0.3690\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4462 - accuracy: 0.9244 - IoU_coef: 0.4462 - val_loss: -0.3690 - val_accuracy: 0.9100 - val_IoU_coef: 0.3690\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4465 - accuracy: 0.9244 - IoU_coef: 0.4465 - val_loss: -0.3696 - val_accuracy: 0.9100 - val_IoU_coef: 0.3696\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4467 - accuracy: 0.9244 - IoU_coef: 0.4467 - val_loss: -0.3703 - val_accuracy: 0.9104 - val_IoU_coef: 0.3703\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4470 - accuracy: 0.9243 - IoU_coef: 0.4470 - val_loss: -0.3704 - val_accuracy: 0.9108 - val_IoU_coef: 0.3704\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4473 - accuracy: 0.9245 - IoU_coef: 0.4473 - val_loss: -0.3707 - val_accuracy: 0.9107 - val_IoU_coef: 0.3707\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4476 - accuracy: 0.9243 - IoU_coef: 0.4476 - val_loss: -0.3706 - val_accuracy: 0.9109 - val_IoU_coef: 0.3706\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4478 - accuracy: 0.9244 - IoU_coef: 0.4478 - val_loss: -0.3704 - val_accuracy: 0.9104 - val_IoU_coef: 0.3704\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4479 - accuracy: 0.9243 - IoU_coef: 0.4479 - val_loss: -0.3711 - val_accuracy: 0.9104 - val_IoU_coef: 0.3711\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4483 - accuracy: 0.9245 - IoU_coef: 0.4483 - val_loss: -0.3710 - val_accuracy: 0.9101 - val_IoU_coef: 0.3710\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4487 - accuracy: 0.9244 - IoU_coef: 0.4487 - val_loss: -0.3707 - val_accuracy: 0.9101 - val_IoU_coef: 0.3707\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4488 - accuracy: 0.9243 - IoU_coef: 0.4488 - val_loss: -0.3713 - val_accuracy: 0.9107 - val_IoU_coef: 0.3713\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4490 - accuracy: 0.9246 - IoU_coef: 0.4490 - val_loss: -0.3722 - val_accuracy: 0.9102 - val_IoU_coef: 0.3722\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4495 - accuracy: 0.9242 - IoU_coef: 0.4495 - val_loss: -0.3726 - val_accuracy: 0.9105 - val_IoU_coef: 0.3726\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4498 - accuracy: 0.9245 - IoU_coef: 0.4498 - val_loss: -0.3729 - val_accuracy: 0.9105 - val_IoU_coef: 0.3729\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4497 - accuracy: 0.9245 - IoU_coef: 0.4497 - val_loss: -0.3727 - val_accuracy: 0.9094 - val_IoU_coef: 0.3727\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4502 - accuracy: 0.9242 - IoU_coef: 0.4502 - val_loss: -0.3722 - val_accuracy: 0.9092 - val_IoU_coef: 0.3722\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4505 - accuracy: 0.9245 - IoU_coef: 0.4505 - val_loss: -0.3728 - val_accuracy: 0.9091 - val_IoU_coef: 0.3728\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4509 - accuracy: 0.9246 - IoU_coef: 0.4509 - val_loss: -0.3729 - val_accuracy: 0.9088 - val_IoU_coef: 0.3729\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4510 - accuracy: 0.9243 - IoU_coef: 0.4510 - val_loss: -0.3723 - val_accuracy: 0.9085 - val_IoU_coef: 0.3723\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4512 - accuracy: 0.9243 - IoU_coef: 0.4512 - val_loss: -0.3721 - val_accuracy: 0.9076 - val_IoU_coef: 0.3721\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4516 - accuracy: 0.9245 - IoU_coef: 0.4516 - val_loss: -0.3726 - val_accuracy: 0.9075 - val_IoU_coef: 0.3726\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4519 - accuracy: 0.9245 - IoU_coef: 0.4519 - val_loss: -0.3734 - val_accuracy: 0.9082 - val_IoU_coef: 0.3734\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4521 - accuracy: 0.9244 - IoU_coef: 0.4521 - val_loss: -0.3740 - val_accuracy: 0.9091 - val_IoU_coef: 0.3740\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4523 - accuracy: 0.9245 - IoU_coef: 0.4523 - val_loss: -0.3742 - val_accuracy: 0.9095 - val_IoU_coef: 0.3742\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4526 - accuracy: 0.9243 - IoU_coef: 0.4526 - val_loss: -0.3748 - val_accuracy: 0.9100 - val_IoU_coef: 0.3748\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4531 - accuracy: 0.9245 - IoU_coef: 0.4531 - val_loss: -0.3747 - val_accuracy: 0.9103 - val_IoU_coef: 0.3747\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4533 - accuracy: 0.9246 - IoU_coef: 0.4533 - val_loss: -0.3748 - val_accuracy: 0.9103 - val_IoU_coef: 0.3748\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4535 - accuracy: 0.9245 - IoU_coef: 0.4535 - val_loss: -0.3753 - val_accuracy: 0.9107 - val_IoU_coef: 0.3753\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4538 - accuracy: 0.9244 - IoU_coef: 0.4538 - val_loss: -0.3758 - val_accuracy: 0.9110 - val_IoU_coef: 0.3758\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4541 - accuracy: 0.9246 - IoU_coef: 0.4541 - val_loss: -0.3767 - val_accuracy: 0.9106 - val_IoU_coef: 0.3767\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4544 - accuracy: 0.9244 - IoU_coef: 0.4544 - val_loss: -0.3773 - val_accuracy: 0.9107 - val_IoU_coef: 0.3773\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4545 - accuracy: 0.9244 - IoU_coef: 0.4545 - val_loss: -0.3773 - val_accuracy: 0.9108 - val_IoU_coef: 0.3773\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4548 - accuracy: 0.9245 - IoU_coef: 0.4548 - val_loss: -0.3771 - val_accuracy: 0.9113 - val_IoU_coef: 0.3771\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4552 - accuracy: 0.9246 - IoU_coef: 0.4552 - val_loss: -0.3777 - val_accuracy: 0.9117 - val_IoU_coef: 0.3777\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4553 - accuracy: 0.9245 - IoU_coef: 0.4553 - val_loss: -0.3769 - val_accuracy: 0.9110 - val_IoU_coef: 0.3769\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4553 - accuracy: 0.9244 - IoU_coef: 0.4553 - val_loss: -0.3768 - val_accuracy: 0.9109 - val_IoU_coef: 0.3768\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4558 - accuracy: 0.9246 - IoU_coef: 0.4558 - val_loss: -0.3774 - val_accuracy: 0.9108 - val_IoU_coef: 0.3774\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4560 - accuracy: 0.9245 - IoU_coef: 0.4560 - val_loss: -0.3780 - val_accuracy: 0.9109 - val_IoU_coef: 0.3780\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.4561 - accuracy: 0.9244 - IoU_coef: 0.4561 - val_loss: -0.3786 - val_accuracy: 0.9116 - val_IoU_coef: 0.3786\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4565 - accuracy: 0.9247 - IoU_coef: 0.4565 - val_loss: -0.3789 - val_accuracy: 0.9112 - val_IoU_coef: 0.3789\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4570 - accuracy: 0.9244 - IoU_coef: 0.4570 - val_loss: -0.3789 - val_accuracy: 0.9104 - val_IoU_coef: 0.3789\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4570 - accuracy: 0.9244 - IoU_coef: 0.4570 - val_loss: -0.3789 - val_accuracy: 0.9100 - val_IoU_coef: 0.3789\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4573 - accuracy: 0.9247 - IoU_coef: 0.4573 - val_loss: -0.3783 - val_accuracy: 0.9092 - val_IoU_coef: 0.3783\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4578 - accuracy: 0.9246 - IoU_coef: 0.4578 - val_loss: -0.3782 - val_accuracy: 0.9087 - val_IoU_coef: 0.3782\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4579 - accuracy: 0.9244 - IoU_coef: 0.4579 - val_loss: -0.3797 - val_accuracy: 0.9089 - val_IoU_coef: 0.3797\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4580 - accuracy: 0.9247 - IoU_coef: 0.4580 - val_loss: -0.3798 - val_accuracy: 0.9080 - val_IoU_coef: 0.3798\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4584 - accuracy: 0.9245 - IoU_coef: 0.4584 - val_loss: -0.3798 - val_accuracy: 0.9077 - val_IoU_coef: 0.3798\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: -0.4587 - accuracy: 0.9244 - IoU_coef: 0.4587 - val_loss: -0.3812 - val_accuracy: 0.9092 - val_IoU_coef: 0.3812\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4590 - accuracy: 0.9246 - IoU_coef: 0.4590 - val_loss: -0.3817 - val_accuracy: 0.9096 - val_IoU_coef: 0.3817\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4593 - accuracy: 0.9245 - IoU_coef: 0.4593 - val_loss: -0.3819 - val_accuracy: 0.9101 - val_IoU_coef: 0.3819\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4595 - accuracy: 0.9246 - IoU_coef: 0.4595 - val_loss: -0.3823 - val_accuracy: 0.9104 - val_IoU_coef: 0.3823\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.4598 - accuracy: 0.9247 - IoU_coef: 0.4598 - val_loss: -0.3819 - val_accuracy: 0.9099 - val_IoU_coef: 0.3819\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4602 - accuracy: 0.9246 - IoU_coef: 0.4602 - val_loss: -0.3821 - val_accuracy: 0.9097 - val_IoU_coef: 0.3821\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.4605 - accuracy: 0.9247 - IoU_coef: 0.4605 - val_loss: -0.3829 - val_accuracy: 0.9098 - val_IoU_coef: 0.3829\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4607 - accuracy: 0.9247 - IoU_coef: 0.4607 - val_loss: -0.3830 - val_accuracy: 0.9096 - val_IoU_coef: 0.3830\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4610 - accuracy: 0.9246 - IoU_coef: 0.4610 - val_loss: -0.3830 - val_accuracy: 0.9102 - val_IoU_coef: 0.3830\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4613 - accuracy: 0.9247 - IoU_coef: 0.4613 - val_loss: -0.3834 - val_accuracy: 0.9101 - val_IoU_coef: 0.3834\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4616 - accuracy: 0.9247 - IoU_coef: 0.4616 - val_loss: -0.3844 - val_accuracy: 0.9100 - val_IoU_coef: 0.3844\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4618 - accuracy: 0.9246 - IoU_coef: 0.4618 - val_loss: -0.3842 - val_accuracy: 0.9100 - val_IoU_coef: 0.3842\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4620 - accuracy: 0.9247 - IoU_coef: 0.4620 - val_loss: -0.3830 - val_accuracy: 0.9092 - val_IoU_coef: 0.3830\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4623 - accuracy: 0.9247 - IoU_coef: 0.4623 - val_loss: -0.3822 - val_accuracy: 0.9084 - val_IoU_coef: 0.3822\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4627 - accuracy: 0.9246 - IoU_coef: 0.4627 - val_loss: -0.3827 - val_accuracy: 0.9085 - val_IoU_coef: 0.3827\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4629 - accuracy: 0.9247 - IoU_coef: 0.4629 - val_loss: -0.3841 - val_accuracy: 0.9091 - val_IoU_coef: 0.3841\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4630 - accuracy: 0.9247 - IoU_coef: 0.4630 - val_loss: -0.3840 - val_accuracy: 0.9090 - val_IoU_coef: 0.3840\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.4634 - accuracy: 0.9246 - IoU_coef: 0.4634 - val_loss: -0.3839 - val_accuracy: 0.9099 - val_IoU_coef: 0.3839\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4636 - accuracy: 0.9246 - IoU_coef: 0.4636 - val_loss: -0.3847 - val_accuracy: 0.9100 - val_IoU_coef: 0.3847\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4641 - accuracy: 0.9247 - IoU_coef: 0.4641 - val_loss: -0.3857 - val_accuracy: 0.9099 - val_IoU_coef: 0.3857\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4640 - accuracy: 0.9247 - IoU_coef: 0.4640 - val_loss: -0.3858 - val_accuracy: 0.9099 - val_IoU_coef: 0.3858\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4645 - accuracy: 0.9247 - IoU_coef: 0.4645 - val_loss: -0.3854 - val_accuracy: 0.9103 - val_IoU_coef: 0.3854\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4646 - accuracy: 0.9246 - IoU_coef: 0.4646 - val_loss: -0.3854 - val_accuracy: 0.9101 - val_IoU_coef: 0.3854\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4648 - accuracy: 0.9246 - IoU_coef: 0.4648 - val_loss: -0.3860 - val_accuracy: 0.9101 - val_IoU_coef: 0.3860\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4652 - accuracy: 0.9247 - IoU_coef: 0.4652 - val_loss: -0.3865 - val_accuracy: 0.9104 - val_IoU_coef: 0.3865\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4654 - accuracy: 0.9248 - IoU_coef: 0.4654 - val_loss: -0.3857 - val_accuracy: 0.9099 - val_IoU_coef: 0.3857\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4655 - accuracy: 0.9245 - IoU_coef: 0.4655 - val_loss: -0.3856 - val_accuracy: 0.9105 - val_IoU_coef: 0.3856\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4659 - accuracy: 0.9249 - IoU_coef: 0.4659 - val_loss: -0.3856 - val_accuracy: 0.9102 - val_IoU_coef: 0.3856\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4663 - accuracy: 0.9246 - IoU_coef: 0.4663 - val_loss: -0.3865 - val_accuracy: 0.9105 - val_IoU_coef: 0.3865\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4664 - accuracy: 0.9246 - IoU_coef: 0.4664 - val_loss: -0.3875 - val_accuracy: 0.9105 - val_IoU_coef: 0.3875\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4670 - accuracy: 0.9248 - IoU_coef: 0.4670 - val_loss: -0.3867 - val_accuracy: 0.9099 - val_IoU_coef: 0.3867\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4670 - accuracy: 0.9248 - IoU_coef: 0.4670 - val_loss: -0.3857 - val_accuracy: 0.9091 - val_IoU_coef: 0.3857\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4672 - accuracy: 0.9246 - IoU_coef: 0.4672 - val_loss: -0.3877 - val_accuracy: 0.9103 - val_IoU_coef: 0.3877\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4677 - accuracy: 0.9248 - IoU_coef: 0.4677 - val_loss: -0.3890 - val_accuracy: 0.9114 - val_IoU_coef: 0.3890\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4676 - accuracy: 0.9248 - IoU_coef: 0.4676 - val_loss: -0.3884 - val_accuracy: 0.9114 - val_IoU_coef: 0.3884\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4681 - accuracy: 0.9246 - IoU_coef: 0.4681 - val_loss: -0.3876 - val_accuracy: 0.9112 - val_IoU_coef: 0.3876\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4685 - accuracy: 0.9247 - IoU_coef: 0.4685 - val_loss: -0.3880 - val_accuracy: 0.9111 - val_IoU_coef: 0.3880\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4685 - accuracy: 0.9250 - IoU_coef: 0.4685 - val_loss: -0.3890 - val_accuracy: 0.9109 - val_IoU_coef: 0.3890\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4688 - accuracy: 0.9248 - IoU_coef: 0.4688 - val_loss: -0.3897 - val_accuracy: 0.9111 - val_IoU_coef: 0.3897\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4692 - accuracy: 0.9247 - IoU_coef: 0.4692 - val_loss: -0.3893 - val_accuracy: 0.9111 - val_IoU_coef: 0.3893\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4695 - accuracy: 0.9249 - IoU_coef: 0.4695 - val_loss: -0.3892 - val_accuracy: 0.9105 - val_IoU_coef: 0.3892\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4697 - accuracy: 0.9247 - IoU_coef: 0.4697 - val_loss: -0.3898 - val_accuracy: 0.9106 - val_IoU_coef: 0.3898\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4698 - accuracy: 0.9247 - IoU_coef: 0.4698 - val_loss: -0.3904 - val_accuracy: 0.9115 - val_IoU_coef: 0.3904\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4704 - accuracy: 0.9250 - IoU_coef: 0.4704 - val_loss: -0.3914 - val_accuracy: 0.9116 - val_IoU_coef: 0.3914\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4705 - accuracy: 0.9248 - IoU_coef: 0.4705 - val_loss: -0.3916 - val_accuracy: 0.9115 - val_IoU_coef: 0.3916\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4708 - accuracy: 0.9247 - IoU_coef: 0.4708 - val_loss: -0.3908 - val_accuracy: 0.9109 - val_IoU_coef: 0.3908\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4711 - accuracy: 0.9249 - IoU_coef: 0.4711 - val_loss: -0.3905 - val_accuracy: 0.9099 - val_IoU_coef: 0.3905\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4713 - accuracy: 0.9250 - IoU_coef: 0.4713 - val_loss: -0.3912 - val_accuracy: 0.9097 - val_IoU_coef: 0.3912\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4715 - accuracy: 0.9248 - IoU_coef: 0.4715 - val_loss: -0.3918 - val_accuracy: 0.9108 - val_IoU_coef: 0.3918\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4720 - accuracy: 0.9249 - IoU_coef: 0.4720 - val_loss: -0.3913 - val_accuracy: 0.9114 - val_IoU_coef: 0.3913\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4722 - accuracy: 0.9249 - IoU_coef: 0.4722 - val_loss: -0.3920 - val_accuracy: 0.9107 - val_IoU_coef: 0.3920\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4722 - accuracy: 0.9246 - IoU_coef: 0.4722 - val_loss: -0.3922 - val_accuracy: 0.9104 - val_IoU_coef: 0.3922\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4725 - accuracy: 0.9249 - IoU_coef: 0.4725 - val_loss: -0.3927 - val_accuracy: 0.9102 - val_IoU_coef: 0.3927\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4729 - accuracy: 0.9250 - IoU_coef: 0.4729 - val_loss: -0.3933 - val_accuracy: 0.9100 - val_IoU_coef: 0.3933\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4733 - accuracy: 0.9248 - IoU_coef: 0.4733 - val_loss: -0.3938 - val_accuracy: 0.9103 - val_IoU_coef: 0.3938\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4735 - accuracy: 0.9249 - IoU_coef: 0.4735 - val_loss: -0.3940 - val_accuracy: 0.9110 - val_IoU_coef: 0.3940\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4736 - accuracy: 0.9250 - IoU_coef: 0.4736 - val_loss: -0.3939 - val_accuracy: 0.9104 - val_IoU_coef: 0.3939\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4739 - accuracy: 0.9247 - IoU_coef: 0.4739 - val_loss: -0.3935 - val_accuracy: 0.9107 - val_IoU_coef: 0.3935\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4741 - accuracy: 0.9250 - IoU_coef: 0.4741 - val_loss: -0.3935 - val_accuracy: 0.9109 - val_IoU_coef: 0.3935\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4745 - accuracy: 0.9250 - IoU_coef: 0.4745 - val_loss: -0.3943 - val_accuracy: 0.9107 - val_IoU_coef: 0.3943\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4747 - accuracy: 0.9247 - IoU_coef: 0.4747 - val_loss: -0.3953 - val_accuracy: 0.9104 - val_IoU_coef: 0.3953\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4750 - accuracy: 0.9248 - IoU_coef: 0.4750 - val_loss: -0.3950 - val_accuracy: 0.9101 - val_IoU_coef: 0.3950\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4752 - accuracy: 0.9250 - IoU_coef: 0.4752 - val_loss: -0.3945 - val_accuracy: 0.9097 - val_IoU_coef: 0.3945\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4755 - accuracy: 0.9249 - IoU_coef: 0.4755 - val_loss: -0.3948 - val_accuracy: 0.9098 - val_IoU_coef: 0.3948\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4757 - accuracy: 0.9248 - IoU_coef: 0.4757 - val_loss: -0.3954 - val_accuracy: 0.9102 - val_IoU_coef: 0.3954\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4759 - accuracy: 0.9250 - IoU_coef: 0.4759 - val_loss: -0.3955 - val_accuracy: 0.9102 - val_IoU_coef: 0.3955\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4762 - accuracy: 0.9249 - IoU_coef: 0.4762 - val_loss: -0.3957 - val_accuracy: 0.9099 - val_IoU_coef: 0.3957\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4766 - accuracy: 0.9248 - IoU_coef: 0.4766 - val_loss: -0.3956 - val_accuracy: 0.9099 - val_IoU_coef: 0.3956\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4766 - accuracy: 0.9250 - IoU_coef: 0.4766 - val_loss: -0.3956 - val_accuracy: 0.9099 - val_IoU_coef: 0.3956\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4770 - accuracy: 0.9250 - IoU_coef: 0.4770 - val_loss: -0.3963 - val_accuracy: 0.9104 - val_IoU_coef: 0.3963\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4773 - accuracy: 0.9249 - IoU_coef: 0.4773 - val_loss: -0.3968 - val_accuracy: 0.9114 - val_IoU_coef: 0.3968\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4774 - accuracy: 0.9249 - IoU_coef: 0.4774 - val_loss: -0.3970 - val_accuracy: 0.9121 - val_IoU_coef: 0.3970\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4779 - accuracy: 0.9251 - IoU_coef: 0.4779 - val_loss: -0.3974 - val_accuracy: 0.9121 - val_IoU_coef: 0.3974\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4780 - accuracy: 0.9248 - IoU_coef: 0.4780 - val_loss: -0.3975 - val_accuracy: 0.9124 - val_IoU_coef: 0.3975\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4783 - accuracy: 0.9249 - IoU_coef: 0.4783 - val_loss: -0.3976 - val_accuracy: 0.9120 - val_IoU_coef: 0.3976\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4786 - accuracy: 0.9250 - IoU_coef: 0.4786 - val_loss: -0.3981 - val_accuracy: 0.9114 - val_IoU_coef: 0.3981\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4789 - accuracy: 0.9250 - IoU_coef: 0.4789 - val_loss: -0.3984 - val_accuracy: 0.9108 - val_IoU_coef: 0.3984\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4791 - accuracy: 0.9250 - IoU_coef: 0.4791 - val_loss: -0.3976 - val_accuracy: 0.9098 - val_IoU_coef: 0.3976\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4794 - accuracy: 0.9249 - IoU_coef: 0.4794 - val_loss: -0.3971 - val_accuracy: 0.9099 - val_IoU_coef: 0.3971\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4796 - accuracy: 0.9251 - IoU_coef: 0.4796 - val_loss: -0.3976 - val_accuracy: 0.9099 - val_IoU_coef: 0.3976\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: -0.4799 - accuracy: 0.9250 - IoU_coef: 0.4799 - val_loss: -0.3980 - val_accuracy: 0.9097 - val_IoU_coef: 0.3980\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4799 - accuracy: 0.9249 - IoU_coef: 0.4799 - val_loss: -0.3985 - val_accuracy: 0.9099 - val_IoU_coef: 0.3985\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4803 - accuracy: 0.9251 - IoU_coef: 0.4803 - val_loss: -0.3980 - val_accuracy: 0.9098 - val_IoU_coef: 0.3980\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4807 - accuracy: 0.9250 - IoU_coef: 0.4807 - val_loss: -0.3977 - val_accuracy: 0.9104 - val_IoU_coef: 0.3977\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4811 - accuracy: 0.9250 - IoU_coef: 0.4811 - val_loss: -0.3983 - val_accuracy: 0.9104 - val_IoU_coef: 0.3983\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4813 - accuracy: 0.9250 - IoU_coef: 0.4813 - val_loss: -0.3986 - val_accuracy: 0.9102 - val_IoU_coef: 0.3986\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4814 - accuracy: 0.9250 - IoU_coef: 0.4814 - val_loss: -0.3981 - val_accuracy: 0.9102 - val_IoU_coef: 0.3981\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4818 - accuracy: 0.9250 - IoU_coef: 0.4818 - val_loss: -0.3973 - val_accuracy: 0.9100 - val_IoU_coef: 0.3973\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4820 - accuracy: 0.9250 - IoU_coef: 0.4820 - val_loss: -0.3980 - val_accuracy: 0.9096 - val_IoU_coef: 0.3980\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4821 - accuracy: 0.9249 - IoU_coef: 0.4821 - val_loss: -0.3994 - val_accuracy: 0.9098 - val_IoU_coef: 0.3994\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4823 - accuracy: 0.9250 - IoU_coef: 0.4823 - val_loss: -0.3995 - val_accuracy: 0.9100 - val_IoU_coef: 0.3995\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4826 - accuracy: 0.9250 - IoU_coef: 0.4826 - val_loss: -0.3992 - val_accuracy: 0.9100 - val_IoU_coef: 0.3992\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4828 - accuracy: 0.9249 - IoU_coef: 0.4828 - val_loss: -0.3995 - val_accuracy: 0.9096 - val_IoU_coef: 0.3995\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4834 - accuracy: 0.9250 - IoU_coef: 0.4834 - val_loss: -0.3996 - val_accuracy: 0.9095 - val_IoU_coef: 0.3996\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4835 - accuracy: 0.9252 - IoU_coef: 0.4835 - val_loss: -0.3993 - val_accuracy: 0.9092 - val_IoU_coef: 0.3993\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4838 - accuracy: 0.9250 - IoU_coef: 0.4838 - val_loss: -0.3995 - val_accuracy: 0.9094 - val_IoU_coef: 0.3995\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4840 - accuracy: 0.9250 - IoU_coef: 0.4840 - val_loss: -0.4001 - val_accuracy: 0.9100 - val_IoU_coef: 0.4001\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4843 - accuracy: 0.9251 - IoU_coef: 0.4843 - val_loss: -0.4011 - val_accuracy: 0.9112 - val_IoU_coef: 0.4011\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4847 - accuracy: 0.9251 - IoU_coef: 0.4847 - val_loss: -0.4017 - val_accuracy: 0.9119 - val_IoU_coef: 0.4017\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4849 - accuracy: 0.9250 - IoU_coef: 0.4849 - val_loss: -0.4013 - val_accuracy: 0.9115 - val_IoU_coef: 0.4013\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4849 - accuracy: 0.9250 - IoU_coef: 0.4849 - val_loss: -0.4022 - val_accuracy: 0.9119 - val_IoU_coef: 0.4022\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4854 - accuracy: 0.9252 - IoU_coef: 0.4854 - val_loss: -0.4025 - val_accuracy: 0.9115 - val_IoU_coef: 0.4025\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4856 - accuracy: 0.9251 - IoU_coef: 0.4856 - val_loss: -0.4022 - val_accuracy: 0.9110 - val_IoU_coef: 0.4022\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4859 - accuracy: 0.9249 - IoU_coef: 0.4859 - val_loss: -0.4031 - val_accuracy: 0.9118 - val_IoU_coef: 0.4031\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4861 - accuracy: 0.9252 - IoU_coef: 0.4861 - val_loss: -0.4038 - val_accuracy: 0.9119 - val_IoU_coef: 0.4038\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4862 - accuracy: 0.9251 - IoU_coef: 0.4862 - val_loss: -0.4038 - val_accuracy: 0.9117 - val_IoU_coef: 0.4038\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4867 - accuracy: 0.9250 - IoU_coef: 0.4867 - val_loss: -0.4037 - val_accuracy: 0.9121 - val_IoU_coef: 0.4037\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.4868 - accuracy: 0.9252 - IoU_coef: 0.4868 - val_loss: -0.4038 - val_accuracy: 0.9122 - val_IoU_coef: 0.4038\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4870 - accuracy: 0.9251 - IoU_coef: 0.4870 - val_loss: -0.4045 - val_accuracy: 0.9123 - val_IoU_coef: 0.4045\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4874 - accuracy: 0.9251 - IoU_coef: 0.4874 - val_loss: -0.4052 - val_accuracy: 0.9124 - val_IoU_coef: 0.4052\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4876 - accuracy: 0.9252 - IoU_coef: 0.4876 - val_loss: -0.4052 - val_accuracy: 0.9117 - val_IoU_coef: 0.4052\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4877 - accuracy: 0.9249 - IoU_coef: 0.4877 - val_loss: -0.4045 - val_accuracy: 0.9120 - val_IoU_coef: 0.4045\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4880 - accuracy: 0.9253 - IoU_coef: 0.4880 - val_loss: -0.4049 - val_accuracy: 0.9113 - val_IoU_coef: 0.4049\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4883 - accuracy: 0.9250 - IoU_coef: 0.4883 - val_loss: -0.4057 - val_accuracy: 0.9114 - val_IoU_coef: 0.4057\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4887 - accuracy: 0.9250 - IoU_coef: 0.4887 - val_loss: -0.4063 - val_accuracy: 0.9120 - val_IoU_coef: 0.4063\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4887 - accuracy: 0.9253 - IoU_coef: 0.4887 - val_loss: -0.4061 - val_accuracy: 0.9117 - val_IoU_coef: 0.4061\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4890 - accuracy: 0.9251 - IoU_coef: 0.4890 - val_loss: -0.4053 - val_accuracy: 0.9115 - val_IoU_coef: 0.4053\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.4893 - accuracy: 0.9249 - IoU_coef: 0.4893 - val_loss: -0.4060 - val_accuracy: 0.9122 - val_IoU_coef: 0.4060\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4897 - accuracy: 0.9253 - IoU_coef: 0.4897 - val_loss: -0.4069 - val_accuracy: 0.9122 - val_IoU_coef: 0.4069\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4895 - accuracy: 0.9252 - IoU_coef: 0.4895 - val_loss: -0.4064 - val_accuracy: 0.9121 - val_IoU_coef: 0.4064\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4901 - accuracy: 0.9251 - IoU_coef: 0.4901 - val_loss: -0.4061 - val_accuracy: 0.9120 - val_IoU_coef: 0.4061\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4903 - accuracy: 0.9251 - IoU_coef: 0.4903 - val_loss: -0.4065 - val_accuracy: 0.9115 - val_IoU_coef: 0.4065\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4907 - accuracy: 0.9252 - IoU_coef: 0.4907 - val_loss: -0.4066 - val_accuracy: 0.9111 - val_IoU_coef: 0.4066\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4908 - accuracy: 0.9252 - IoU_coef: 0.4908 - val_loss: -0.4061 - val_accuracy: 0.9113 - val_IoU_coef: 0.4061\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4912 - accuracy: 0.9251 - IoU_coef: 0.4912 - val_loss: -0.4062 - val_accuracy: 0.9117 - val_IoU_coef: 0.4062\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.4914 - accuracy: 0.9252 - IoU_coef: 0.4914 - val_loss: -0.4065 - val_accuracy: 0.9117 - val_IoU_coef: 0.4065\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4916 - accuracy: 0.9251 - IoU_coef: 0.4916 - val_loss: -0.4066 - val_accuracy: 0.9124 - val_IoU_coef: 0.4066\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4919 - accuracy: 0.9254 - IoU_coef: 0.4919 - val_loss: -0.4063 - val_accuracy: 0.9122 - val_IoU_coef: 0.4063\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4923 - accuracy: 0.9252 - IoU_coef: 0.4923 - val_loss: -0.4069 - val_accuracy: 0.9117 - val_IoU_coef: 0.4069\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4925 - accuracy: 0.9250 - IoU_coef: 0.4925 - val_loss: -0.4073 - val_accuracy: 0.9118 - val_IoU_coef: 0.4073\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4926 - accuracy: 0.9253 - IoU_coef: 0.4926 - val_loss: -0.4070 - val_accuracy: 0.9119 - val_IoU_coef: 0.4070\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4929 - accuracy: 0.9253 - IoU_coef: 0.4929 - val_loss: -0.4069 - val_accuracy: 0.9116 - val_IoU_coef: 0.4069\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.4930 - accuracy: 0.9249 - IoU_coef: 0.4930 - val_loss: -0.4072 - val_accuracy: 0.9123 - val_IoU_coef: 0.4072\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4935 - accuracy: 0.9252 - IoU_coef: 0.4935 - val_loss: -0.4071 - val_accuracy: 0.9125 - val_IoU_coef: 0.4071\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4936 - accuracy: 0.9253 - IoU_coef: 0.4936 - val_loss: -0.4068 - val_accuracy: 0.9121 - val_IoU_coef: 0.4068\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4939 - accuracy: 0.9250 - IoU_coef: 0.4939 - val_loss: -0.4064 - val_accuracy: 0.9124 - val_IoU_coef: 0.4064\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4943 - accuracy: 0.9253 - IoU_coef: 0.4943 - val_loss: -0.4066 - val_accuracy: 0.9127 - val_IoU_coef: 0.4066\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4945 - accuracy: 0.9253 - IoU_coef: 0.4945 - val_loss: -0.4071 - val_accuracy: 0.9126 - val_IoU_coef: 0.4071\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4947 - accuracy: 0.9251 - IoU_coef: 0.4947 - val_loss: -0.4075 - val_accuracy: 0.9125 - val_IoU_coef: 0.4075\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.4949 - accuracy: 0.9252 - IoU_coef: 0.4949 - val_loss: -0.4080 - val_accuracy: 0.9117 - val_IoU_coef: 0.4080\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.4951 - accuracy: 0.9253 - IoU_coef: 0.4951 - val_loss: -0.4083 - val_accuracy: 0.9106 - val_IoU_coef: 0.4083\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4955 - accuracy: 0.9251 - IoU_coef: 0.4955 - val_loss: -0.4079 - val_accuracy: 0.9107 - val_IoU_coef: 0.4079\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4956 - accuracy: 0.9252 - IoU_coef: 0.4956 - val_loss: -0.4083 - val_accuracy: 0.9112 - val_IoU_coef: 0.4083\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.4958 - accuracy: 0.9253 - IoU_coef: 0.4958 - val_loss: -0.4097 - val_accuracy: 0.9116 - val_IoU_coef: 0.4097\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4960 - accuracy: 0.9251 - IoU_coef: 0.4960 - val_loss: -0.4102 - val_accuracy: 0.9119 - val_IoU_coef: 0.4102\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4964 - accuracy: 0.9252 - IoU_coef: 0.4964 - val_loss: -0.4094 - val_accuracy: 0.9113 - val_IoU_coef: 0.4094\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4967 - accuracy: 0.9253 - IoU_coef: 0.4967 - val_loss: -0.4095 - val_accuracy: 0.9108 - val_IoU_coef: 0.4095\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4969 - accuracy: 0.9252 - IoU_coef: 0.4969 - val_loss: -0.4095 - val_accuracy: 0.9108 - val_IoU_coef: 0.4095\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.4971 - accuracy: 0.9252 - IoU_coef: 0.4971 - val_loss: -0.4087 - val_accuracy: 0.9111 - val_IoU_coef: 0.4087\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.4971 - accuracy: 0.9253 - IoU_coef: 0.4971 - val_loss: -0.4098 - val_accuracy: 0.9116 - val_IoU_coef: 0.4098\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.4977 - accuracy: 0.9254 - IoU_coef: 0.4977 - val_loss: -0.4103 - val_accuracy: 0.9108 - val_IoU_coef: 0.4103\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4981 - accuracy: 0.9252 - IoU_coef: 0.4981 - val_loss: -0.4103 - val_accuracy: 0.9107 - val_IoU_coef: 0.4103\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4982 - accuracy: 0.9254 - IoU_coef: 0.4982 - val_loss: -0.4102 - val_accuracy: 0.9110 - val_IoU_coef: 0.4102\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4985 - accuracy: 0.9253 - IoU_coef: 0.4985 - val_loss: -0.4106 - val_accuracy: 0.9108 - val_IoU_coef: 0.4106\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.4987 - accuracy: 0.9251 - IoU_coef: 0.4987 - val_loss: -0.4111 - val_accuracy: 0.9108 - val_IoU_coef: 0.4111\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.4990 - accuracy: 0.9253 - IoU_coef: 0.4990 - val_loss: -0.4123 - val_accuracy: 0.9115 - val_IoU_coef: 0.4123\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.4991 - accuracy: 0.9255 - IoU_coef: 0.4991 - val_loss: -0.4125 - val_accuracy: 0.9112 - val_IoU_coef: 0.4125\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.4994 - accuracy: 0.9250 - IoU_coef: 0.4994 - val_loss: -0.4127 - val_accuracy: 0.9114 - val_IoU_coef: 0.4127\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.4998 - accuracy: 0.9253 - IoU_coef: 0.4998 - val_loss: -0.4129 - val_accuracy: 0.9110 - val_IoU_coef: 0.4129\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.4998 - accuracy: 0.9255 - IoU_coef: 0.4998 - val_loss: -0.4115 - val_accuracy: 0.9096 - val_IoU_coef: 0.4115\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5001 - accuracy: 0.9251 - IoU_coef: 0.5001 - val_loss: -0.4115 - val_accuracy: 0.9103 - val_IoU_coef: 0.4115\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5005 - accuracy: 0.9254 - IoU_coef: 0.5005 - val_loss: -0.4120 - val_accuracy: 0.9114 - val_IoU_coef: 0.4120\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5006 - accuracy: 0.9255 - IoU_coef: 0.5006 - val_loss: -0.4129 - val_accuracy: 0.9113 - val_IoU_coef: 0.4129\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5008 - accuracy: 0.9251 - IoU_coef: 0.5008 - val_loss: -0.4141 - val_accuracy: 0.9119 - val_IoU_coef: 0.4141\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5012 - accuracy: 0.9252 - IoU_coef: 0.5012 - val_loss: -0.4145 - val_accuracy: 0.9120 - val_IoU_coef: 0.4145\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5013 - accuracy: 0.9256 - IoU_coef: 0.5013 - val_loss: -0.4134 - val_accuracy: 0.9109 - val_IoU_coef: 0.4134\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5016 - accuracy: 0.9252 - IoU_coef: 0.5016 - val_loss: -0.4132 - val_accuracy: 0.9111 - val_IoU_coef: 0.4132\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5019 - accuracy: 0.9252 - IoU_coef: 0.5019 - val_loss: -0.4139 - val_accuracy: 0.9123 - val_IoU_coef: 0.4139\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5021 - accuracy: 0.9255 - IoU_coef: 0.5021 - val_loss: -0.4144 - val_accuracy: 0.9119 - val_IoU_coef: 0.4144\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5024 - accuracy: 0.9253 - IoU_coef: 0.5024 - val_loss: -0.4142 - val_accuracy: 0.9114 - val_IoU_coef: 0.4142\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5026 - accuracy: 0.9252 - IoU_coef: 0.5026 - val_loss: -0.4133 - val_accuracy: 0.9108 - val_IoU_coef: 0.4133\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5029 - accuracy: 0.9254 - IoU_coef: 0.5029 - val_loss: -0.4132 - val_accuracy: 0.9103 - val_IoU_coef: 0.4132\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5031 - accuracy: 0.9254 - IoU_coef: 0.5031 - val_loss: -0.4139 - val_accuracy: 0.9108 - val_IoU_coef: 0.4139\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5033 - accuracy: 0.9253 - IoU_coef: 0.5033 - val_loss: -0.4146 - val_accuracy: 0.9113 - val_IoU_coef: 0.4146\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5035 - accuracy: 0.9254 - IoU_coef: 0.5035 - val_loss: -0.4149 - val_accuracy: 0.9108 - val_IoU_coef: 0.4149\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.5038 - accuracy: 0.9253 - IoU_coef: 0.5038 - val_loss: -0.4148 - val_accuracy: 0.9101 - val_IoU_coef: 0.4148\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5040 - accuracy: 0.9253 - IoU_coef: 0.5040 - val_loss: -0.4148 - val_accuracy: 0.9104 - val_IoU_coef: 0.4148\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5042 - accuracy: 0.9255 - IoU_coef: 0.5042 - val_loss: -0.4152 - val_accuracy: 0.9106 - val_IoU_coef: 0.4152\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5045 - accuracy: 0.9253 - IoU_coef: 0.5045 - val_loss: -0.4167 - val_accuracy: 0.9115 - val_IoU_coef: 0.4167\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5048 - accuracy: 0.9254 - IoU_coef: 0.5048 - val_loss: -0.4170 - val_accuracy: 0.9117 - val_IoU_coef: 0.4170\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5051 - accuracy: 0.9254 - IoU_coef: 0.5051 - val_loss: -0.4161 - val_accuracy: 0.9114 - val_IoU_coef: 0.4161\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5052 - accuracy: 0.9252 - IoU_coef: 0.5052 - val_loss: -0.4152 - val_accuracy: 0.9113 - val_IoU_coef: 0.4152\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5056 - accuracy: 0.9254 - IoU_coef: 0.5056 - val_loss: -0.4160 - val_accuracy: 0.9115 - val_IoU_coef: 0.4160\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5057 - accuracy: 0.9255 - IoU_coef: 0.5057 - val_loss: -0.4175 - val_accuracy: 0.9118 - val_IoU_coef: 0.4175\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5060 - accuracy: 0.9253 - IoU_coef: 0.5060 - val_loss: -0.4180 - val_accuracy: 0.9121 - val_IoU_coef: 0.4180\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5062 - accuracy: 0.9254 - IoU_coef: 0.5062 - val_loss: -0.4172 - val_accuracy: 0.9110 - val_IoU_coef: 0.4172\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5065 - accuracy: 0.9253 - IoU_coef: 0.5065 - val_loss: -0.4157 - val_accuracy: 0.9098 - val_IoU_coef: 0.4157\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5069 - accuracy: 0.9255 - IoU_coef: 0.5069 - val_loss: -0.4147 - val_accuracy: 0.9088 - val_IoU_coef: 0.4147\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5070 - accuracy: 0.9255 - IoU_coef: 0.5070 - val_loss: -0.4152 - val_accuracy: 0.9085 - val_IoU_coef: 0.4152\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5071 - accuracy: 0.9252 - IoU_coef: 0.5071 - val_loss: -0.4170 - val_accuracy: 0.9096 - val_IoU_coef: 0.4170\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5076 - accuracy: 0.9254 - IoU_coef: 0.5076 - val_loss: -0.4170 - val_accuracy: 0.9100 - val_IoU_coef: 0.4170\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5077 - accuracy: 0.9255 - IoU_coef: 0.5077 - val_loss: -0.4162 - val_accuracy: 0.9096 - val_IoU_coef: 0.4162\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5078 - accuracy: 0.9253 - IoU_coef: 0.5078 - val_loss: -0.4168 - val_accuracy: 0.9096 - val_IoU_coef: 0.4168\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5082 - accuracy: 0.9255 - IoU_coef: 0.5082 - val_loss: -0.4170 - val_accuracy: 0.9094 - val_IoU_coef: 0.4170\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5085 - accuracy: 0.9254 - IoU_coef: 0.5085 - val_loss: -0.4168 - val_accuracy: 0.9095 - val_IoU_coef: 0.4168\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5088 - accuracy: 0.9253 - IoU_coef: 0.5088 - val_loss: -0.4172 - val_accuracy: 0.9103 - val_IoU_coef: 0.4172\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5089 - accuracy: 0.9256 - IoU_coef: 0.5089 - val_loss: -0.4169 - val_accuracy: 0.9101 - val_IoU_coef: 0.4169\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5090 - accuracy: 0.9253 - IoU_coef: 0.5090 - val_loss: -0.4174 - val_accuracy: 0.9100 - val_IoU_coef: 0.4174\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5094 - accuracy: 0.9253 - IoU_coef: 0.5094 - val_loss: -0.4176 - val_accuracy: 0.9101 - val_IoU_coef: 0.4176\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5098 - accuracy: 0.9256 - IoU_coef: 0.5098 - val_loss: -0.4178 - val_accuracy: 0.9103 - val_IoU_coef: 0.4178\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5099 - accuracy: 0.9255 - IoU_coef: 0.5099 - val_loss: -0.4183 - val_accuracy: 0.9101 - val_IoU_coef: 0.4183\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5102 - accuracy: 0.9253 - IoU_coef: 0.5102 - val_loss: -0.4189 - val_accuracy: 0.9103 - val_IoU_coef: 0.4189\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5104 - accuracy: 0.9255 - IoU_coef: 0.5104 - val_loss: -0.4195 - val_accuracy: 0.9110 - val_IoU_coef: 0.4195\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5107 - accuracy: 0.9256 - IoU_coef: 0.5107 - val_loss: -0.4185 - val_accuracy: 0.9103 - val_IoU_coef: 0.4185\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5107 - accuracy: 0.9253 - IoU_coef: 0.5107 - val_loss: -0.4186 - val_accuracy: 0.9108 - val_IoU_coef: 0.4186\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5113 - accuracy: 0.9255 - IoU_coef: 0.5113 - val_loss: -0.4198 - val_accuracy: 0.9113 - val_IoU_coef: 0.4198\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5114 - accuracy: 0.9256 - IoU_coef: 0.5114 - val_loss: -0.4211 - val_accuracy: 0.9107 - val_IoU_coef: 0.4211\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5115 - accuracy: 0.9253 - IoU_coef: 0.5115 - val_loss: -0.4214 - val_accuracy: 0.9108 - val_IoU_coef: 0.4214\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5120 - accuracy: 0.9254 - IoU_coef: 0.5120 - val_loss: -0.4206 - val_accuracy: 0.9109 - val_IoU_coef: 0.4206\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5117 - accuracy: 0.9256 - IoU_coef: 0.5117 - val_loss: -0.4213 - val_accuracy: 0.9106 - val_IoU_coef: 0.4213\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5122 - accuracy: 0.9253 - IoU_coef: 0.5122 - val_loss: -0.4234 - val_accuracy: 0.9113 - val_IoU_coef: 0.4234\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5125 - accuracy: 0.9253 - IoU_coef: 0.5125 - val_loss: -0.4237 - val_accuracy: 0.9124 - val_IoU_coef: 0.4237\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5125 - accuracy: 0.9257 - IoU_coef: 0.5125 - val_loss: -0.4229 - val_accuracy: 0.9119 - val_IoU_coef: 0.4229\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5127 - accuracy: 0.9253 - IoU_coef: 0.5127 - val_loss: -0.4230 - val_accuracy: 0.9115 - val_IoU_coef: 0.4230\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5131 - accuracy: 0.9252 - IoU_coef: 0.5131 - val_loss: -0.4232 - val_accuracy: 0.9117 - val_IoU_coef: 0.4232\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5133 - accuracy: 0.9257 - IoU_coef: 0.5133 - val_loss: -0.4223 - val_accuracy: 0.9111 - val_IoU_coef: 0.4223\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5133 - accuracy: 0.9255 - IoU_coef: 0.5133 - val_loss: -0.4228 - val_accuracy: 0.9112 - val_IoU_coef: 0.4228\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5139 - accuracy: 0.9252 - IoU_coef: 0.5139 - val_loss: -0.4228 - val_accuracy: 0.9121 - val_IoU_coef: 0.4228\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5140 - accuracy: 0.9256 - IoU_coef: 0.5140 - val_loss: -0.4223 - val_accuracy: 0.9124 - val_IoU_coef: 0.4223\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5141 - accuracy: 0.9256 - IoU_coef: 0.5141 - val_loss: -0.4233 - val_accuracy: 0.9127 - val_IoU_coef: 0.4233\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5145 - accuracy: 0.9255 - IoU_coef: 0.5145 - val_loss: -0.4235 - val_accuracy: 0.9124 - val_IoU_coef: 0.4235\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5148 - accuracy: 0.9254 - IoU_coef: 0.5148 - val_loss: -0.4228 - val_accuracy: 0.9122 - val_IoU_coef: 0.4228\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5152 - accuracy: 0.9256 - IoU_coef: 0.5152 - val_loss: -0.4232 - val_accuracy: 0.9120 - val_IoU_coef: 0.4232\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5154 - accuracy: 0.9256 - IoU_coef: 0.5154 - val_loss: -0.4236 - val_accuracy: 0.9113 - val_IoU_coef: 0.4236\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5156 - accuracy: 0.9254 - IoU_coef: 0.5156 - val_loss: -0.4230 - val_accuracy: 0.9105 - val_IoU_coef: 0.4230\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5160 - accuracy: 0.9254 - IoU_coef: 0.5160 - val_loss: -0.4230 - val_accuracy: 0.9106 - val_IoU_coef: 0.4230\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5162 - accuracy: 0.9257 - IoU_coef: 0.5162 - val_loss: -0.4231 - val_accuracy: 0.9113 - val_IoU_coef: 0.4231\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5164 - accuracy: 0.9256 - IoU_coef: 0.5164 - val_loss: -0.4238 - val_accuracy: 0.9119 - val_IoU_coef: 0.4238\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5165 - accuracy: 0.9254 - IoU_coef: 0.5165 - val_loss: -0.4254 - val_accuracy: 0.9126 - val_IoU_coef: 0.4254\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5166 - accuracy: 0.9255 - IoU_coef: 0.5166 - val_loss: -0.4256 - val_accuracy: 0.9124 - val_IoU_coef: 0.4256\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5169 - accuracy: 0.9256 - IoU_coef: 0.5169 - val_loss: -0.4244 - val_accuracy: 0.9120 - val_IoU_coef: 0.4244\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5171 - accuracy: 0.9255 - IoU_coef: 0.5171 - val_loss: -0.4245 - val_accuracy: 0.9118 - val_IoU_coef: 0.4245\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5175 - accuracy: 0.9256 - IoU_coef: 0.5175 - val_loss: -0.4262 - val_accuracy: 0.9120 - val_IoU_coef: 0.4262\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5178 - accuracy: 0.9254 - IoU_coef: 0.5178 - val_loss: -0.4268 - val_accuracy: 0.9126 - val_IoU_coef: 0.4268\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5179 - accuracy: 0.9256 - IoU_coef: 0.5179 - val_loss: -0.4259 - val_accuracy: 0.9123 - val_IoU_coef: 0.4259\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5184 - accuracy: 0.9256 - IoU_coef: 0.5184 - val_loss: -0.4255 - val_accuracy: 0.9117 - val_IoU_coef: 0.4255\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5185 - accuracy: 0.9254 - IoU_coef: 0.5185 - val_loss: -0.4260 - val_accuracy: 0.9119 - val_IoU_coef: 0.4260\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5187 - accuracy: 0.9257 - IoU_coef: 0.5187 - val_loss: -0.4260 - val_accuracy: 0.9118 - val_IoU_coef: 0.4260\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5189 - accuracy: 0.9256 - IoU_coef: 0.5189 - val_loss: -0.4256 - val_accuracy: 0.9117 - val_IoU_coef: 0.4256\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5191 - accuracy: 0.9254 - IoU_coef: 0.5191 - val_loss: -0.4255 - val_accuracy: 0.9115 - val_IoU_coef: 0.4255\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5195 - accuracy: 0.9256 - IoU_coef: 0.5195 - val_loss: -0.4251 - val_accuracy: 0.9109 - val_IoU_coef: 0.4251\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5196 - accuracy: 0.9256 - IoU_coef: 0.5196 - val_loss: -0.4251 - val_accuracy: 0.9103 - val_IoU_coef: 0.4251\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5199 - accuracy: 0.9256 - IoU_coef: 0.5199 - val_loss: -0.4252 - val_accuracy: 0.9104 - val_IoU_coef: 0.4252\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5200 - accuracy: 0.9255 - IoU_coef: 0.5200 - val_loss: -0.4255 - val_accuracy: 0.9106 - val_IoU_coef: 0.4255\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5205 - accuracy: 0.9256 - IoU_coef: 0.5205 - val_loss: -0.4262 - val_accuracy: 0.9110 - val_IoU_coef: 0.4262\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5206 - accuracy: 0.9256 - IoU_coef: 0.5206 - val_loss: -0.4267 - val_accuracy: 0.9119 - val_IoU_coef: 0.4267\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5207 - accuracy: 0.9257 - IoU_coef: 0.5207 - val_loss: -0.4270 - val_accuracy: 0.9121 - val_IoU_coef: 0.4270\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5211 - accuracy: 0.9255 - IoU_coef: 0.5211 - val_loss: -0.4281 - val_accuracy: 0.9125 - val_IoU_coef: 0.4281\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5216 - accuracy: 0.9255 - IoU_coef: 0.5216 - val_loss: -0.4288 - val_accuracy: 0.9127 - val_IoU_coef: 0.4288\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5215 - accuracy: 0.9258 - IoU_coef: 0.5215 - val_loss: -0.4287 - val_accuracy: 0.9120 - val_IoU_coef: 0.4287\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.5219 - accuracy: 0.9257 - IoU_coef: 0.5219 - val_loss: -0.4290 - val_accuracy: 0.9113 - val_IoU_coef: 0.4290\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5220 - accuracy: 0.9254 - IoU_coef: 0.5220 - val_loss: -0.4295 - val_accuracy: 0.9114 - val_IoU_coef: 0.4295\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5223 - accuracy: 0.9257 - IoU_coef: 0.5223 - val_loss: -0.4296 - val_accuracy: 0.9114 - val_IoU_coef: 0.4296\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5226 - accuracy: 0.9257 - IoU_coef: 0.5226 - val_loss: -0.4301 - val_accuracy: 0.9117 - val_IoU_coef: 0.4301\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5229 - accuracy: 0.9256 - IoU_coef: 0.5229 - val_loss: -0.4303 - val_accuracy: 0.9122 - val_IoU_coef: 0.4303\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5231 - accuracy: 0.9256 - IoU_coef: 0.5231 - val_loss: -0.4294 - val_accuracy: 0.9120 - val_IoU_coef: 0.4294\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5233 - accuracy: 0.9256 - IoU_coef: 0.5233 - val_loss: -0.4291 - val_accuracy: 0.9121 - val_IoU_coef: 0.4291\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5237 - accuracy: 0.9256 - IoU_coef: 0.5237 - val_loss: -0.4298 - val_accuracy: 0.9124 - val_IoU_coef: 0.4298\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5236 - accuracy: 0.9256 - IoU_coef: 0.5236 - val_loss: -0.4308 - val_accuracy: 0.9125 - val_IoU_coef: 0.4308\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5240 - accuracy: 0.9256 - IoU_coef: 0.5240 - val_loss: -0.4315 - val_accuracy: 0.9128 - val_IoU_coef: 0.4315\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5243 - accuracy: 0.9256 - IoU_coef: 0.5243 - val_loss: -0.4314 - val_accuracy: 0.9129 - val_IoU_coef: 0.4314\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5243 - accuracy: 0.9256 - IoU_coef: 0.5243 - val_loss: -0.4315 - val_accuracy: 0.9127 - val_IoU_coef: 0.4315\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5246 - accuracy: 0.9255 - IoU_coef: 0.5246 - val_loss: -0.4325 - val_accuracy: 0.9126 - val_IoU_coef: 0.4325\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5249 - accuracy: 0.9257 - IoU_coef: 0.5249 - val_loss: -0.4326 - val_accuracy: 0.9123 - val_IoU_coef: 0.4326\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5250 - accuracy: 0.9257 - IoU_coef: 0.5250 - val_loss: -0.4314 - val_accuracy: 0.9120 - val_IoU_coef: 0.4314\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5254 - accuracy: 0.9256 - IoU_coef: 0.5254 - val_loss: -0.4320 - val_accuracy: 0.9124 - val_IoU_coef: 0.4320\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5256 - accuracy: 0.9256 - IoU_coef: 0.5256 - val_loss: -0.4321 - val_accuracy: 0.9121 - val_IoU_coef: 0.4321\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5257 - accuracy: 0.9256 - IoU_coef: 0.5257 - val_loss: -0.4328 - val_accuracy: 0.9121 - val_IoU_coef: 0.4328\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5258 - accuracy: 0.9256 - IoU_coef: 0.5258 - val_loss: -0.4336 - val_accuracy: 0.9119 - val_IoU_coef: 0.4336\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5263 - accuracy: 0.9256 - IoU_coef: 0.5263 - val_loss: -0.4335 - val_accuracy: 0.9119 - val_IoU_coef: 0.4335\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5267 - accuracy: 0.9256 - IoU_coef: 0.5267 - val_loss: -0.4325 - val_accuracy: 0.9120 - val_IoU_coef: 0.4325\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5268 - accuracy: 0.9258 - IoU_coef: 0.5268 - val_loss: -0.4323 - val_accuracy: 0.9118 - val_IoU_coef: 0.4323\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5270 - accuracy: 0.9256 - IoU_coef: 0.5270 - val_loss: -0.4330 - val_accuracy: 0.9120 - val_IoU_coef: 0.4330\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5270 - accuracy: 0.9255 - IoU_coef: 0.5270 - val_loss: -0.4333 - val_accuracy: 0.9128 - val_IoU_coef: 0.4333\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5274 - accuracy: 0.9258 - IoU_coef: 0.5274 - val_loss: -0.4333 - val_accuracy: 0.9126 - val_IoU_coef: 0.4333\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5275 - accuracy: 0.9256 - IoU_coef: 0.5275 - val_loss: -0.4336 - val_accuracy: 0.9126 - val_IoU_coef: 0.4336\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.5280 - accuracy: 0.9256 - IoU_coef: 0.5280 - val_loss: -0.4338 - val_accuracy: 0.9130 - val_IoU_coef: 0.4338\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5281 - accuracy: 0.9258 - IoU_coef: 0.5281 - val_loss: -0.4339 - val_accuracy: 0.9128 - val_IoU_coef: 0.4339\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5283 - accuracy: 0.9256 - IoU_coef: 0.5283 - val_loss: -0.4351 - val_accuracy: 0.9133 - val_IoU_coef: 0.4351\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5285 - accuracy: 0.9256 - IoU_coef: 0.5285 - val_loss: -0.4351 - val_accuracy: 0.9139 - val_IoU_coef: 0.4351\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5287 - accuracy: 0.9257 - IoU_coef: 0.5287 - val_loss: -0.4345 - val_accuracy: 0.9135 - val_IoU_coef: 0.4345\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5289 - accuracy: 0.9256 - IoU_coef: 0.5289 - val_loss: -0.4351 - val_accuracy: 0.9131 - val_IoU_coef: 0.4351\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5293 - accuracy: 0.9256 - IoU_coef: 0.5293 - val_loss: -0.4353 - val_accuracy: 0.9131 - val_IoU_coef: 0.4353\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5293 - accuracy: 0.9258 - IoU_coef: 0.5293 - val_loss: -0.4355 - val_accuracy: 0.9129 - val_IoU_coef: 0.4355\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5296 - accuracy: 0.9258 - IoU_coef: 0.5296 - val_loss: -0.4356 - val_accuracy: 0.9131 - val_IoU_coef: 0.4356\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5300 - accuracy: 0.9257 - IoU_coef: 0.5300 - val_loss: -0.4351 - val_accuracy: 0.9136 - val_IoU_coef: 0.4351\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5299 - accuracy: 0.9256 - IoU_coef: 0.5299 - val_loss: -0.4344 - val_accuracy: 0.9136 - val_IoU_coef: 0.4344\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5303 - accuracy: 0.9257 - IoU_coef: 0.5303 - val_loss: -0.4353 - val_accuracy: 0.9134 - val_IoU_coef: 0.4353\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5305 - accuracy: 0.9257 - IoU_coef: 0.5305 - val_loss: -0.4361 - val_accuracy: 0.9129 - val_IoU_coef: 0.4361\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5303 - accuracy: 0.9256 - IoU_coef: 0.5303 - val_loss: -0.4357 - val_accuracy: 0.9126 - val_IoU_coef: 0.4357\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5310 - accuracy: 0.9256 - IoU_coef: 0.5310 - val_loss: -0.4361 - val_accuracy: 0.9129 - val_IoU_coef: 0.4361\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5310 - accuracy: 0.9258 - IoU_coef: 0.5310 - val_loss: -0.4372 - val_accuracy: 0.9131 - val_IoU_coef: 0.4372\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5312 - accuracy: 0.9257 - IoU_coef: 0.5312 - val_loss: -0.4369 - val_accuracy: 0.9129 - val_IoU_coef: 0.4369\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5317 - accuracy: 0.9256 - IoU_coef: 0.5317 - val_loss: -0.4372 - val_accuracy: 0.9130 - val_IoU_coef: 0.4372\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5318 - accuracy: 0.9258 - IoU_coef: 0.5318 - val_loss: -0.4380 - val_accuracy: 0.9126 - val_IoU_coef: 0.4380\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5319 - accuracy: 0.9258 - IoU_coef: 0.5319 - val_loss: -0.4378 - val_accuracy: 0.9122 - val_IoU_coef: 0.4378\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5324 - accuracy: 0.9256 - IoU_coef: 0.5324 - val_loss: -0.4374 - val_accuracy: 0.9124 - val_IoU_coef: 0.4374\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5325 - accuracy: 0.9257 - IoU_coef: 0.5325 - val_loss: -0.4390 - val_accuracy: 0.9127 - val_IoU_coef: 0.4390\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5330 - accuracy: 0.9259 - IoU_coef: 0.5330 - val_loss: -0.4394 - val_accuracy: 0.9120 - val_IoU_coef: 0.4394\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5329 - accuracy: 0.9256 - IoU_coef: 0.5329 - val_loss: -0.4388 - val_accuracy: 0.9120 - val_IoU_coef: 0.4388\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5334 - accuracy: 0.9256 - IoU_coef: 0.5334 - val_loss: -0.4392 - val_accuracy: 0.9124 - val_IoU_coef: 0.4392\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5334 - accuracy: 0.9259 - IoU_coef: 0.5334 - val_loss: -0.4398 - val_accuracy: 0.9122 - val_IoU_coef: 0.4398\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5337 - accuracy: 0.9257 - IoU_coef: 0.5337 - val_loss: -0.4392 - val_accuracy: 0.9121 - val_IoU_coef: 0.4392\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5338 - accuracy: 0.9257 - IoU_coef: 0.5338 - val_loss: -0.4389 - val_accuracy: 0.9123 - val_IoU_coef: 0.4389\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5340 - accuracy: 0.9258 - IoU_coef: 0.5340 - val_loss: -0.4393 - val_accuracy: 0.9124 - val_IoU_coef: 0.4393\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5344 - accuracy: 0.9257 - IoU_coef: 0.5344 - val_loss: -0.4397 - val_accuracy: 0.9126 - val_IoU_coef: 0.4397\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5346 - accuracy: 0.9257 - IoU_coef: 0.5346 - val_loss: -0.4398 - val_accuracy: 0.9129 - val_IoU_coef: 0.4398\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5350 - accuracy: 0.9258 - IoU_coef: 0.5350 - val_loss: -0.4395 - val_accuracy: 0.9130 - val_IoU_coef: 0.4395\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5349 - accuracy: 0.9257 - IoU_coef: 0.5349 - val_loss: -0.4405 - val_accuracy: 0.9127 - val_IoU_coef: 0.4405\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 487ms/step - loss: -0.5353 - accuracy: 0.9255 - IoU_coef: 0.5353 - val_loss: -0.4410 - val_accuracy: 0.9131 - val_IoU_coef: 0.4410\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5356 - accuracy: 0.9258 - IoU_coef: 0.5356 - val_loss: -0.4407 - val_accuracy: 0.9133 - val_IoU_coef: 0.4407\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5360 - accuracy: 0.9259 - IoU_coef: 0.5360 - val_loss: -0.4402 - val_accuracy: 0.9131 - val_IoU_coef: 0.4402\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.5361 - accuracy: 0.9257 - IoU_coef: 0.5361 - val_loss: -0.4403 - val_accuracy: 0.9130 - val_IoU_coef: 0.4403\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5364 - accuracy: 0.9256 - IoU_coef: 0.5364 - val_loss: -0.4407 - val_accuracy: 0.9130 - val_IoU_coef: 0.4407\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5364 - accuracy: 0.9259 - IoU_coef: 0.5364 - val_loss: -0.4416 - val_accuracy: 0.9131 - val_IoU_coef: 0.4416\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5367 - accuracy: 0.9258 - IoU_coef: 0.5367 - val_loss: -0.4418 - val_accuracy: 0.9133 - val_IoU_coef: 0.4418\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5370 - accuracy: 0.9257 - IoU_coef: 0.5370 - val_loss: -0.4421 - val_accuracy: 0.9137 - val_IoU_coef: 0.4421\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5374 - accuracy: 0.9258 - IoU_coef: 0.5374 - val_loss: -0.4422 - val_accuracy: 0.9136 - val_IoU_coef: 0.4422\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5374 - accuracy: 0.9258 - IoU_coef: 0.5374 - val_loss: -0.4412 - val_accuracy: 0.9135 - val_IoU_coef: 0.4412\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5377 - accuracy: 0.9258 - IoU_coef: 0.5377 - val_loss: -0.4407 - val_accuracy: 0.9136 - val_IoU_coef: 0.4407\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: -0.5379 - accuracy: 0.9258 - IoU_coef: 0.5379 - val_loss: -0.4412 - val_accuracy: 0.9132 - val_IoU_coef: 0.4412\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5382 - accuracy: 0.9258 - IoU_coef: 0.5382 - val_loss: -0.4415 - val_accuracy: 0.9135 - val_IoU_coef: 0.4415\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5385 - accuracy: 0.9258 - IoU_coef: 0.5385 - val_loss: -0.4418 - val_accuracy: 0.9136 - val_IoU_coef: 0.4418\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5386 - accuracy: 0.9258 - IoU_coef: 0.5386 - val_loss: -0.4429 - val_accuracy: 0.9132 - val_IoU_coef: 0.4429\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.5386 - accuracy: 0.9257 - IoU_coef: 0.5386 - val_loss: -0.4436 - val_accuracy: 0.9132 - val_IoU_coef: 0.4436\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5392 - accuracy: 0.9258 - IoU_coef: 0.5392 - val_loss: -0.4435 - val_accuracy: 0.9134 - val_IoU_coef: 0.4435\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5390 - accuracy: 0.9259 - IoU_coef: 0.5390 - val_loss: -0.4435 - val_accuracy: 0.9137 - val_IoU_coef: 0.4435\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5392 - accuracy: 0.9257 - IoU_coef: 0.5392 - val_loss: -0.4437 - val_accuracy: 0.9138 - val_IoU_coef: 0.4437\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5397 - accuracy: 0.9258 - IoU_coef: 0.5397 - val_loss: -0.4436 - val_accuracy: 0.9133 - val_IoU_coef: 0.4436\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5397 - accuracy: 0.9259 - IoU_coef: 0.5397 - val_loss: -0.4432 - val_accuracy: 0.9124 - val_IoU_coef: 0.4432\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5401 - accuracy: 0.9257 - IoU_coef: 0.5401 - val_loss: -0.4435 - val_accuracy: 0.9123 - val_IoU_coef: 0.4435\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5402 - accuracy: 0.9257 - IoU_coef: 0.5402 - val_loss: -0.4431 - val_accuracy: 0.9120 - val_IoU_coef: 0.4431\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5408 - accuracy: 0.9258 - IoU_coef: 0.5408 - val_loss: -0.4438 - val_accuracy: 0.9123 - val_IoU_coef: 0.4438\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5408 - accuracy: 0.9259 - IoU_coef: 0.5408 - val_loss: -0.4453 - val_accuracy: 0.9130 - val_IoU_coef: 0.4453\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5412 - accuracy: 0.9258 - IoU_coef: 0.5412 - val_loss: -0.4455 - val_accuracy: 0.9136 - val_IoU_coef: 0.4455\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5411 - accuracy: 0.9258 - IoU_coef: 0.5411 - val_loss: -0.4441 - val_accuracy: 0.9137 - val_IoU_coef: 0.4441\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5413 - accuracy: 0.9258 - IoU_coef: 0.5413 - val_loss: -0.4441 - val_accuracy: 0.9137 - val_IoU_coef: 0.4441\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5417 - accuracy: 0.9259 - IoU_coef: 0.5417 - val_loss: -0.4450 - val_accuracy: 0.9137 - val_IoU_coef: 0.4450\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5419 - accuracy: 0.9258 - IoU_coef: 0.5419 - val_loss: -0.4458 - val_accuracy: 0.9134 - val_IoU_coef: 0.4458\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5420 - accuracy: 0.9258 - IoU_coef: 0.5420 - val_loss: -0.4466 - val_accuracy: 0.9135 - val_IoU_coef: 0.4466\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5423 - accuracy: 0.9259 - IoU_coef: 0.5423 - val_loss: -0.4464 - val_accuracy: 0.9137 - val_IoU_coef: 0.4464\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5426 - accuracy: 0.9259 - IoU_coef: 0.5426 - val_loss: -0.4462 - val_accuracy: 0.9136 - val_IoU_coef: 0.4462\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5428 - accuracy: 0.9258 - IoU_coef: 0.5428 - val_loss: -0.4467 - val_accuracy: 0.9137 - val_IoU_coef: 0.4467\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5430 - accuracy: 0.9259 - IoU_coef: 0.5430 - val_loss: -0.4474 - val_accuracy: 0.9138 - val_IoU_coef: 0.4474\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5432 - accuracy: 0.9258 - IoU_coef: 0.5432 - val_loss: -0.4471 - val_accuracy: 0.9141 - val_IoU_coef: 0.4471\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5434 - accuracy: 0.9259 - IoU_coef: 0.5434 - val_loss: -0.4468 - val_accuracy: 0.9142 - val_IoU_coef: 0.4468\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5435 - accuracy: 0.9259 - IoU_coef: 0.5435 - val_loss: -0.4466 - val_accuracy: 0.9141 - val_IoU_coef: 0.4466\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5439 - accuracy: 0.9259 - IoU_coef: 0.5439 - val_loss: -0.4465 - val_accuracy: 0.9139 - val_IoU_coef: 0.4465\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5440 - accuracy: 0.9258 - IoU_coef: 0.5440 - val_loss: -0.4463 - val_accuracy: 0.9137 - val_IoU_coef: 0.4463\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5445 - accuracy: 0.9258 - IoU_coef: 0.5445 - val_loss: -0.4467 - val_accuracy: 0.9138 - val_IoU_coef: 0.4467\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5445 - accuracy: 0.9259 - IoU_coef: 0.5445 - val_loss: -0.4474 - val_accuracy: 0.9137 - val_IoU_coef: 0.4474\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5448 - accuracy: 0.9258 - IoU_coef: 0.5448 - val_loss: -0.4470 - val_accuracy: 0.9139 - val_IoU_coef: 0.4470\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5450 - accuracy: 0.9259 - IoU_coef: 0.5450 - val_loss: -0.4466 - val_accuracy: 0.9139 - val_IoU_coef: 0.4466\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5454 - accuracy: 0.9259 - IoU_coef: 0.5454 - val_loss: -0.4465 - val_accuracy: 0.9139 - val_IoU_coef: 0.4465\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5453 - accuracy: 0.9259 - IoU_coef: 0.5453 - val_loss: -0.4462 - val_accuracy: 0.9137 - val_IoU_coef: 0.4462\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5458 - accuracy: 0.9259 - IoU_coef: 0.5458 - val_loss: -0.4469 - val_accuracy: 0.9139 - val_IoU_coef: 0.4469\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5457 - accuracy: 0.9259 - IoU_coef: 0.5457 - val_loss: -0.4480 - val_accuracy: 0.9138 - val_IoU_coef: 0.4480\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5460 - accuracy: 0.9259 - IoU_coef: 0.5460 - val_loss: -0.4481 - val_accuracy: 0.9133 - val_IoU_coef: 0.4481\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5462 - accuracy: 0.9258 - IoU_coef: 0.5462 - val_loss: -0.4478 - val_accuracy: 0.9132 - val_IoU_coef: 0.4478\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5464 - accuracy: 0.9259 - IoU_coef: 0.5464 - val_loss: -0.4479 - val_accuracy: 0.9128 - val_IoU_coef: 0.4479\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5467 - accuracy: 0.9260 - IoU_coef: 0.5467 - val_loss: -0.4478 - val_accuracy: 0.9122 - val_IoU_coef: 0.4478\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5469 - accuracy: 0.9258 - IoU_coef: 0.5469 - val_loss: -0.4483 - val_accuracy: 0.9125 - val_IoU_coef: 0.4483\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5472 - accuracy: 0.9259 - IoU_coef: 0.5472 - val_loss: -0.4489 - val_accuracy: 0.9128 - val_IoU_coef: 0.4489\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5473 - accuracy: 0.9260 - IoU_coef: 0.5473 - val_loss: -0.4486 - val_accuracy: 0.9119 - val_IoU_coef: 0.4486\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5475 - accuracy: 0.9257 - IoU_coef: 0.5475 - val_loss: -0.4481 - val_accuracy: 0.9117 - val_IoU_coef: 0.4481\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5477 - accuracy: 0.9260 - IoU_coef: 0.5477 - val_loss: -0.4470 - val_accuracy: 0.9115 - val_IoU_coef: 0.4470\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5478 - accuracy: 0.9260 - IoU_coef: 0.5478 - val_loss: -0.4481 - val_accuracy: 0.9118 - val_IoU_coef: 0.4481\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5482 - accuracy: 0.9256 - IoU_coef: 0.5482 - val_loss: -0.4495 - val_accuracy: 0.9132 - val_IoU_coef: 0.4495\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5484 - accuracy: 0.9259 - IoU_coef: 0.5484 - val_loss: -0.4493 - val_accuracy: 0.9136 - val_IoU_coef: 0.4493\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5486 - accuracy: 0.9260 - IoU_coef: 0.5486 - val_loss: -0.4491 - val_accuracy: 0.9128 - val_IoU_coef: 0.4491\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5489 - accuracy: 0.9258 - IoU_coef: 0.5489 - val_loss: -0.4488 - val_accuracy: 0.9126 - val_IoU_coef: 0.4488\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5491 - accuracy: 0.9259 - IoU_coef: 0.5491 - val_loss: -0.4486 - val_accuracy: 0.9132 - val_IoU_coef: 0.4486\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5493 - accuracy: 0.9260 - IoU_coef: 0.5493 - val_loss: -0.4497 - val_accuracy: 0.9134 - val_IoU_coef: 0.4497\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5495 - accuracy: 0.9259 - IoU_coef: 0.5495 - val_loss: -0.4505 - val_accuracy: 0.9141 - val_IoU_coef: 0.4505\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5498 - accuracy: 0.9259 - IoU_coef: 0.5498 - val_loss: -0.4504 - val_accuracy: 0.9145 - val_IoU_coef: 0.4504\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5499 - accuracy: 0.9261 - IoU_coef: 0.5499 - val_loss: -0.4511 - val_accuracy: 0.9140 - val_IoU_coef: 0.4511\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5503 - accuracy: 0.9259 - IoU_coef: 0.5503 - val_loss: -0.4511 - val_accuracy: 0.9136 - val_IoU_coef: 0.4511\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5504 - accuracy: 0.9259 - IoU_coef: 0.5504 - val_loss: -0.4510 - val_accuracy: 0.9131 - val_IoU_coef: 0.4510\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5505 - accuracy: 0.9260 - IoU_coef: 0.5505 - val_loss: -0.4519 - val_accuracy: 0.9130 - val_IoU_coef: 0.4519\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5507 - accuracy: 0.9259 - IoU_coef: 0.5507 - val_loss: -0.4528 - val_accuracy: 0.9133 - val_IoU_coef: 0.4528\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5508 - accuracy: 0.9259 - IoU_coef: 0.5508 - val_loss: -0.4526 - val_accuracy: 0.9129 - val_IoU_coef: 0.4526\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5510 - accuracy: 0.9259 - IoU_coef: 0.5510 - val_loss: -0.4527 - val_accuracy: 0.9125 - val_IoU_coef: 0.4527\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5513 - accuracy: 0.9259 - IoU_coef: 0.5513 - val_loss: -0.4531 - val_accuracy: 0.9124 - val_IoU_coef: 0.4531\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5517 - accuracy: 0.9260 - IoU_coef: 0.5517 - val_loss: -0.4532 - val_accuracy: 0.9126 - val_IoU_coef: 0.4532\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5517 - accuracy: 0.9259 - IoU_coef: 0.5517 - val_loss: -0.4539 - val_accuracy: 0.9132 - val_IoU_coef: 0.4539\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5520 - accuracy: 0.9259 - IoU_coef: 0.5520 - val_loss: -0.4548 - val_accuracy: 0.9137 - val_IoU_coef: 0.4548\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -0.5525 - accuracy: 0.9260 - IoU_coef: 0.5525 - val_loss: -0.4547 - val_accuracy: 0.9136 - val_IoU_coef: 0.4547\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5524 - accuracy: 0.9260 - IoU_coef: 0.5524 - val_loss: -0.4543 - val_accuracy: 0.9129 - val_IoU_coef: 0.4543\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5526 - accuracy: 0.9259 - IoU_coef: 0.5526 - val_loss: -0.4539 - val_accuracy: 0.9129 - val_IoU_coef: 0.4539\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5528 - accuracy: 0.9260 - IoU_coef: 0.5528 - val_loss: -0.4540 - val_accuracy: 0.9128 - val_IoU_coef: 0.4540\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5530 - accuracy: 0.9261 - IoU_coef: 0.5530 - val_loss: -0.4549 - val_accuracy: 0.9127 - val_IoU_coef: 0.4549\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5531 - accuracy: 0.9258 - IoU_coef: 0.5531 - val_loss: -0.4561 - val_accuracy: 0.9129 - val_IoU_coef: 0.4561\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5535 - accuracy: 0.9260 - IoU_coef: 0.5535 - val_loss: -0.4560 - val_accuracy: 0.9128 - val_IoU_coef: 0.4560\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5537 - accuracy: 0.9260 - IoU_coef: 0.5537 - val_loss: -0.4557 - val_accuracy: 0.9125 - val_IoU_coef: 0.4557\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5538 - accuracy: 0.9259 - IoU_coef: 0.5538 - val_loss: -0.4561 - val_accuracy: 0.9128 - val_IoU_coef: 0.4561\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5541 - accuracy: 0.9259 - IoU_coef: 0.5541 - val_loss: -0.4570 - val_accuracy: 0.9133 - val_IoU_coef: 0.4570\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5541 - accuracy: 0.9260 - IoU_coef: 0.5541 - val_loss: -0.4569 - val_accuracy: 0.9132 - val_IoU_coef: 0.4569\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5545 - accuracy: 0.9259 - IoU_coef: 0.5545 - val_loss: -0.4568 - val_accuracy: 0.9132 - val_IoU_coef: 0.4568\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5550 - accuracy: 0.9259 - IoU_coef: 0.5550 - val_loss: -0.4573 - val_accuracy: 0.9134 - val_IoU_coef: 0.4573\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5548 - accuracy: 0.9261 - IoU_coef: 0.5548 - val_loss: -0.4579 - val_accuracy: 0.9129 - val_IoU_coef: 0.4579\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5551 - accuracy: 0.9260 - IoU_coef: 0.5551 - val_loss: -0.4578 - val_accuracy: 0.9123 - val_IoU_coef: 0.4578\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5554 - accuracy: 0.9258 - IoU_coef: 0.5554 - val_loss: -0.4577 - val_accuracy: 0.9130 - val_IoU_coef: 0.4577\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5556 - accuracy: 0.9260 - IoU_coef: 0.5556 - val_loss: -0.4580 - val_accuracy: 0.9135 - val_IoU_coef: 0.4580\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5558 - accuracy: 0.9261 - IoU_coef: 0.5558 - val_loss: -0.4582 - val_accuracy: 0.9137 - val_IoU_coef: 0.4582\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5561 - accuracy: 0.9259 - IoU_coef: 0.5561 - val_loss: -0.4582 - val_accuracy: 0.9142 - val_IoU_coef: 0.4582\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5562 - accuracy: 0.9260 - IoU_coef: 0.5562 - val_loss: -0.4589 - val_accuracy: 0.9139 - val_IoU_coef: 0.4589\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5564 - accuracy: 0.9260 - IoU_coef: 0.5564 - val_loss: -0.4591 - val_accuracy: 0.9137 - val_IoU_coef: 0.4591\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5565 - accuracy: 0.9260 - IoU_coef: 0.5565 - val_loss: -0.4602 - val_accuracy: 0.9140 - val_IoU_coef: 0.4602\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5569 - accuracy: 0.9261 - IoU_coef: 0.5569 - val_loss: -0.4613 - val_accuracy: 0.9142 - val_IoU_coef: 0.4613\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5571 - accuracy: 0.9260 - IoU_coef: 0.5571 - val_loss: -0.4618 - val_accuracy: 0.9139 - val_IoU_coef: 0.4618\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5574 - accuracy: 0.9259 - IoU_coef: 0.5574 - val_loss: -0.4614 - val_accuracy: 0.9136 - val_IoU_coef: 0.4614\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5576 - accuracy: 0.9260 - IoU_coef: 0.5576 - val_loss: -0.4607 - val_accuracy: 0.9133 - val_IoU_coef: 0.4607\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5577 - accuracy: 0.9260 - IoU_coef: 0.5577 - val_loss: -0.4607 - val_accuracy: 0.9128 - val_IoU_coef: 0.4607\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5581 - accuracy: 0.9260 - IoU_coef: 0.5581 - val_loss: -0.4617 - val_accuracy: 0.9130 - val_IoU_coef: 0.4617\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5582 - accuracy: 0.9261 - IoU_coef: 0.5582 - val_loss: -0.4619 - val_accuracy: 0.9133 - val_IoU_coef: 0.4619\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5585 - accuracy: 0.9259 - IoU_coef: 0.5585 - val_loss: -0.4617 - val_accuracy: 0.9135 - val_IoU_coef: 0.4617\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5588 - accuracy: 0.9260 - IoU_coef: 0.5588 - val_loss: -0.4614 - val_accuracy: 0.9136 - val_IoU_coef: 0.4614\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5589 - accuracy: 0.9261 - IoU_coef: 0.5589 - val_loss: -0.4618 - val_accuracy: 0.9133 - val_IoU_coef: 0.4618\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5592 - accuracy: 0.9261 - IoU_coef: 0.5592 - val_loss: -0.4615 - val_accuracy: 0.9129 - val_IoU_coef: 0.4615\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5592 - accuracy: 0.9260 - IoU_coef: 0.5592 - val_loss: -0.4613 - val_accuracy: 0.9132 - val_IoU_coef: 0.4613\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5595 - accuracy: 0.9260 - IoU_coef: 0.5595 - val_loss: -0.4626 - val_accuracy: 0.9139 - val_IoU_coef: 0.4626\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5596 - accuracy: 0.9261 - IoU_coef: 0.5596 - val_loss: -0.4637 - val_accuracy: 0.9138 - val_IoU_coef: 0.4637\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5598 - accuracy: 0.9260 - IoU_coef: 0.5598 - val_loss: -0.4628 - val_accuracy: 0.9135 - val_IoU_coef: 0.4628\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5600 - accuracy: 0.9259 - IoU_coef: 0.5600 - val_loss: -0.4634 - val_accuracy: 0.9135 - val_IoU_coef: 0.4634\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5603 - accuracy: 0.9261 - IoU_coef: 0.5603 - val_loss: -0.4639 - val_accuracy: 0.9133 - val_IoU_coef: 0.4639\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5606 - accuracy: 0.9260 - IoU_coef: 0.5606 - val_loss: -0.4633 - val_accuracy: 0.9135 - val_IoU_coef: 0.4633\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5609 - accuracy: 0.9260 - IoU_coef: 0.5609 - val_loss: -0.4624 - val_accuracy: 0.9140 - val_IoU_coef: 0.4624\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5611 - accuracy: 0.9261 - IoU_coef: 0.5611 - val_loss: -0.4632 - val_accuracy: 0.9142 - val_IoU_coef: 0.4632\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5611 - accuracy: 0.9259 - IoU_coef: 0.5611 - val_loss: -0.4630 - val_accuracy: 0.9147 - val_IoU_coef: 0.4630\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5614 - accuracy: 0.9260 - IoU_coef: 0.5614 - val_loss: -0.4616 - val_accuracy: 0.9150 - val_IoU_coef: 0.4616\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5616 - accuracy: 0.9262 - IoU_coef: 0.5616 - val_loss: -0.4624 - val_accuracy: 0.9147 - val_IoU_coef: 0.4624\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5621 - accuracy: 0.9260 - IoU_coef: 0.5621 - val_loss: -0.4638 - val_accuracy: 0.9143 - val_IoU_coef: 0.4638\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5620 - accuracy: 0.9260 - IoU_coef: 0.5620 - val_loss: -0.4639 - val_accuracy: 0.9143 - val_IoU_coef: 0.4639\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5623 - accuracy: 0.9261 - IoU_coef: 0.5623 - val_loss: -0.4639 - val_accuracy: 0.9142 - val_IoU_coef: 0.4639\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5623 - accuracy: 0.9261 - IoU_coef: 0.5623 - val_loss: -0.4643 - val_accuracy: 0.9143 - val_IoU_coef: 0.4643\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5628 - accuracy: 0.9260 - IoU_coef: 0.5628 - val_loss: -0.4639 - val_accuracy: 0.9145 - val_IoU_coef: 0.4639\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5628 - accuracy: 0.9260 - IoU_coef: 0.5628 - val_loss: -0.4638 - val_accuracy: 0.9144 - val_IoU_coef: 0.4638\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5630 - accuracy: 0.9261 - IoU_coef: 0.5630 - val_loss: -0.4648 - val_accuracy: 0.9139 - val_IoU_coef: 0.4648\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5634 - accuracy: 0.9260 - IoU_coef: 0.5634 - val_loss: -0.4650 - val_accuracy: 0.9135 - val_IoU_coef: 0.4650\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5633 - accuracy: 0.9260 - IoU_coef: 0.5633 - val_loss: -0.4649 - val_accuracy: 0.9135 - val_IoU_coef: 0.4649\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5636 - accuracy: 0.9261 - IoU_coef: 0.5636 - val_loss: -0.4653 - val_accuracy: 0.9133 - val_IoU_coef: 0.4653\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5639 - accuracy: 0.9260 - IoU_coef: 0.5639 - val_loss: -0.4663 - val_accuracy: 0.9135 - val_IoU_coef: 0.4663\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5642 - accuracy: 0.9260 - IoU_coef: 0.5642 - val_loss: -0.4670 - val_accuracy: 0.9132 - val_IoU_coef: 0.4670\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5642 - accuracy: 0.9261 - IoU_coef: 0.5642 - val_loss: -0.4667 - val_accuracy: 0.9130 - val_IoU_coef: 0.4667\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -0.5645 - accuracy: 0.9261 - IoU_coef: 0.5645 - val_loss: -0.4665 - val_accuracy: 0.9132 - val_IoU_coef: 0.4665\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5647 - accuracy: 0.9260 - IoU_coef: 0.5647 - val_loss: -0.4669 - val_accuracy: 0.9137 - val_IoU_coef: 0.4669\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5646 - accuracy: 0.9260 - IoU_coef: 0.5646 - val_loss: -0.4674 - val_accuracy: 0.9139 - val_IoU_coef: 0.4674\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5651 - accuracy: 0.9261 - IoU_coef: 0.5651 - val_loss: -0.4677 - val_accuracy: 0.9139 - val_IoU_coef: 0.4677\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5653 - accuracy: 0.9262 - IoU_coef: 0.5653 - val_loss: -0.4679 - val_accuracy: 0.9136 - val_IoU_coef: 0.4679\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5653 - accuracy: 0.9260 - IoU_coef: 0.5653 - val_loss: -0.4679 - val_accuracy: 0.9139 - val_IoU_coef: 0.4679\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5657 - accuracy: 0.9260 - IoU_coef: 0.5657 - val_loss: -0.4674 - val_accuracy: 0.9145 - val_IoU_coef: 0.4674\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5656 - accuracy: 0.9263 - IoU_coef: 0.5656 - val_loss: -0.4679 - val_accuracy: 0.9145 - val_IoU_coef: 0.4679\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5661 - accuracy: 0.9261 - IoU_coef: 0.5661 - val_loss: -0.4687 - val_accuracy: 0.9144 - val_IoU_coef: 0.4687\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5662 - accuracy: 0.9260 - IoU_coef: 0.5662 - val_loss: -0.4690 - val_accuracy: 0.9145 - val_IoU_coef: 0.4690\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5665 - accuracy: 0.9262 - IoU_coef: 0.5665 - val_loss: -0.4691 - val_accuracy: 0.9143 - val_IoU_coef: 0.4691\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: -0.5665 - accuracy: 0.9262 - IoU_coef: 0.5665 - val_loss: -0.4691 - val_accuracy: 0.9140 - val_IoU_coef: 0.4691\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5668 - accuracy: 0.9260 - IoU_coef: 0.5668 - val_loss: -0.4688 - val_accuracy: 0.9140 - val_IoU_coef: 0.4688\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5670 - accuracy: 0.9260 - IoU_coef: 0.5670 - val_loss: -0.4693 - val_accuracy: 0.9138 - val_IoU_coef: 0.4693\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5670 - accuracy: 0.9261 - IoU_coef: 0.5670 - val_loss: -0.4700 - val_accuracy: 0.9134 - val_IoU_coef: 0.4700\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5676 - accuracy: 0.9260 - IoU_coef: 0.5676 - val_loss: -0.4698 - val_accuracy: 0.9131 - val_IoU_coef: 0.4698\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5678 - accuracy: 0.9262 - IoU_coef: 0.5678 - val_loss: -0.4693 - val_accuracy: 0.9131 - val_IoU_coef: 0.4693\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5679 - accuracy: 0.9262 - IoU_coef: 0.5679 - val_loss: -0.4689 - val_accuracy: 0.9129 - val_IoU_coef: 0.4689\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5681 - accuracy: 0.9261 - IoU_coef: 0.5681 - val_loss: -0.4692 - val_accuracy: 0.9133 - val_IoU_coef: 0.4692\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.5683 - accuracy: 0.9261 - IoU_coef: 0.5683 - val_loss: -0.4699 - val_accuracy: 0.9135 - val_IoU_coef: 0.4699\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5684 - accuracy: 0.9261 - IoU_coef: 0.5684 - val_loss: -0.4708 - val_accuracy: 0.9135 - val_IoU_coef: 0.4708\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5687 - accuracy: 0.9261 - IoU_coef: 0.5687 - val_loss: -0.4712 - val_accuracy: 0.9134 - val_IoU_coef: 0.4712\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5691 - accuracy: 0.9262 - IoU_coef: 0.5691 - val_loss: -0.4706 - val_accuracy: 0.9133 - val_IoU_coef: 0.4706\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5691 - accuracy: 0.9261 - IoU_coef: 0.5691 - val_loss: -0.4700 - val_accuracy: 0.9135 - val_IoU_coef: 0.4700\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5690 - accuracy: 0.9261 - IoU_coef: 0.5690 - val_loss: -0.4711 - val_accuracy: 0.9137 - val_IoU_coef: 0.4711\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5696 - accuracy: 0.9262 - IoU_coef: 0.5696 - val_loss: -0.4717 - val_accuracy: 0.9137 - val_IoU_coef: 0.4717\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5695 - accuracy: 0.9261 - IoU_coef: 0.5695 - val_loss: -0.4706 - val_accuracy: 0.9139 - val_IoU_coef: 0.4706\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5696 - accuracy: 0.9261 - IoU_coef: 0.5696 - val_loss: -0.4706 - val_accuracy: 0.9142 - val_IoU_coef: 0.4706\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5702 - accuracy: 0.9262 - IoU_coef: 0.5702 - val_loss: -0.4707 - val_accuracy: 0.9141 - val_IoU_coef: 0.4707\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5700 - accuracy: 0.9261 - IoU_coef: 0.5700 - val_loss: -0.4702 - val_accuracy: 0.9139 - val_IoU_coef: 0.4702\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5702 - accuracy: 0.9260 - IoU_coef: 0.5702 - val_loss: -0.4703 - val_accuracy: 0.9143 - val_IoU_coef: 0.4703\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5705 - accuracy: 0.9263 - IoU_coef: 0.5705 - val_loss: -0.4705 - val_accuracy: 0.9139 - val_IoU_coef: 0.4705\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.5706 - accuracy: 0.9260 - IoU_coef: 0.5706 - val_loss: -0.4700 - val_accuracy: 0.9138 - val_IoU_coef: 0.4700\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5710 - accuracy: 0.9260 - IoU_coef: 0.5710 - val_loss: -0.4705 - val_accuracy: 0.9143 - val_IoU_coef: 0.4705\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5712 - accuracy: 0.9263 - IoU_coef: 0.5712 - val_loss: -0.4717 - val_accuracy: 0.9140 - val_IoU_coef: 0.4717\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5717 - accuracy: 0.9261 - IoU_coef: 0.5717 - val_loss: -0.4720 - val_accuracy: 0.9137 - val_IoU_coef: 0.4720\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5714 - accuracy: 0.9261 - IoU_coef: 0.5714 - val_loss: -0.4718 - val_accuracy: 0.9139 - val_IoU_coef: 0.4718\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5717 - accuracy: 0.9262 - IoU_coef: 0.5717 - val_loss: -0.4707 - val_accuracy: 0.9136 - val_IoU_coef: 0.4707\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5720 - accuracy: 0.9261 - IoU_coef: 0.5720 - val_loss: -0.4706 - val_accuracy: 0.9138 - val_IoU_coef: 0.4706\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5721 - accuracy: 0.9261 - IoU_coef: 0.5721 - val_loss: -0.4707 - val_accuracy: 0.9137 - val_IoU_coef: 0.4707\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5726 - accuracy: 0.9262 - IoU_coef: 0.5726 - val_loss: -0.4708 - val_accuracy: 0.9131 - val_IoU_coef: 0.4708\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5726 - accuracy: 0.9260 - IoU_coef: 0.5726 - val_loss: -0.4711 - val_accuracy: 0.9133 - val_IoU_coef: 0.4711\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5728 - accuracy: 0.9262 - IoU_coef: 0.5728 - val_loss: -0.4713 - val_accuracy: 0.9137 - val_IoU_coef: 0.4713\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5731 - accuracy: 0.9262 - IoU_coef: 0.5731 - val_loss: -0.4710 - val_accuracy: 0.9140 - val_IoU_coef: 0.4710\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5733 - accuracy: 0.9261 - IoU_coef: 0.5733 - val_loss: -0.4708 - val_accuracy: 0.9142 - val_IoU_coef: 0.4708\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5733 - accuracy: 0.9262 - IoU_coef: 0.5733 - val_loss: -0.4716 - val_accuracy: 0.9145 - val_IoU_coef: 0.4716\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5736 - accuracy: 0.9262 - IoU_coef: 0.5736 - val_loss: -0.4722 - val_accuracy: 0.9146 - val_IoU_coef: 0.4722\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5738 - accuracy: 0.9261 - IoU_coef: 0.5738 - val_loss: -0.4718 - val_accuracy: 0.9149 - val_IoU_coef: 0.4718\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5742 - accuracy: 0.9262 - IoU_coef: 0.5742 - val_loss: -0.4712 - val_accuracy: 0.9147 - val_IoU_coef: 0.4712\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5743 - accuracy: 0.9262 - IoU_coef: 0.5743 - val_loss: -0.4718 - val_accuracy: 0.9143 - val_IoU_coef: 0.4718\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5745 - accuracy: 0.9261 - IoU_coef: 0.5745 - val_loss: -0.4717 - val_accuracy: 0.9142 - val_IoU_coef: 0.4717\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5747 - accuracy: 0.9262 - IoU_coef: 0.5747 - val_loss: -0.4718 - val_accuracy: 0.9143 - val_IoU_coef: 0.4718\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5747 - accuracy: 0.9262 - IoU_coef: 0.5747 - val_loss: -0.4717 - val_accuracy: 0.9145 - val_IoU_coef: 0.4717\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5752 - accuracy: 0.9262 - IoU_coef: 0.5752 - val_loss: -0.4709 - val_accuracy: 0.9147 - val_IoU_coef: 0.4709\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5751 - accuracy: 0.9261 - IoU_coef: 0.5751 - val_loss: -0.4714 - val_accuracy: 0.9150 - val_IoU_coef: 0.4714\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5756 - accuracy: 0.9262 - IoU_coef: 0.5756 - val_loss: -0.4719 - val_accuracy: 0.9150 - val_IoU_coef: 0.4719\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5755 - accuracy: 0.9262 - IoU_coef: 0.5755 - val_loss: -0.4724 - val_accuracy: 0.9149 - val_IoU_coef: 0.4724\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5759 - accuracy: 0.9262 - IoU_coef: 0.5759 - val_loss: -0.4728 - val_accuracy: 0.9148 - val_IoU_coef: 0.4728\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5761 - accuracy: 0.9262 - IoU_coef: 0.5761 - val_loss: -0.4738 - val_accuracy: 0.9147 - val_IoU_coef: 0.4738\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5765 - accuracy: 0.9262 - IoU_coef: 0.5765 - val_loss: -0.4744 - val_accuracy: 0.9147 - val_IoU_coef: 0.4744\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5762 - accuracy: 0.9262 - IoU_coef: 0.5762 - val_loss: -0.4747 - val_accuracy: 0.9147 - val_IoU_coef: 0.4747\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5766 - accuracy: 0.9261 - IoU_coef: 0.5766 - val_loss: -0.4751 - val_accuracy: 0.9143 - val_IoU_coef: 0.4751\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5767 - accuracy: 0.9261 - IoU_coef: 0.5767 - val_loss: -0.4755 - val_accuracy: 0.9142 - val_IoU_coef: 0.4755\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5767 - accuracy: 0.9262 - IoU_coef: 0.5767 - val_loss: -0.4760 - val_accuracy: 0.9142 - val_IoU_coef: 0.4760\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5772 - accuracy: 0.9263 - IoU_coef: 0.5772 - val_loss: -0.4760 - val_accuracy: 0.9144 - val_IoU_coef: 0.4760\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5773 - accuracy: 0.9261 - IoU_coef: 0.5773 - val_loss: -0.4760 - val_accuracy: 0.9146 - val_IoU_coef: 0.4760\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5776 - accuracy: 0.9262 - IoU_coef: 0.5776 - val_loss: -0.4768 - val_accuracy: 0.9148 - val_IoU_coef: 0.4768\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5776 - accuracy: 0.9262 - IoU_coef: 0.5776 - val_loss: -0.4773 - val_accuracy: 0.9146 - val_IoU_coef: 0.4773\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5781 - accuracy: 0.9262 - IoU_coef: 0.5781 - val_loss: -0.4768 - val_accuracy: 0.9143 - val_IoU_coef: 0.4768\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5780 - accuracy: 0.9261 - IoU_coef: 0.5780 - val_loss: -0.4769 - val_accuracy: 0.9144 - val_IoU_coef: 0.4769\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5783 - accuracy: 0.9263 - IoU_coef: 0.5783 - val_loss: -0.4780 - val_accuracy: 0.9144 - val_IoU_coef: 0.4780\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5784 - accuracy: 0.9263 - IoU_coef: 0.5784 - val_loss: -0.4787 - val_accuracy: 0.9144 - val_IoU_coef: 0.4787\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5787 - accuracy: 0.9261 - IoU_coef: 0.5787 - val_loss: -0.4779 - val_accuracy: 0.9145 - val_IoU_coef: 0.4779\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5790 - accuracy: 0.9262 - IoU_coef: 0.5790 - val_loss: -0.4785 - val_accuracy: 0.9143 - val_IoU_coef: 0.4785\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5791 - accuracy: 0.9262 - IoU_coef: 0.5791 - val_loss: -0.4789 - val_accuracy: 0.9138 - val_IoU_coef: 0.4789\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5794 - accuracy: 0.9262 - IoU_coef: 0.5794 - val_loss: -0.4789 - val_accuracy: 0.9135 - val_IoU_coef: 0.4789\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5795 - accuracy: 0.9262 - IoU_coef: 0.5795 - val_loss: -0.4795 - val_accuracy: 0.9137 - val_IoU_coef: 0.4795\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5798 - accuracy: 0.9263 - IoU_coef: 0.5798 - val_loss: -0.4804 - val_accuracy: 0.9141 - val_IoU_coef: 0.4804\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5799 - accuracy: 0.9262 - IoU_coef: 0.5799 - val_loss: -0.4814 - val_accuracy: 0.9144 - val_IoU_coef: 0.4814\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5802 - accuracy: 0.9262 - IoU_coef: 0.5802 - val_loss: -0.4814 - val_accuracy: 0.9145 - val_IoU_coef: 0.4814\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5801 - accuracy: 0.9262 - IoU_coef: 0.5801 - val_loss: -0.4815 - val_accuracy: 0.9144 - val_IoU_coef: 0.4815\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5806 - accuracy: 0.9262 - IoU_coef: 0.5806 - val_loss: -0.4819 - val_accuracy: 0.9144 - val_IoU_coef: 0.4819\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5808 - accuracy: 0.9263 - IoU_coef: 0.5808 - val_loss: -0.4822 - val_accuracy: 0.9142 - val_IoU_coef: 0.4822\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5809 - accuracy: 0.9262 - IoU_coef: 0.5809 - val_loss: -0.4826 - val_accuracy: 0.9139 - val_IoU_coef: 0.4826\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5811 - accuracy: 0.9262 - IoU_coef: 0.5811 - val_loss: -0.4831 - val_accuracy: 0.9138 - val_IoU_coef: 0.4831\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5812 - accuracy: 0.9262 - IoU_coef: 0.5812 - val_loss: -0.4833 - val_accuracy: 0.9137 - val_IoU_coef: 0.4833\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5815 - accuracy: 0.9262 - IoU_coef: 0.5815 - val_loss: -0.4831 - val_accuracy: 0.9135 - val_IoU_coef: 0.4831\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5815 - accuracy: 0.9262 - IoU_coef: 0.5815 - val_loss: -0.4831 - val_accuracy: 0.9135 - val_IoU_coef: 0.4831\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5816 - accuracy: 0.9262 - IoU_coef: 0.5816 - val_loss: -0.4836 - val_accuracy: 0.9138 - val_IoU_coef: 0.4836\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5820 - accuracy: 0.9262 - IoU_coef: 0.5820 - val_loss: -0.4838 - val_accuracy: 0.9140 - val_IoU_coef: 0.4838\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5822 - accuracy: 0.9263 - IoU_coef: 0.5822 - val_loss: -0.4834 - val_accuracy: 0.9139 - val_IoU_coef: 0.4834\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5820 - accuracy: 0.9263 - IoU_coef: 0.5820 - val_loss: -0.4834 - val_accuracy: 0.9136 - val_IoU_coef: 0.4834\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5826 - accuracy: 0.9262 - IoU_coef: 0.5826 - val_loss: -0.4838 - val_accuracy: 0.9135 - val_IoU_coef: 0.4838\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5826 - accuracy: 0.9263 - IoU_coef: 0.5826 - val_loss: -0.4838 - val_accuracy: 0.9128 - val_IoU_coef: 0.4838\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5829 - accuracy: 0.9262 - IoU_coef: 0.5829 - val_loss: -0.4836 - val_accuracy: 0.9127 - val_IoU_coef: 0.4836\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5830 - accuracy: 0.9262 - IoU_coef: 0.5830 - val_loss: -0.4844 - val_accuracy: 0.9134 - val_IoU_coef: 0.4844\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5831 - accuracy: 0.9262 - IoU_coef: 0.5831 - val_loss: -0.4847 - val_accuracy: 0.9133 - val_IoU_coef: 0.4847\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5834 - accuracy: 0.9262 - IoU_coef: 0.5834 - val_loss: -0.4849 - val_accuracy: 0.9132 - val_IoU_coef: 0.4849\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5835 - accuracy: 0.9262 - IoU_coef: 0.5835 - val_loss: -0.4846 - val_accuracy: 0.9134 - val_IoU_coef: 0.4846\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5835 - accuracy: 0.9263 - IoU_coef: 0.5835 - val_loss: -0.4841 - val_accuracy: 0.9132 - val_IoU_coef: 0.4841\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5838 - accuracy: 0.9262 - IoU_coef: 0.5838 - val_loss: -0.4847 - val_accuracy: 0.9134 - val_IoU_coef: 0.4847\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5840 - accuracy: 0.9262 - IoU_coef: 0.5840 - val_loss: -0.4850 - val_accuracy: 0.9138 - val_IoU_coef: 0.4850\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5842 - accuracy: 0.9262 - IoU_coef: 0.5842 - val_loss: -0.4856 - val_accuracy: 0.9137 - val_IoU_coef: 0.4856\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5844 - accuracy: 0.9262 - IoU_coef: 0.5844 - val_loss: -0.4870 - val_accuracy: 0.9137 - val_IoU_coef: 0.4870\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5844 - accuracy: 0.9262 - IoU_coef: 0.5844 - val_loss: -0.4874 - val_accuracy: 0.9139 - val_IoU_coef: 0.4874\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5846 - accuracy: 0.9263 - IoU_coef: 0.5846 - val_loss: -0.4863 - val_accuracy: 0.9136 - val_IoU_coef: 0.4863\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5849 - accuracy: 0.9262 - IoU_coef: 0.5849 - val_loss: -0.4862 - val_accuracy: 0.9140 - val_IoU_coef: 0.4862\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5851 - accuracy: 0.9261 - IoU_coef: 0.5851 - val_loss: -0.4863 - val_accuracy: 0.9146 - val_IoU_coef: 0.4863\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.5853 - accuracy: 0.9264 - IoU_coef: 0.5853 - val_loss: -0.4866 - val_accuracy: 0.9146 - val_IoU_coef: 0.4866\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5857 - accuracy: 0.9263 - IoU_coef: 0.5857 - val_loss: -0.4870 - val_accuracy: 0.9148 - val_IoU_coef: 0.4870\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5856 - accuracy: 0.9261 - IoU_coef: 0.5856 - val_loss: -0.4863 - val_accuracy: 0.9154 - val_IoU_coef: 0.4863\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5859 - accuracy: 0.9263 - IoU_coef: 0.5859 - val_loss: -0.4864 - val_accuracy: 0.9152 - val_IoU_coef: 0.4864\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5860 - accuracy: 0.9263 - IoU_coef: 0.5860 - val_loss: -0.4872 - val_accuracy: 0.9147 - val_IoU_coef: 0.4872\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5862 - accuracy: 0.9261 - IoU_coef: 0.5862 - val_loss: -0.4870 - val_accuracy: 0.9144 - val_IoU_coef: 0.4870\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5865 - accuracy: 0.9262 - IoU_coef: 0.5865 - val_loss: -0.4871 - val_accuracy: 0.9141 - val_IoU_coef: 0.4871\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5866 - accuracy: 0.9264 - IoU_coef: 0.5866 - val_loss: -0.4876 - val_accuracy: 0.9138 - val_IoU_coef: 0.4876\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5868 - accuracy: 0.9262 - IoU_coef: 0.5868 - val_loss: -0.4875 - val_accuracy: 0.9147 - val_IoU_coef: 0.4875\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5872 - accuracy: 0.9262 - IoU_coef: 0.5872 - val_loss: -0.4860 - val_accuracy: 0.9154 - val_IoU_coef: 0.4860\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5869 - accuracy: 0.9263 - IoU_coef: 0.5869 - val_loss: -0.4873 - val_accuracy: 0.9151 - val_IoU_coef: 0.4873\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5872 - accuracy: 0.9261 - IoU_coef: 0.5872 - val_loss: -0.4891 - val_accuracy: 0.9147 - val_IoU_coef: 0.4891\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5877 - accuracy: 0.9262 - IoU_coef: 0.5877 - val_loss: -0.4892 - val_accuracy: 0.9147 - val_IoU_coef: 0.4892\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5877 - accuracy: 0.9264 - IoU_coef: 0.5877 - val_loss: -0.4885 - val_accuracy: 0.9141 - val_IoU_coef: 0.4885\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5878 - accuracy: 0.9262 - IoU_coef: 0.5878 - val_loss: -0.4888 - val_accuracy: 0.9141 - val_IoU_coef: 0.4888\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5881 - accuracy: 0.9261 - IoU_coef: 0.5881 - val_loss: -0.4892 - val_accuracy: 0.9148 - val_IoU_coef: 0.4892\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5881 - accuracy: 0.9263 - IoU_coef: 0.5881 - val_loss: -0.4892 - val_accuracy: 0.9146 - val_IoU_coef: 0.4892\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5884 - accuracy: 0.9263 - IoU_coef: 0.5884 - val_loss: -0.4898 - val_accuracy: 0.9142 - val_IoU_coef: 0.4898\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5887 - accuracy: 0.9261 - IoU_coef: 0.5887 - val_loss: -0.4901 - val_accuracy: 0.9142 - val_IoU_coef: 0.4901\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5889 - accuracy: 0.9264 - IoU_coef: 0.5889 - val_loss: -0.4888 - val_accuracy: 0.9140 - val_IoU_coef: 0.4888\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5889 - accuracy: 0.9264 - IoU_coef: 0.5889 - val_loss: -0.4887 - val_accuracy: 0.9139 - val_IoU_coef: 0.4887\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5892 - accuracy: 0.9262 - IoU_coef: 0.5892 - val_loss: -0.4903 - val_accuracy: 0.9142 - val_IoU_coef: 0.4903\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5894 - accuracy: 0.9262 - IoU_coef: 0.5894 - val_loss: -0.4908 - val_accuracy: 0.9143 - val_IoU_coef: 0.4908\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5893 - accuracy: 0.9264 - IoU_coef: 0.5893 - val_loss: -0.4901 - val_accuracy: 0.9139 - val_IoU_coef: 0.4901\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5895 - accuracy: 0.9263 - IoU_coef: 0.5895 - val_loss: -0.4897 - val_accuracy: 0.9140 - val_IoU_coef: 0.4897\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5900 - accuracy: 0.9262 - IoU_coef: 0.5900 - val_loss: -0.4892 - val_accuracy: 0.9142 - val_IoU_coef: 0.4892\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5902 - accuracy: 0.9263 - IoU_coef: 0.5902 - val_loss: -0.4900 - val_accuracy: 0.9141 - val_IoU_coef: 0.4900\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5903 - accuracy: 0.9263 - IoU_coef: 0.5903 - val_loss: -0.4906 - val_accuracy: 0.9140 - val_IoU_coef: 0.4906\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5908 - accuracy: 0.9263 - IoU_coef: 0.5908 - val_loss: -0.4903 - val_accuracy: 0.9141 - val_IoU_coef: 0.4903\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5908 - accuracy: 0.9263 - IoU_coef: 0.5908 - val_loss: -0.4900 - val_accuracy: 0.9141 - val_IoU_coef: 0.4900\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5910 - accuracy: 0.9263 - IoU_coef: 0.5910 - val_loss: -0.4897 - val_accuracy: 0.9141 - val_IoU_coef: 0.4897\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5912 - accuracy: 0.9263 - IoU_coef: 0.5912 - val_loss: -0.4892 - val_accuracy: 0.9143 - val_IoU_coef: 0.4892\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5913 - accuracy: 0.9263 - IoU_coef: 0.5913 - val_loss: -0.4886 - val_accuracy: 0.9142 - val_IoU_coef: 0.4886\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5914 - accuracy: 0.9263 - IoU_coef: 0.5914 - val_loss: -0.4893 - val_accuracy: 0.9146 - val_IoU_coef: 0.4893\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5917 - accuracy: 0.9264 - IoU_coef: 0.5917 - val_loss: -0.4905 - val_accuracy: 0.9147 - val_IoU_coef: 0.4905\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5918 - accuracy: 0.9262 - IoU_coef: 0.5918 - val_loss: -0.4903 - val_accuracy: 0.9146 - val_IoU_coef: 0.4903\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5922 - accuracy: 0.9263 - IoU_coef: 0.5922 - val_loss: -0.4899 - val_accuracy: 0.9141 - val_IoU_coef: 0.4899\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5925 - accuracy: 0.9263 - IoU_coef: 0.5925 - val_loss: -0.4895 - val_accuracy: 0.9136 - val_IoU_coef: 0.4895\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5924 - accuracy: 0.9263 - IoU_coef: 0.5924 - val_loss: -0.4887 - val_accuracy: 0.9131 - val_IoU_coef: 0.4887\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5927 - accuracy: 0.9263 - IoU_coef: 0.5927 - val_loss: -0.4891 - val_accuracy: 0.9136 - val_IoU_coef: 0.4891\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5927 - accuracy: 0.9264 - IoU_coef: 0.5927 - val_loss: -0.4901 - val_accuracy: 0.9139 - val_IoU_coef: 0.4901\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5928 - accuracy: 0.9262 - IoU_coef: 0.5928 - val_loss: -0.4898 - val_accuracy: 0.9141 - val_IoU_coef: 0.4898\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5931 - accuracy: 0.9263 - IoU_coef: 0.5931 - val_loss: -0.4886 - val_accuracy: 0.9139 - val_IoU_coef: 0.4886\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5931 - accuracy: 0.9264 - IoU_coef: 0.5931 - val_loss: -0.4891 - val_accuracy: 0.9136 - val_IoU_coef: 0.4891\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5935 - accuracy: 0.9263 - IoU_coef: 0.5935 - val_loss: -0.4891 - val_accuracy: 0.9133 - val_IoU_coef: 0.4891\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5934 - accuracy: 0.9262 - IoU_coef: 0.5934 - val_loss: -0.4892 - val_accuracy: 0.9133 - val_IoU_coef: 0.4892\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.5935 - accuracy: 0.9264 - IoU_coef: 0.5935 - val_loss: -0.4895 - val_accuracy: 0.9135 - val_IoU_coef: 0.4895\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5940 - accuracy: 0.9263 - IoU_coef: 0.5940 - val_loss: -0.4900 - val_accuracy: 0.9137 - val_IoU_coef: 0.4900\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.5942 - accuracy: 0.9263 - IoU_coef: 0.5942 - val_loss: -0.4898 - val_accuracy: 0.9138 - val_IoU_coef: 0.4898\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5944 - accuracy: 0.9263 - IoU_coef: 0.5944 - val_loss: -0.4896 - val_accuracy: 0.9140 - val_IoU_coef: 0.4896\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5946 - accuracy: 0.9264 - IoU_coef: 0.5946 - val_loss: -0.4893 - val_accuracy: 0.9139 - val_IoU_coef: 0.4893\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5947 - accuracy: 0.9262 - IoU_coef: 0.5947 - val_loss: -0.4891 - val_accuracy: 0.9141 - val_IoU_coef: 0.4891\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5951 - accuracy: 0.9264 - IoU_coef: 0.5951 - val_loss: -0.4883 - val_accuracy: 0.9137 - val_IoU_coef: 0.4883\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5951 - accuracy: 0.9264 - IoU_coef: 0.5951 - val_loss: -0.4885 - val_accuracy: 0.9133 - val_IoU_coef: 0.4885\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5955 - accuracy: 0.9263 - IoU_coef: 0.5955 - val_loss: -0.4889 - val_accuracy: 0.9133 - val_IoU_coef: 0.4889\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5956 - accuracy: 0.9263 - IoU_coef: 0.5956 - val_loss: -0.4898 - val_accuracy: 0.9135 - val_IoU_coef: 0.4898\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5955 - accuracy: 0.9264 - IoU_coef: 0.5955 - val_loss: -0.4908 - val_accuracy: 0.9135 - val_IoU_coef: 0.4908\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5958 - accuracy: 0.9262 - IoU_coef: 0.5958 - val_loss: -0.4916 - val_accuracy: 0.9141 - val_IoU_coef: 0.4916\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.5957 - accuracy: 0.9263 - IoU_coef: 0.5957 - val_loss: -0.4918 - val_accuracy: 0.9141 - val_IoU_coef: 0.4918\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5963 - accuracy: 0.9264 - IoU_coef: 0.5963 - val_loss: -0.4917 - val_accuracy: 0.9138 - val_IoU_coef: 0.4917\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.5962 - accuracy: 0.9263 - IoU_coef: 0.5962 - val_loss: -0.4919 - val_accuracy: 0.9137 - val_IoU_coef: 0.4919\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.5966 - accuracy: 0.9264 - IoU_coef: 0.5966 - val_loss: -0.4914 - val_accuracy: 0.9138 - val_IoU_coef: 0.4914\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5967 - accuracy: 0.9263 - IoU_coef: 0.5967 - val_loss: -0.4915 - val_accuracy: 0.9140 - val_IoU_coef: 0.4915\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5969 - accuracy: 0.9263 - IoU_coef: 0.5969 - val_loss: -0.4930 - val_accuracy: 0.9142 - val_IoU_coef: 0.4930\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: -0.5970 - accuracy: 0.9264 - IoU_coef: 0.5970 - val_loss: -0.4940 - val_accuracy: 0.9141 - val_IoU_coef: 0.4940\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5971 - accuracy: 0.9262 - IoU_coef: 0.5971 - val_loss: -0.4942 - val_accuracy: 0.9139 - val_IoU_coef: 0.4942\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.5975 - accuracy: 0.9264 - IoU_coef: 0.5975 - val_loss: -0.4937 - val_accuracy: 0.9140 - val_IoU_coef: 0.4937\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: -0.5975 - accuracy: 0.9264 - IoU_coef: 0.5975 - val_loss: -0.4933 - val_accuracy: 0.9134 - val_IoU_coef: 0.4933\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.5977 - accuracy: 0.9263 - IoU_coef: 0.5977 - val_loss: -0.4927 - val_accuracy: 0.9132 - val_IoU_coef: 0.4927\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: -0.5980 - accuracy: 0.9263 - IoU_coef: 0.5980 - val_loss: -0.4931 - val_accuracy: 0.9136 - val_IoU_coef: 0.4931\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.5980 - accuracy: 0.9264 - IoU_coef: 0.5980 - val_loss: -0.4938 - val_accuracy: 0.9138 - val_IoU_coef: 0.4938\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5983 - accuracy: 0.9264 - IoU_coef: 0.5983 - val_loss: -0.4941 - val_accuracy: 0.9139 - val_IoU_coef: 0.4941\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5985 - accuracy: 0.9262 - IoU_coef: 0.5985 - val_loss: -0.4944 - val_accuracy: 0.9145 - val_IoU_coef: 0.4944\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5989 - accuracy: 0.9265 - IoU_coef: 0.5989 - val_loss: -0.4946 - val_accuracy: 0.9145 - val_IoU_coef: 0.4946\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.5991 - accuracy: 0.9264 - IoU_coef: 0.5991 - val_loss: -0.4945 - val_accuracy: 0.9138 - val_IoU_coef: 0.4945\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.5991 - accuracy: 0.9262 - IoU_coef: 0.5991 - val_loss: -0.4941 - val_accuracy: 0.9137 - val_IoU_coef: 0.4941\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.5994 - accuracy: 0.9264 - IoU_coef: 0.5994 - val_loss: -0.4939 - val_accuracy: 0.9140 - val_IoU_coef: 0.4939\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.5992 - accuracy: 0.9265 - IoU_coef: 0.5992 - val_loss: -0.4948 - val_accuracy: 0.9139 - val_IoU_coef: 0.4948\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.5996 - accuracy: 0.9263 - IoU_coef: 0.5996 - val_loss: -0.4955 - val_accuracy: 0.9141 - val_IoU_coef: 0.4955\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.5998 - accuracy: 0.9263 - IoU_coef: 0.5998 - val_loss: -0.4954 - val_accuracy: 0.9144 - val_IoU_coef: 0.4954\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6000 - accuracy: 0.9265 - IoU_coef: 0.6000 - val_loss: -0.4950 - val_accuracy: 0.9139 - val_IoU_coef: 0.4950\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6002 - accuracy: 0.9264 - IoU_coef: 0.6002 - val_loss: -0.4949 - val_accuracy: 0.9137 - val_IoU_coef: 0.4949\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6003 - accuracy: 0.9263 - IoU_coef: 0.6003 - val_loss: -0.4952 - val_accuracy: 0.9136 - val_IoU_coef: 0.4952\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6006 - accuracy: 0.9264 - IoU_coef: 0.6006 - val_loss: -0.4946 - val_accuracy: 0.9137 - val_IoU_coef: 0.4946\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6008 - accuracy: 0.9265 - IoU_coef: 0.6008 - val_loss: -0.4946 - val_accuracy: 0.9136 - val_IoU_coef: 0.4946\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6010 - accuracy: 0.9264 - IoU_coef: 0.6010 - val_loss: -0.4953 - val_accuracy: 0.9137 - val_IoU_coef: 0.4953\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6011 - accuracy: 0.9263 - IoU_coef: 0.6011 - val_loss: -0.4958 - val_accuracy: 0.9139 - val_IoU_coef: 0.4958\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6013 - accuracy: 0.9264 - IoU_coef: 0.6013 - val_loss: -0.4957 - val_accuracy: 0.9139 - val_IoU_coef: 0.4957\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6013 - accuracy: 0.9264 - IoU_coef: 0.6013 - val_loss: -0.4966 - val_accuracy: 0.9138 - val_IoU_coef: 0.4966\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6015 - accuracy: 0.9264 - IoU_coef: 0.6015 - val_loss: -0.4970 - val_accuracy: 0.9140 - val_IoU_coef: 0.4970\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6018 - accuracy: 0.9264 - IoU_coef: 0.6018 - val_loss: -0.4970 - val_accuracy: 0.9142 - val_IoU_coef: 0.4970\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6019 - accuracy: 0.9264 - IoU_coef: 0.6019 - val_loss: -0.4972 - val_accuracy: 0.9142 - val_IoU_coef: 0.4972\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6021 - accuracy: 0.9264 - IoU_coef: 0.6021 - val_loss: -0.4973 - val_accuracy: 0.9144 - val_IoU_coef: 0.4973\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.6021 - accuracy: 0.9264 - IoU_coef: 0.6021 - val_loss: -0.4971 - val_accuracy: 0.9144 - val_IoU_coef: 0.4971\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6022 - accuracy: 0.9264 - IoU_coef: 0.6022 - val_loss: -0.4971 - val_accuracy: 0.9141 - val_IoU_coef: 0.4971\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6026 - accuracy: 0.9263 - IoU_coef: 0.6026 - val_loss: -0.4969 - val_accuracy: 0.9141 - val_IoU_coef: 0.4969\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6026 - accuracy: 0.9264 - IoU_coef: 0.6026 - val_loss: -0.4967 - val_accuracy: 0.9142 - val_IoU_coef: 0.4967\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6029 - accuracy: 0.9265 - IoU_coef: 0.6029 - val_loss: -0.4969 - val_accuracy: 0.9141 - val_IoU_coef: 0.4969\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6031 - accuracy: 0.9264 - IoU_coef: 0.6031 - val_loss: -0.4973 - val_accuracy: 0.9141 - val_IoU_coef: 0.4973\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6033 - accuracy: 0.9263 - IoU_coef: 0.6033 - val_loss: -0.4976 - val_accuracy: 0.9143 - val_IoU_coef: 0.4976\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6035 - accuracy: 0.9265 - IoU_coef: 0.6035 - val_loss: -0.4978 - val_accuracy: 0.9141 - val_IoU_coef: 0.4978\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6037 - accuracy: 0.9264 - IoU_coef: 0.6037 - val_loss: -0.4971 - val_accuracy: 0.9137 - val_IoU_coef: 0.4971\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6036 - accuracy: 0.9264 - IoU_coef: 0.6036 - val_loss: -0.4962 - val_accuracy: 0.9138 - val_IoU_coef: 0.4962\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6040 - accuracy: 0.9264 - IoU_coef: 0.6040 - val_loss: -0.4955 - val_accuracy: 0.9140 - val_IoU_coef: 0.4955\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.6041 - accuracy: 0.9264 - IoU_coef: 0.6041 - val_loss: -0.4966 - val_accuracy: 0.9140 - val_IoU_coef: 0.4966\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6043 - accuracy: 0.9264 - IoU_coef: 0.6043 - val_loss: -0.4971 - val_accuracy: 0.9141 - val_IoU_coef: 0.4971\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6047 - accuracy: 0.9264 - IoU_coef: 0.6047 - val_loss: -0.4971 - val_accuracy: 0.9141 - val_IoU_coef: 0.4971\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6049 - accuracy: 0.9264 - IoU_coef: 0.6049 - val_loss: -0.4969 - val_accuracy: 0.9138 - val_IoU_coef: 0.4969\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6050 - accuracy: 0.9265 - IoU_coef: 0.6050 - val_loss: -0.4961 - val_accuracy: 0.9135 - val_IoU_coef: 0.4961\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6051 - accuracy: 0.9264 - IoU_coef: 0.6051 - val_loss: -0.4963 - val_accuracy: 0.9138 - val_IoU_coef: 0.4963\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6053 - accuracy: 0.9264 - IoU_coef: 0.6053 - val_loss: -0.4969 - val_accuracy: 0.9143 - val_IoU_coef: 0.4969\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6053 - accuracy: 0.9265 - IoU_coef: 0.6053 - val_loss: -0.4973 - val_accuracy: 0.9145 - val_IoU_coef: 0.4973\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6056 - accuracy: 0.9264 - IoU_coef: 0.6056 - val_loss: -0.4975 - val_accuracy: 0.9146 - val_IoU_coef: 0.4975\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6057 - accuracy: 0.9264 - IoU_coef: 0.6057 - val_loss: -0.4978 - val_accuracy: 0.9144 - val_IoU_coef: 0.4978\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6058 - accuracy: 0.9264 - IoU_coef: 0.6058 - val_loss: -0.4982 - val_accuracy: 0.9139 - val_IoU_coef: 0.4982\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6060 - accuracy: 0.9265 - IoU_coef: 0.6060 - val_loss: -0.4986 - val_accuracy: 0.9136 - val_IoU_coef: 0.4986\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6060 - accuracy: 0.9264 - IoU_coef: 0.6060 - val_loss: -0.4996 - val_accuracy: 0.9144 - val_IoU_coef: 0.4996\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6063 - accuracy: 0.9265 - IoU_coef: 0.6063 - val_loss: -0.4997 - val_accuracy: 0.9147 - val_IoU_coef: 0.4997\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6067 - accuracy: 0.9264 - IoU_coef: 0.6067 - val_loss: -0.4996 - val_accuracy: 0.9148 - val_IoU_coef: 0.4996\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6066 - accuracy: 0.9264 - IoU_coef: 0.6066 - val_loss: -0.4993 - val_accuracy: 0.9148 - val_IoU_coef: 0.4993\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6067 - accuracy: 0.9265 - IoU_coef: 0.6067 - val_loss: -0.4995 - val_accuracy: 0.9143 - val_IoU_coef: 0.4995\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6069 - accuracy: 0.9264 - IoU_coef: 0.6069 - val_loss: -0.5004 - val_accuracy: 0.9142 - val_IoU_coef: 0.5004\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6072 - accuracy: 0.9264 - IoU_coef: 0.6072 - val_loss: -0.5010 - val_accuracy: 0.9146 - val_IoU_coef: 0.5010\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6072 - accuracy: 0.9266 - IoU_coef: 0.6072 - val_loss: -0.5011 - val_accuracy: 0.9143 - val_IoU_coef: 0.5011\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6074 - accuracy: 0.9264 - IoU_coef: 0.6074 - val_loss: -0.5005 - val_accuracy: 0.9143 - val_IoU_coef: 0.5005\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6075 - accuracy: 0.9263 - IoU_coef: 0.6075 - val_loss: -0.4997 - val_accuracy: 0.9145 - val_IoU_coef: 0.4997\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6078 - accuracy: 0.9265 - IoU_coef: 0.6078 - val_loss: -0.5000 - val_accuracy: 0.9141 - val_IoU_coef: 0.5000\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6079 - accuracy: 0.9264 - IoU_coef: 0.6079 - val_loss: -0.4999 - val_accuracy: 0.9140 - val_IoU_coef: 0.4999\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6079 - accuracy: 0.9263 - IoU_coef: 0.6079 - val_loss: -0.4996 - val_accuracy: 0.9145 - val_IoU_coef: 0.4996\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6080 - accuracy: 0.9265 - IoU_coef: 0.6080 - val_loss: -0.4998 - val_accuracy: 0.9147 - val_IoU_coef: 0.4998\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6085 - accuracy: 0.9265 - IoU_coef: 0.6085 - val_loss: -0.4991 - val_accuracy: 0.9149 - val_IoU_coef: 0.4991\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6087 - accuracy: 0.9264 - IoU_coef: 0.6087 - val_loss: -0.4989 - val_accuracy: 0.9152 - val_IoU_coef: 0.4989\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6086 - accuracy: 0.9265 - IoU_coef: 0.6086 - val_loss: -0.4992 - val_accuracy: 0.9150 - val_IoU_coef: 0.4992\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6088 - accuracy: 0.9265 - IoU_coef: 0.6088 - val_loss: -0.4996 - val_accuracy: 0.9148 - val_IoU_coef: 0.4996\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6088 - accuracy: 0.9264 - IoU_coef: 0.6088 - val_loss: -0.4999 - val_accuracy: 0.9148 - val_IoU_coef: 0.4999\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6094 - accuracy: 0.9265 - IoU_coef: 0.6094 - val_loss: -0.4993 - val_accuracy: 0.9144 - val_IoU_coef: 0.4993\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6097 - accuracy: 0.9265 - IoU_coef: 0.6097 - val_loss: -0.5002 - val_accuracy: 0.9143 - val_IoU_coef: 0.5002\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6099 - accuracy: 0.9264 - IoU_coef: 0.6099 - val_loss: -0.5016 - val_accuracy: 0.9144 - val_IoU_coef: 0.5016\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6097 - accuracy: 0.9264 - IoU_coef: 0.6097 - val_loss: -0.5020 - val_accuracy: 0.9143 - val_IoU_coef: 0.5020\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6099 - accuracy: 0.9264 - IoU_coef: 0.6099 - val_loss: -0.5016 - val_accuracy: 0.9143 - val_IoU_coef: 0.5016\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6098 - accuracy: 0.9264 - IoU_coef: 0.6098 - val_loss: -0.5020 - val_accuracy: 0.9144 - val_IoU_coef: 0.5020\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6102 - accuracy: 0.9264 - IoU_coef: 0.6102 - val_loss: -0.5019 - val_accuracy: 0.9144 - val_IoU_coef: 0.5019\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: -0.6105 - accuracy: 0.9265 - IoU_coef: 0.6105 - val_loss: -0.5013 - val_accuracy: 0.9144 - val_IoU_coef: 0.5013\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -0.6106 - accuracy: 0.9264 - IoU_coef: 0.6106 - val_loss: -0.5017 - val_accuracy: 0.9146 - val_IoU_coef: 0.5017\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6110 - accuracy: 0.9265 - IoU_coef: 0.6110 - val_loss: -0.5025 - val_accuracy: 0.9148 - val_IoU_coef: 0.5025\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6112 - accuracy: 0.9265 - IoU_coef: 0.6112 - val_loss: -0.5023 - val_accuracy: 0.9146 - val_IoU_coef: 0.5023\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6109 - accuracy: 0.9265 - IoU_coef: 0.6109 - val_loss: -0.5016 - val_accuracy: 0.9146 - val_IoU_coef: 0.5016\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6112 - accuracy: 0.9264 - IoU_coef: 0.6112 - val_loss: -0.5017 - val_accuracy: 0.9142 - val_IoU_coef: 0.5017\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -0.6115 - accuracy: 0.9264 - IoU_coef: 0.6115 - val_loss: -0.5015 - val_accuracy: 0.9138 - val_IoU_coef: 0.5015\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6116 - accuracy: 0.9265 - IoU_coef: 0.6116 - val_loss: -0.5013 - val_accuracy: 0.9136 - val_IoU_coef: 0.5013\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: -0.6113 - accuracy: 0.9265 - IoU_coef: 0.6113 - val_loss: -0.5020 - val_accuracy: 0.9140 - val_IoU_coef: 0.5020\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -0.6120 - accuracy: 0.9265 - IoU_coef: 0.6120 - val_loss: -0.5018 - val_accuracy: 0.9141 - val_IoU_coef: 0.5018\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.6122 - accuracy: 0.9265 - IoU_coef: 0.6122 - val_loss: -0.5012 - val_accuracy: 0.9143 - val_IoU_coef: 0.5012\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6124 - accuracy: 0.9265 - IoU_coef: 0.6124 - val_loss: -0.5006 - val_accuracy: 0.9143 - val_IoU_coef: 0.5006\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -0.6125 - accuracy: 0.9265 - IoU_coef: 0.6125 - val_loss: -0.5010 - val_accuracy: 0.9144 - val_IoU_coef: 0.5010\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6125 - accuracy: 0.9264 - IoU_coef: 0.6125 - val_loss: -0.5018 - val_accuracy: 0.9146 - val_IoU_coef: 0.5018\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6128 - accuracy: 0.9265 - IoU_coef: 0.6128 - val_loss: -0.5017 - val_accuracy: 0.9148 - val_IoU_coef: 0.5017\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: -0.6131 - accuracy: 0.9264 - IoU_coef: 0.6131 - val_loss: -0.5021 - val_accuracy: 0.9149 - val_IoU_coef: 0.5021\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6133 - accuracy: 0.9265 - IoU_coef: 0.6133 - val_loss: -0.5027 - val_accuracy: 0.9146 - val_IoU_coef: 0.5027\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6133 - accuracy: 0.9265 - IoU_coef: 0.6133 - val_loss: -0.5030 - val_accuracy: 0.9145 - val_IoU_coef: 0.5030\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.6134 - accuracy: 0.9265 - IoU_coef: 0.6134 - val_loss: -0.5025 - val_accuracy: 0.9145 - val_IoU_coef: 0.5025\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -0.6137 - accuracy: 0.9265 - IoU_coef: 0.6137 - val_loss: -0.5028 - val_accuracy: 0.9148 - val_IoU_coef: 0.5028\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6139 - accuracy: 0.9266 - IoU_coef: 0.6139 - val_loss: -0.5030 - val_accuracy: 0.9147 - val_IoU_coef: 0.5030\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6141 - accuracy: 0.9265 - IoU_coef: 0.6141 - val_loss: -0.5022 - val_accuracy: 0.9143 - val_IoU_coef: 0.5022\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6139 - accuracy: 0.9264 - IoU_coef: 0.6139 - val_loss: -0.5022 - val_accuracy: 0.9141 - val_IoU_coef: 0.5022\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6143 - accuracy: 0.9264 - IoU_coef: 0.6143 - val_loss: -0.5022 - val_accuracy: 0.9141 - val_IoU_coef: 0.5022\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6146 - accuracy: 0.9265 - IoU_coef: 0.6146 - val_loss: -0.5018 - val_accuracy: 0.9141 - val_IoU_coef: 0.5018\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6145 - accuracy: 0.9265 - IoU_coef: 0.6145 - val_loss: -0.5014 - val_accuracy: 0.9139 - val_IoU_coef: 0.5014\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: -0.6145 - accuracy: 0.9263 - IoU_coef: 0.6145 - val_loss: -0.5014 - val_accuracy: 0.9142 - val_IoU_coef: 0.5014\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -0.6149 - accuracy: 0.9265 - IoU_coef: 0.6149 - val_loss: -0.5010 - val_accuracy: 0.9143 - val_IoU_coef: 0.5010\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -0.6151 - accuracy: 0.9266 - IoU_coef: 0.6151 - val_loss: -0.5008 - val_accuracy: 0.9141 - val_IoU_coef: 0.5008\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: -0.6150 - accuracy: 0.9265 - IoU_coef: 0.6150 - val_loss: -0.5017 - val_accuracy: 0.9144 - val_IoU_coef: 0.5017\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: -0.6154 - accuracy: 0.9265 - IoU_coef: 0.6154 - val_loss: -0.5024 - val_accuracy: 0.9146 - val_IoU_coef: 0.5024\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: -0.6153 - accuracy: 0.9265 - IoU_coef: 0.6153 - val_loss: -0.5027 - val_accuracy: 0.9143 - val_IoU_coef: 0.5027\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6157 - accuracy: 0.9265 - IoU_coef: 0.6157 - val_loss: -0.5027 - val_accuracy: 0.9142 - val_IoU_coef: 0.5027\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: -0.6161 - accuracy: 0.9265 - IoU_coef: 0.6161 - val_loss: -0.5025 - val_accuracy: 0.9140 - val_IoU_coef: 0.5025\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: -0.6160 - accuracy: 0.9265 - IoU_coef: 0.6160 - val_loss: -0.5022 - val_accuracy: 0.9134 - val_IoU_coef: 0.5022\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -0.6162 - accuracy: 0.9265 - IoU_coef: 0.6162 - val_loss: -0.5011 - val_accuracy: 0.9128 - val_IoU_coef: 0.5011\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAFNCAYAAACT/m9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1zW9f7/8cfrYi8XKJq49wBBEbfS3lnWaZ7S4/dU1um0TplNbS/rV51s2K7TsNOep9JScU9Q3AsVQUOUQBkC1/v3x/uSHICowOcCXvfbjRvX9bk+1+d6guXL9/vzHmKMQSmllGqoXE4HUEoppZykhVAppVSDpoVQKaVUg6aFUCmlVIOmhVAppVSDpoVQKaVUg6aFUNVrIvKjiIyu7nOdJCJpInJGDVzXiEhnz+PXROTBqpx7Ap9zjYj8fKI5K7luooikV/d1Vf3n63QApY4kIvsOeRoMFAGlnuc3GmM+rOq1jDHn1sS59Z0xZlx1XEdE2gNbAD9jTInn2h8CVf4zVKqmaSFUXscYE3rwsYikAX83xkw/8jwR8T34l6tSSp0o7RpVdcbBri8RuUdEdgLviEhTEflORLJEZK/ncdQh75kpIn/3PB4jInNEZLLn3C0icu4JnttBRGaLSJ6ITBeRKSLynwpyVyXjoyIy13O9n0Uk4pDXrxWRrSKSLSL3V/L7GSAiO0XE55Bjl4jICs/jBBGZLyI5IpIpIi+LiH8F13pXRB475PndnvdkiMjYI849X0SWi0iuiGwXkUmHvDzb8z1HRPaJyKCDv9tD3j9YRBaLyB+e74Or+rupjIj08Lw/R0RWichFh7x2nois9lxzh4jc5Tke4fnzyRGRPSKSJCL692Q9p3/Aqq5pCTQD2gE3YP8bfsfzvC1QALxcyfsHAOuACOAZ4C0RkRM49yNgERAOTAKureQzq5LxauBvQAvAHzj4F3NP4FXP9U/xfF4U5TDGLAT2A6cdcd2PPI9LgTs8P88g4HTg5kpy48lwjifPmUAX4Mj7k/uB64AmwPnATSJysee14Z7vTYwxocaY+UdcuxnwPfCS52d7HvheRMKP+BmO+t0cI7Mf8C3ws+d9/wQ+FJFunlPewnazhwG9gV89x/8FpAPNgUjgPkDXoazntBCqusYNTDTGFBljCowx2caYz40x+caYPOBxYEQl799qjHnDGFMKvAe0wv6FV+VzRaQt0B94yBhzwBgzB/imog+sYsZ3jDHrjTEFwKdArOf4ZcB3xpjZxpgi4EHP76AiHwNXAYhIGHCe5xjGmKXGmAXGmBJjTBrwejk5ynO5J1+qMWY/tvAf+vPNNMasNMa4jTErPJ9XleuCLZwbjDEfeHJ9DKwFLjzknIp+N5UZCIQCT3n+jH4FvsPzuwGKgZ4i0sgYs9cYs+yQ462AdsaYYmNMktEFmes9LYSqrskyxhQefCIiwSLyuqfrMBfbFdfk0O7BI+w8+MAYk+95GHqc554C7DnkGMD2igJXMePOQx7nH5LplEOv7SlE2RV9Frb1N0pEAoBRwDJjzFZPjq6ebr+dnhxPYFuHx3JYBmDrET/fABH5zdP1+wcwrorXPXjtrUcc2wq0PuR5Rb+bY2Y2xhz6j4ZDr3sp9h8JW0VklogM8hx/FtgI/Cwim0VkQtV+DFWXaSFUdc2R/zr/F9ANGGCMacSfXXEVdXdWh0ygmYgEH3KsTSXnn0zGzEOv7fnM8IpONsasxv6Ffy6Hd4uC7WJdC3Tx5LjvRDJgu3cP9RG2RdzGGNMYeO2Q6x6rNZWB7TI+VFtgRxVyHeu6bY64v1d2XWPMYmPMSGy36VfYlibGmDxjzL+MMR2Bi4A7ReT0k8yivJwWQlXXhWHvueV47jdNrOkP9LSwlgCTRMTf05q4sJK3nEzGz4ALRGSoZ2DLIxz7/9uPgNuwBfe/R+TIBfaJSHfgpipm+BQYIyI9PYX4yPxh2BZyoYgkYAvwQVnYrtyOFVz7B6CriFwtIr4icgXQE9uNeTIWYluP40XET0QSsX9Gn3j+zK4RkcbGmGLs78QNICIXiEhnz73gP7D3VSvrilb1gBZCVde9AAQBu4EFwP9q6XOvwQ44yQYeA6Zh5zuW54QzGmNWAf/AFrdMYC92MEdlDt6j+9UYs/uQ43dhi1Qe8IYnc1Uy/Oj5GX7Fdhv+esQpNwOPiEge8BCe1pXnvfnYe6JzPSMxBx5x7WzgAmyrORsYD1xwRO7jZow5gC1852J/768A1xlj1npOuRZI83QRj8P+eYIdDDQd2AfMB14xxvx2MlmU9xO9D6zUyRORacBaY0yNt0iVUtVLW4RKnQAR6S8inUTE5ZleMBJ7r0kpVcfoyjJKnZiWwBfYgSvpwE3GmOXORlJKnQjtGlVKKdWgadeoUkqpBk0LoVJKqQat3t0jjIiIMO3bt3c6hlJKKS+ydOnS3caY5uW9Vu8KYfv27VmyZInTMZRSSnkRETlyKb8y2jWqlFKqQdNCqJRSqkHTQqiUUqpBq3f3CJVSqroVFxeTnp5OYWHhsU9WjgoMDCQqKgo/P78qv0cLoVJKHUN6ejphYWG0b98euzGF8kbGGLKzs0lPT6dDhw5Vfp92jSql1DEUFhYSHh6uRdDLiQjh4eHH3XLXQqiUUlWgRbBuOJE/Jy2ESinl5bKzs4mNjSU2NpaWLVvSunXrsucHDhyo9L1Llizh1ltvPeZnDB48uFqyzpw5kwsuuKBarlVb9B6hUkp5ufDwcJKTkwGYNGkSoaGh3HXXXWWvl5SU4Otb/l/n8fHxxMfHH/Mz5s2bVz1h6yBtEVZgz57pGFPqdAyllCrXmDFjGDduHAMGDGD8+PEsWrSIQYMGERcXx+DBg1m3bh1weAtt0qRJjB07lsTERDp27MhLL71Udr3Q0NCy8xMTE7nsssvo3r0711xzDQd3Kfrhhx/o3r07/fr149Zbbz1my2/Pnj1cfPHFxMTEMHDgQFasWAHArFmzylq0cXFx5OXlkZmZyfDhw4mNjaV3794kJSVV+++sItoiLEd29v9YufJcOnR4knbtJjgdRymlypWens68efPw8fEhNzeXpKQkfH19mT59Ovfddx+ff/75Ue9Zu3Ytv/32G3l5eXTr1o2bbrrpqKkGy5cvZ9WqVZxyyikMGTKEuXPnEh8fz4033sjs2bPp0KEDV1111THzTZw4kbi4OL766it+/fVXrrvuOpKTk5k8eTJTpkxhyJAh7Nu3j8DAQKZOncrZZ5/N/fffT2lpKfn5+dX2ezoWLYTlKCpKB6CgYIPDSZRSXuf228HTTVltYmPhhReO+21/+ctf8PHxAeCPP/5g9OjRbNiwARGhuLi43Pecf/75BAQEEBAQQIsWLdi1axdRUVGHnZOQkFB2LDY2lrS0NEJDQ+nYsWPZtISrrrqKqVOnVppvzpw5ZcX4tNNOIzs7m9zcXIYMGcKdd97JNddcw6hRo4iKiqJ///6MHTuW4uJiLr74YmJjY4/793GitGu0UjpKTCnlvUJCQsoeP/jgg5x66qmkpqby7bffVjiFICAgoOyxj48PJSUlJ3TOyZgwYQJvvvkmBQUFDBkyhLVr1zJ8+HBmz55N69atGTNmDO+//361fmZltEVYLuN0AKWUtzqBlltt+OOPP2jdujUA7777brVfv1u3bmzevJm0tDTat2/PtGnTjvmeYcOG8eGHH/Lggw8yc+ZMIiIiaNSoEZs2bSI6Opro6GgWL17M2rVrCQoKIioqiuuvv56ioiKWLVvGddddV+0/R3m0RVguWwh13pBSqq4YP3489957L3FxcdXeggMICgrilVde4ZxzzqFfv36EhYXRuHHjSt8zadIkli5dSkxMDBMmTOC9994D4IUXXqB3797ExMTg5+fHueeey8yZM+nTpw9xcXFMmzaN2267rdp/horIwdFA9UV8fLw52f0IMzKmsn79jbRq9Xe6dXujmpIppeqqNWvW0KNHD6djOG7fvn2EhoZijOEf//gHXbp04Y477nA61lHK+/MSkaXGmHLnkWiLUCmlVJW88cYbxMbG0qtXL/744w9uvPFGpyNVC71HWCntGlVKqYPuuOMOr2wBnixtEZarfnUXK6WUqpgWwkppi1Appeo7LYTlqG8DiJRSSlVMC2G5DhZCbREqpVR9p4WwHAcX2xbRX49SynmnnnoqP/3002HHXnjhBW666aYK35OYmMjBqWTnnXceOTk5R50zadIkJk+eXOlnf/XVV6xevbrs+UMPPcT06dOPJ365vGm7Jv2bvhzG2P29XK6Acl8vLS2gpCS3NiMppRqwq666ik8++eSwY5988kmVFr4Gu2tEkyZNTuizjyyEjzzyCGecccYJXctbaSEsh9tdBICI/2HHjXGzbdtk5s9vw7x5LcnK+sKJeEqpBuayyy7j+++/L9uENy0tjYyMDIYNG8ZNN91EfHw8vXr1YuLEieW+v3379uzevRuAxx9/nK5duzJ06NCyrZrAzhHs378/ffr04dJLLyU/P5958+bxzTffcPfddxMbG8umTZsYM2YMn332GQAzZswgLi6O6Ohoxo4dS1FRUdnnTZw4kb59+xIdHc3atWsr/fmc3q5JC2E53G67WK3I4VuTbN36OJs3301wcBeCgjqxatVlpKf/24mISqkGpFmzZiQkJPDjjz8CtjV4+eWXIyI8/vjjLFmyhBUrVjBr1qyyIlKepUuX8sknn5CcnMwPP/zA4sWLy14bNWoUixcvJiUlhR49evDWW28xePBgLrroIp599lmSk5Pp1KlT2fmFhYWMGTOGadOmsXLlSkpKSnj11VfLXo+IiGDZsmXcdNNNx+x+Pbhd04oVK3jiiSfK1hg9uF1TcnIySUlJBAUF8dFHH3H22WeTnJxMSkpKtexSoRPqy+F2Fxx8VHastHQ/27Y9RfPml9Gz56e43QWsXn01GzfeittdRNu2d5V/MaVUvbJhw+3s21e92zCFhsbSpUvli3kf7B4dOXIkn3zyCW+99RYAn376KVOnTqWkpITMzExWr15NTExMuddISkrikksuITg4GICLLrqo7LXU1FQeeOABcnJy2LdvH2effXaledatW0eHDh3o2rUrAKNHj2bKlCncfvvtgC2sAP369eOLLyrvPXN6uyZtEZajaVPb/23MnwvX5uYuxu3Op2XLsYgIPj7B9O79ORERo9iy5QEKCjY5FVcp1QCMHDmSGTNmsGzZMvLz8+nXrx9btmxh8uTJzJgxgxUrVnD++edXuP3SsYwZM4aXX36ZlStXMnHixBO+zkEHt3I6mW2camu7Jm0RlqNZs7NwuULKRo8CFBVtAyAoqHPZMREfunT5N3v3/sKGDbcSHf2d7lihVD13rJZbTQkNDeXUU09l7NixZYNkcnNzCQkJoXHjxuzatYsff/yRxMTECq8xfPhwxowZw7333ktJSQnffvtt2XqheXl5tGrViuLiYj788MOyLZ3CwsLIy8s76lrdunUjLS2NjRs30rlzZz744ANGjBhxQj+b09s1aYuwPPffj+TlH1YICwttIQwIOHwn54CAU2jf/mH27PmB7OxvajWmUqphueqqq0hJSSkrhAe3LerevTtXX301Q4YMqfT9ffv25YorrqBPnz6ce+659O/fv+y1Rx99lAEDBjBkyBC6d+9edvzKK6/k2WefJS4ujk2b/uz5CgwM5J133uEvf/kL0dHRuFwuxo0bd0I/l9PbNek2TOW57z7mDHySFt3/QdeuLwOwbt0N7N79NUOG7DrqdLe7mKVL+1JQsIWEhLUEBkYddY5Squ7SbZjqFt2GqToEBSElgLu47FBh4TYCAtqUe7rL5Uf37h/gdu9n5853ayejUkqpaqGFsDxBQSCQsXMqeXl2dFhh4WaCgjpW+JawsFgaNx5GZubrFBRsrq2kSimlTpIjhVBEmonILyKywfO9aQXn/U9EckTku1oNGBREsSfR0qX9KCraQWHhlsMGypQnMvJaiorSWbiwE/n56yo9VymllHdwqkU4AZhhjOkCzPA8L8+zwLW1luqgoKBDnrjJyHgdY0oIDKy4RQjQqtX/0ajRIABSUs6gsHD7Uee43UWsWHE+ubkLqzOxUqqG1bfxFPXVifw5OVUIRwLveR6/B1xc3knGmBnA0eN2a9ohhdDHJ4zsbNsgPXLE6JFEXPTtO4/mza+gqCidBQvakpu7iB07pmCMITd3EWlpj7Bnzw+sWHFOjf4ISqnqExgYSHZ2thZDL2eMITs7m8DAwON6n1PzCCONMZmexzuBSIdylO+QQhgSEk1u7jzATpWoiq5dp5CVNQ2AZcsGALBhwy2HnVNSkkNpaSE+Psf3B6aUqn1RUVGkp6eTlZXldBR1DIGBgURFHd/I/RorhCIyHWhZzkv3H/rEGGNE5KT+mSUiNwA3ALRt2/ZkLmUFBdHjcfCf+CJZoWvKCqG/f9UKoZ9fOB07PsPmzeMrPW/jxtvo1u31o44bYygt3Udx8W6KinbQpMnQ4/8ZlFLVxs/Pjw4dOjgdQ9WQGiuExpgK9+kQkV0i0soYkykirYDfT/KzpgJTwc4jPJlrARAUROR0YEIv8kP+XHjbzy+8ypdo2/ZufH0bsX790RNM4+NXsGRJDJmZU8nO/p6uXV8jPPxcNm68kx07Xjrq/MGDs/D3jzihH0UppVTlnLpH+A0w2vN4NPC1QznKd7BrtKCAJk3+XDLoeJdPa9Xqetq2nUBkpP1Rw8NHMnBgGqGh0fTo8REABw7sIDX1QmbN8i23CAJs3z5Z700opVQNcaoQPgWcKSIbgDM8zxGReBF58+BJIpIE/Bc4XUTSRaTy5dCry8FCmJ9PcLBdnSAgoN1xX0bERceOT9K9+zv067eE6OivCAy012nefBQtWhy9qebBz2vS5DSaNTsPgO3bn2bBgg5s2/YMKSnnMHOmsGPHayfykymllDqCLrFWnk2boHNnePddGD2aoqJMXK4A/PyaVUvGI+XmLqK0NB9f30aEhfU97LU//pjH8uUVrx/Yvv0kgoI6Exl5TY1kU0qp+qCyJdZ094nyHNI1ChAQ0KpGP65Ro4QKX2vceDCtWt1AZubUQ84fXDaAJy1tEgCFhVtp0+ZuXC6/8i6jlFKqAloIy3NEIXRa166v0rHj0/j5NcHtPoDbfYA5c8IOO2fLlvspKdlLp07POpRSKaXqJi2E5fGyQijiws+vCQAulz8ulz+DB+/E5QrB7S4kJ2cGq1dfyfbtk2ne/HLCwuJ1X0SllKoiLYTlCQiwX3v3Op2kQv7+B9cgCKVFiysICIhi+fKhLFuWgIg/jRsPo1Wr/yMy8ugBOUoppf6khbA8ItC8Oeze7XSSKmvc+M8BNcYcICdnBjk5Mygo2Ehh4RZat77lqIE4SimltBBWLCKiThVCAB+fUEpL9x12LC3tIQD27v2FQYOOXgRcKaUaOt2PsCLNm0MdW1ewf/9VtGp1IwBt2tx12GulpflORFJKKa+nhbAidbBFGBjYlm7dXiMx0dCp07P067eciIhLADvIRiml1NG0EFakDrYIjxQWFkuvXp8THn4BpaUFGOPGGMPvv0+juDjH6XhKKeUVtBBWpEULyM2F/LrdpSgiNG9+OaWlfzBrlg8LF3Zk9eorWbu29vc7Vkopb6SFsCLdu9vva9Y4m6MaREb+leDgXgAUFqYBkJ39HW53sYOplFLKO2ghrEjv3vZ7aqqzOaqBiNCv32K6dj1878Ndu953KJFSSnkPLYQV6dQJAgNh2TKnk1QLH58gTjnlBuLjU4iO/gE/v+Zs3HgHGRlv4HYXOR1PKaUco4WwIr6+MGwY/Pyz00mqVWhoDOHh59K+/SOUluaxfv0NLF7cG2NKnY6mlFKO0EJYmfPPh7VrISXF6STVrlGjgWWPCwo2smvXxw6mUUop52ghrMy110JICDz+uNNJql1YWCz9+69h8ODfAVi79lpWrrzI4VRKKVX7tBBWplkzuPtu+O9/4e23nU5T7UJCuuPv35zY2JkAZGd/y8qVF+N2H3A2mFJK1SIthMfywANwxhlw003w6adOp6kRTZqMICbG3gvNzv6azZvvpbR0P0VFGQ4nU0qpmqeF8Fh8fGwBTEiAK66ASZOguP7Nv2vUKKHscXr68yQlhTJ/fmvS0//tYCqllKp5WgiromlT+OUXe8/w4YchPh4WL3Y6VbXy9W3MsGH7jjq+d+8MB9IopVTt0UJYVYGB8P778NVXdjHugQPh5pthzx6nk1UbH58Q4uLm0q/fEoYPL8bf/xSys78mLe0Rp6MppVSN0UJ4vEaOhNWr4ZZb4PXX7cT7xx+H/fudTlYtGjceTFhYP1wuX0JCogFIS5vIkiX9WLXqCofTKaVU9dNCeCIaN4YXX4Tly2HQIDugpn17ePJJu1B3PdGr13/p2XMaQUHd2LdvGVlZn7Jx478wxjgdTSmlqo0WwpMREwM//ABz50L//nDffbYgPvww7N3rdLqT5usbRosWl9O165SyY+npz7Nr1wcOplJKqeqlhbA6DB5sC+LixTB8uB1Z2q4d3H9/ndvctzxNm57OiBHussE0a9eOZsOG23WNUqVUvaCFsDrFx9vBNMnJcM45tqu0fXs7KX/nTqfTnRQRwccnhB49PgRgx44XWb36Gu0mVUrVeVoIa0KfPnbuYWoqXHwxPP88dOgAt94K6elOpzspkZFX06/fckJD+7J79+fMnx+lC3Yrpeo0LYQ1qWdP+M9/7MLdV10Fr75qR5mOGwdpaU6nO2FhYbH067eIoKBuHDiQwYYN/3Q6klJKnTAthLWhSxe7VumGDfC3v9nHXbrA2LGwcaPT6U6IiA/9+6+gRYurych4lbVr/6bdpEqpOkkLYW1q3x5eew02b7Zrl378MXTrBn/9K6xZ43S64+Zy+dOhw6MA7Nz5LuvW/d3hREopdfy0EDohKgpeegm2bIE77oAvv4ReveDyy2HFCqfTHZegoI4MG2YXE9i5820WLOiM213icCqllKo6LYROatkSJk+29wsnTID//c8OtLn44jq1lqmPTzCDBu0AoLBwE4sX92DVqr+Qk5PkcDKllDo2LYTeoHlzeOIJWxAnToRZs+xuFwfnJ9aBe28BAacwYoSbxo2HU1Cwkaysz1i//ga9b6iU8npaCL1Js2Z2Mv62bbaluH07nH8+DBgAX3wBpd49TUFE6NPnF9q3f5Tw8AvJz1/Ltm1PaTFUSnk1RwqhiDQTkV9EZIPne9NyzokVkfkiskpEVohIw1nxOSwM/vUv2LQJ3ngDsrPh0kvtfcR33oED3ruDvMvlT/v2D9Cz58cAbNlyH2lpk5wNpZRSlXCqRTgBmGGM6QLM8Dw/Uj5wnTGmF3AO8IKINKnFjM7z94e//x3Wr4dp0yAoyE656NzZDrbJz3c6YYV8fELo3fsb/P1bsXXrI6xffxOlpQVOx1JKqaM4VQhHAu95Hr8HXHzkCcaY9caYDZ7HGcDvQPNaS+hNfHzsiNJly+w9w/bt4bbb7Hqmjz8OOTlOJyxXRMSFDBy4lSZNEsnIeI2kpGDy8+vmvEmlVP3lVCGMNMZkeh7vBCIrO1lEEgB/YFNNB/NqInDuuTB7NiQl2QE1DzwAbdvaUadeuJ6py+VHnz7T6dp1KgArV55HYeFWh1MppdSfaqwQish0EUkt52vkoecZO5KiwtEUItIK+AD4mzHGXcE5N4jIEhFZkpWVVa0/h9caOhS+/97uiXjeefDss7al+I9/eN3ybSI+nHLK9XTu/BIFBRtYsKA927Y943QspZQCQJwY0Sci64BEY0ymp9DNNMZ0K+e8RsBM4AljzGdVuXZ8fLxZsmRJteatEzZsgGeegffeA7cbrr4a7rnHDrDxIvv3r2Xx4h4AtGp1Iy1bjsHfvyVBQe2dDaaUqtdEZKkxJr6815zqGv0GGO15PBr4+sgTRMQf+BJ4v6pFsEHr0sWOMN282e5y8fnn0Lu3nZy/cKHT6cqEhHQnPj6ZJk0Sycx8neXLB7FwYQdKS7134I9Sqn5zqhA+BZwpIhuAMzzPEZF4EXnTc87lwHBgjIgke75inYlbh0RF2W2ftm2zk/Nnz4aBA+H002HGDK+YnB8a2ofY2N+Ijv6x7Ni8eaeQn7/BwVRKqYbKka7RmtRgu0YrkpcHU6fCc89BZib07w/33QcXXQQu59dTMMaQmnoR2dnfAdCp03O0aXOnw6mUUvWNN3aNqtpycHL+li3w+uuwZw9ccglER8P770NxsaPxRITo6G/p0OFxADZt+hfLlyfidjubSynVcGghbCgCAuCGG+wmwR9/DL6+MHq0vbc4ZQoUODvZvV27+0hI2EBoaF/++GMWs2f7s3PnBxQX73E0l1Kq/tNC2ND4+sKVV0JyMnz3HbRuDbfcYqdePPss7N/vWLTg4M7067eE5s3/AsDatdcxd244GzbcrqvSKKVqjBbChkrELug9Z47d7SI2FsaPtwXx6adh3z6HYgm9en1KTMxPtGhxJQA7drxIUlIw8+e3paTEmVxKqfpLC2FDJwLDh8NPP8G8eRAfb1epad8ennzSDrZxQLNmZ9Gz58ckJhpiYn4GoKhoO3PmhLF+/S243d678LhSqm7RQqj+NGgQ/PgjLFhgt3667z5bEB9/HHJzHYvVrNmZDB2aR0BAWwAyMqYwe3YAGzfeRVbW547lUkrVDzp9QlVs8WJ45BF7L7FpU7jjDjtZv3FjR+KUlhayd+8v7Nz5Drt3f1l23Ne3KZGR19G+/UT8/I7a0UsppSqdPqGFUB3b0qW2IH7zjS2I48fDP/8JISGORXK7D7Bjx8tkZ39LTs5MAER8adNmPB06PIqIdnYopf6khVBVj2XL4KGH7GLfLVrYe4njxtl9Eh2WmfkOmzbdRUmJnW7RosXVdOs2FZcrGBFxOJ1Symk6oV5Vj759bTfpvHkQEwN33mnvIT7/vOPzEFu1+htDhuymTZu7Afj9949ISgpl1iwX69aNo779g08pVX20EKrjN2gQ/PKLnXYRE2NXrunSxa5c4+BKNSJCp07PMGRINp07v0RgYCcAMjNfZ9YsF1u2TNKCqJQ6inaNqpM3cybcf79tKXbsCA8/bLeB8oK1TIuL9zB3bnjZc5crhDZt7sLlCo1YzDcAACAASURBVKRlyzEEBLR0MJ1SqrZo16iqWYmJdmL+99/bEaXXXmsn6H/zjeO7Xfj5NSMx0TBkyB7atXsIf/9Itm59mC1b7mX+/FZkZLzuaD6llPO0EKrqIQLnnQdLlti1TAsKYORIGDzYdqE6zM+vKR06PExCwmq6dp1KcLDdsHj9+nEsWtSDrKyvtNtUqQZKC6GqXi6XXct09Wq7/dP27bbFeOGFkJrqdDpcrgBOOeV6EhJSGTQoneDgXuTnr2XVqkvYsOGfFBZudTqiUqqWaSFUNcPPD66/Htavt0u1JSVBnz4wdiykpzudDoCAgNYkJKQyfHgRERGjyMiYwoIF7ZkzpxkZGW9y4MBupyMqpWqBFkJVs4KD7XzDTZvgttvgww/tCNPx4yE72+l0ALhc/vTq9Rk9e04jIKAdJSV7Wb/+eubNa05y8mlkZ3+PMW6nYyqlaoiOGlW1Ky0NJk6EDz6ARo3seqa33GILphcwxo0xJeTkzGbLlvvIy1tc9lrHjk8THNyNJk1Ox+Xyx+XydzCpUup46MoyyvukptqW4vffQ1SU7T71kikXh8rJmcWKFefidh++YIDLFUyzZmcTENCGjh2fxscn0KGESqmq0EKovNesWXaFmmXL7D3E//f/4NRTnU51GGPcZGV9Tk7OTER82b9/Jbm5i3C7/9zEuFOn54iKuoOSkhxd+FspL6SFUHk3t9tOuXjgAdt1et558OKL0Lmz08kq5HaXkJY2id9//5jCws2Hvdaq1d9p2/Y+goI6OJROKXUknVCvvJvLBddcY6dcPP20HWHasyfcdRfk5Didrlwuly8dOz7GwIGbGDx4J5GRfy17LTPzTRYu7Mi2bU/r3ESl6gAthMp7BAXZ0aTr1sF119nFvLt0gVdfhZISp9NVyN8/kh49PmDYsAISEtbRvPkVAGzePIHVq6/EmFKHEyqlKqNdo8p7LV9uNwOeNQt69YLnnoOzz3Y6VZUUFGxizZpryc2dT0BAOwICovDxCeGUU26gefNLnY6nVIOjXaOqboqLg99+gy++gMJCOOccOP98O0nfywUFdaJv33n06PEfQkJ6k5s7l717f2bVqsvYtm0ybneR0xGVUh5aCJV3E4FLLoFVq2DyZLu4d+/ecM89kJfndLpjioy8hpiY7xg+vJBevT7H5Qpk8+a7mTevFZs3P0BpaaHTEZVq8LQQqrohIMDue7h+Pfz1r/DMM9CtG/znP47vcFEVLlcAzZuPYsiQ3XTpMoWSkly2bXucOXOasHPnB07HU6pB00Ko6pbISHj7bViwwE7Ev/ZaGDrUzkOsA3x8Qmjd+mYGDdpK8+aXY0wRa9dex8yZwv79a5yOp1SDpIVQ1U0DBthi+NZbsGEDxMfDuHGwu24slB0Q0JpevaYxZMgeGjceDkBKypl671ApB2ghVHWXy2V3s1i/3i7o/eab0LUrTJni1dMtDuXn15S4uFl06/YWBw7sYPbsQLZte8bpWEo1KFoIVd3XpIldmi0lxY40veUW6NfPDqypI1q1GkvHjk8BsHnzPaxff5PueKFULdFCqOqPXr1g+nT47DO7Is2wYTBmDGRmOp2sStq2vYcBAzbRsuXfyMh4jbVrR+ueiErVAi2Eqn4RgUsvtcu1TZgAH31ku0uff75OdJcGBXWkW7e3aNfuIXbt+g/z5jUnNfVS8vPXOR1NqXpLC6Gqn0JC7NZOq1bBiBF26kV8PMyf73SyYxIROnR4mLi4eQQEtGX37i9YtKg7GRmva3epUjXAkUIoIs1E5BcR2eD5ftS+NSLSTkSWiUiyiKwSkXFOZFV1XJcu8O23dnWa7GwYPBhuvBH27HE62TE1bjyIgQPTiI7+DoD168eRknK6LuStVDVzqkU4AZhhjOkCzPA8P1ImMMgYEwsMACaIyCm1mFHVFwdXp1mzxrYM33oLuneH99/3+sn4IkJ4+PnEx6+kRYuryMmZyYIFHXC7DzgdTal6w6lCOBJ4z/P4PeDiI08wxhwwxhycVBWAduOqkxUaapdpW7oUOnWC0aPtJsDrvP/+W2hob7p3fxd//5YUFW1lyZJYnXOoVDVxqrhEGmMODuXbCUSWd5KItBGRFcB24GljTEYF590gIktEZElWVlbNJFb1R58+MHcuvP66nXIRE2P3Pty3z+lklXK5/ImPX4mIP/n5a5g9O5Di4r1Ox1KqzquxQigi00UktZyvkYeeZ+wNj3L7p4wx240xMUBnYLSIlFswjTFTjTHxxpj45s2bV/vPouohlwtuuAHWrrWbAj/3nF3M+6efnE5WKX//CIYNy6NRo4EALFzYSadYKHWSaqwQGmPOMMb0Lufra2CXiLQC8Hz//RjXygBSgWE1lVc1UAfXLk1KshsDn3OOLYw7dzqdrEIulz9xcXNp3HgEJSV7mTevuS7crdRJqFIhFJEQEXF5HncVkYtExO8kPvcbYLTn8Wjg63I+M0pEgjyPmwJDAe+/maPqpqFD7UbADz1kJ+R37w6vvgql3rm7vIiL2Nhf6dz53wCsXXsd69bdqCNKlToBVW0RzgYCRaQ18DNwLfDuSXzuU8CZIrIBOMPzHBGJF5E3Pef0ABaKSAowC5hsjFl5Ep+pVOUCA+Hhh2HlSjvn8Oab7XSLld75n52Ii6ioWxgyZC/Nmp1DZuZUZs1ykZJyJsZ4ZwFXyhtJVf4FKSLLjDF9ReSfQJAx5hkRSfZMbfAq8fHxZsmSJU7HUHWdMfDxx3D77Xa5tocespsB+51MR0jNMaaU9PSX2LTpTgACAtrQo8eHNGmidxOUAhCRpcaY+PJeq2qLUERkEHAN8L3nmE91hFPKK4nA1VfbpdouvRQefBD69rWjTb2QiA9t2tzBiBGltG59C+AiOXk4u3Z94nQ0pbxeVQvh7cC9wJfGmFUi0hH4reZiKeUlIiJsy/DrryE31y7kPW4c5OU5naxcIi66dPk3ffr8Aghr1lxFcvKplJTkOh1NKa9Vpa7Rw95gB82EGmO88v8s7RpVNWbfPttF+sIL0K4dvPIKnHuu06kqVFy8h8WLozlwIANf33Di4uYQEtLd6VhKOeKku0ZF5CMRaSQiIdhpDKtF5O7qDKmU1wsNtbtYJCXZe4XnnQeXXw67djmdrFx+fs0YNGgbbdrcTUlJNosX92DNmtEUF+c4HU0pr1LVrtGenhbgxcCPQAfsyFGlGp4hQyA1FR57zHaZ9ugB77zjleuWivjQqdMzREf/SHBwd3btep+UlNN0FwulDlHVQujnmTd4MfCNMaaYClaDUapB8PeH+++H5GTo2RPGjoWzzoLt251OVq7w8HNISFhD27b3sm/fcmbN8iEt7RF27fpI1yxVDV5VC+HrQBoQAswWkXaAV94jVKpW9egBs2fb+4Xz50OvXvDyy17ZOgRo1+4hQkKiAUhLm8iaNdeQlvaIw6mUctZxD5Ype6OIrzHG67b81sEyyjGbNsE//mHXKz31VHjjDbvLhRcqLS1k48bbyMycCkCTJqfTpctLhIT0dDiZUjWjOgbLNBaR5w/u8CAiz2Fbh0qpgzp1gh9/tEuzLV8O0dHw1FNQ4nX/XsTHJ5Bu3V5n8OAsIiOvIydnBosX92L9+pv1/qFqcKraNfo2kAdc7vnKBd6pqVBK1Vkidp7hypV2asW998KAAbBsmdPJyuXvH0GPHu8RH78CgIyMV1m4sCtr1oxmz55fHE6nVO2oaiHsZIyZaIzZ7Pl6GOhYk8GUqtOiouDzz+G//4WMDEhIgLvvhoICp5OVKzQ0mkGDMomMHE1JSQ67dr3PihVn6f1D1SBUtRAWiMjQg09EZAjgnf9HK+VNLrvMLtM2dixMngxxcTBvntOpyhUQ0JIePd5l8OAdtGv3EOAiLW0i27c/53Q0pWpUVQvhOGCKiKSJSBrwMnBjjaVSqj5p2hSmToX//c8uzZaYCI88AsXFTicrl8sVQIcODzN8eCGNGg1h06a7mDMnnJycJNxu77vfqdTJqlIhNMakGGP6ADFAjDEmDjitRpMpVd+cfbadiH/ZZTBxot3qaelSp1NVyOXyo3fvL/DxCaOkZA/JycOZPduPuXMjyc/f6HQ8parNce1Qb4zJPWSN0TtrII9S9VvTpvDRR/DVV5CVZe8d3nsvFBY6naxc/v4tGDr0D+Li5hIRcSkAxcW/s2hRF1asOI/S0nyHEyp18o6rEB5Bqi2FUg3NyJH23uGYMXaKRZ8+MGuW06nKJSI0bjyY3r0/IzHR0KvXZ/j6NmXPnh9JSgph1aorKC7OdjqmUifsZAqhdy6doVRd0aQJvPUW/PyzvV+YmGhHlh444HSySjVvfilDh+6ha9fXCA7uSVbWpyxZ0pfs7O8pLfXOlq1Slam0EIpInojklvOVB5xSSxmVqt/OPNOuWXr99XZkaUICpKQ4neqYTjnlRhISVhEba1uyK1dewIIFbUhLe5TSUh1UruqOSguhMSbMGNOonK8wY4xvbYVUqt5r1MiOLP3mG9i5E/r3t7tbeOnI0kM1aTKcvn3n0bHjU7jdRaSlPcTSpbaFqFRdcDJdo0qp6nbhhbBqFYwaBQ8+CH37wqJFTqc6poCA1rRtew+DB2cSFjaA/Py1rFx5ASkpZ1FQsMnpeEpVSguhUt4mPBw++cSOLN27FwYNggkTvHZk6aF8fELo128BXbq8gogve/f+wsKFnVm8OIbs7P85HU+pcmkhVMpbjRxpW4djx8LTT9tVaRYscDpVlbRufRNDh+YSGflXAPbvX8nKleeyffsLOilfeR0thEp5s8aN7XZOP/0E+/fDkCFw111eu2bpoXx8gujR4wNGjHAzaFAGISHRbNp0B7Nn+7FwYXftMlVeQwuhUnXBWWfZVWmuvx6eew5iY2HuXKdTVYmIEBDQivj4ZKKi7qRx42EUFKwjJeVsdu/+Dre7yOmIqoHTQqhUXdGoEbz2GkyfbucaDhsGd9wB+XVjdRcRF507P0dc3GxiYv7HgQMZpKZeyOzZgaxbdyP79qU6HVE1UFoIlaprTj/d7nd4883wwgvQpQvMn+90quPSrNnZJCSso1GjQQBkZk5l6dJ+5OYudjiZaoi0ECpVF4WGwssv29ahry+MGAGTJtWJeYcHBQa2oW/fefTtu4B27R4AhGXLEkhOPo2iogyn46kGRAuhUnXZ6afD8uVw/vnw8MN2MM2qVU6nOi6NGg2gQ4dH6d/frqaTk/Mb8+e3JjV1FMaUOpxONQRaCJWq65o1gy+/hP/+F7ZssdMsHn8cSutWEQkO7kZCwjratBkPwO7dX5KaOoqSkn2UlPzhcDpVn4kx9Wvt7Pj4eLNkyRKnYyjljKws+Oc/Ydo02zp87z3o1MnpVMfN7S5i8eLeFBT8ue9hfHwKoaExDqZSdZmILDXGxJf3mrYIlapPmjeHjz+GDz6wA2p69YJnnqlzrUOXK4D4+GQiI68rO7ZkSR9mzhRSUs7SLlNVrbQQKlXfiMBf/2rnHQ4bBvfcY1uHaWlOJzsuPj4h9OjxHgkJG+jd+9uy43v3/sL8+W0pKdnnYDpVn2ghVKq+atPG7nX46qt2AE10tF2lpo7dDgkO7kxExAWMGFFK584vAXDgQAZz5oSxadN4jHE7nFDVdY4UQhFpJiK/iMgGz/emlZzbSETSReTl2syoVL0gAuPG2dZhQgLccAOccw5s3+50suMm4iIq6p8MGpROs2bnA7B9+7OkpJxOXt4yh9OpusypFuEEYIYxpgsww/O8Io8Cs2sllVL1Vbt28MsvMGUKzJkDvXvDO+/UudYh2C2fYmK+o2/fRYSERJOTM5OlS/uxcuVF5OdvPPYFlDqCU4VwJPCe5/F7wMXlnSQi/YBI4OdayqVU/eVy2dVoVq60a5WOHQsXXAAZdXPyeqNG/YmPT6Fz5xcAyM7+lkWLupOUFMbMmb6sWvUX3elCVYlThTDSGJPpebwTW+wOIyIu4DngrtoMplS917Ej/PYbvPii/d6rlx1lWgdbhyJCVNRtJCYa4uNTCAnpTWnpPqCUrKzPmD3bj717ZzodU3m5GiuEIjJdRFLL+Rp56HnGTmQs7//Am4EfjDHpVfisG0RkiYgsycrKqqafQKl6zOWCW2+FlBTo2ROuuw4uuQR27nQ62QkLDY2hX78lDByYRp8+M4iMHA1ASsqp/P77Zw6nU97MkQn1IrIOSDTGZIpIK2CmMabbEed8CAwD3EAo4A+8Yoyp7H6iTqhX6niVltrW4X33QUiIvY94xRV2oE0dt2fPdFasOBOAgIB2dOjwGC1b/tXhVMoJlU2od6oQPgtkG2OeEpEJQDNjzPhKzh8DxBtjbjnWtbUQKnWC1q6FMWNg4UK49FJ45RVo0cLpVCftwIFdpKaOIjd3XtkxH58wfH2b0bTpGXTp8iI+PiEOJlS1wRtXlnkKOFNENgBneJ4jIvEi8qZDmZRq2Lp3tyNKn3oKvv3W3jv8rO53Kfr7RxIXN4fu3T8AIDi4J8a4KSrays6db5GUFEpKypmUlhY6nFQ5RdcaVUodbdUqGD0ali613aRTpkB4uNOpqpUxhiVL4ti/P6XsWJs299Cx45NIPegWVofzxhahUsqb9eplN/t97DH44gv7/OuvnU5VrUSE+PhlDByYRlTUnQBs3/40s2a5WLCgA/v3r6awcBuFhXVv8QF1fLRFqJSq3IoVtnWYnGzXMH3xRbv1Uz1ijCEnZyYrVpyDMQeOej0iYhTdu7+Nr29jB9Kp6qAtQqXUiYuJgUWLYOJE+OQTuyrN9987napaiQhNm57K8OH5jBhRQs+e0w57fffuL5gzpwnp6f92KKGqSVoIlVLH5ucHkybZEaUREXZFmrFjISfH6WTVSsQHER9atLicAQM206nT8/Tvv5oOHZ4EYOPGW9m9+zvc7mKHk6rqpF2jSqnjU1QEjz5qR5e2agVvvglnn+10qhqXnf0jK1eed9ixjh2fpk2bu7ALYSlvpl2jSqnqExBgB9HMnw9hYXY3ixtugNxcp5PVqPDwc+nU6f8ddmzz5nuYNcuHhQu7ardpHaaFUCl1Yvr3h2XLYPx4eOst6NYNvvvO6VQ1qk2b20lMNCQmGvr1+3Prp8LCbWzceCuZme9SXFy/uosbAi2ESqkTFxgITz9tJ+I3agQXXghXXgm7djmdrMaFhcUxeHAW/fotY8iQ3/H3b8W6dX9j7tym7N07k/p226k+00KolDp5gwbZ7Z0mTIBPP7XbPH3zjdOpapy/fwRhYXH4+jaib9/5NGmSCNiFvmfNcrFu3Y2UlhY4G1IdkxZCpVT18PeHJ5+E2bOheXMYOdKuSlNH9zs8XoGB7YiN/Y3u3d8tO5aZOZWkpGBmzvQlPf1l58KpSmkhVEpVr6FDYckSePhh+PJLOw/x88+dTlVrWrYczYgRpfTvv4p27R70HC1l48Z/snBhN5164YW0ECqlqp+/Pzz0EMybB23bwmWX2a86vN/h8RBxERLSkw4dHmHECDexsUkAFBSsZ/ZsfxYvjmX37u8oKNii9xK9gBZCpVTNiY+3q9I8+aQdUVpPdrQ4HiJCkyZDGTZsH8HBvQDYvz+F1NQLWbiwI2lpE8nP3+BwyoZNJ9QrpWrHmjVwzTWwfDmMGmX3O4yMdDqVI3bv/pZt254gN3fBYccHDcogIKCVQ6nqN6/bmLcmaSFUyosdOADPPWfvH4aG2gW8r74aGui2R0VFO8nIeIWtWx8tO+bnF4ExJbRrNxEwREb+FX//5s6FrCe0ECqlvMuaNfC3v9m1S8880y7T1rat06kcc+DALjZvvpedO98p9/Xevb8lIuKCWk5Vv+gSa0op79KjB8ydCy+/bJdq69ULXngBSkqcTuYIf/9Iund/m6FD/2DYsAISEtbRosXVZa+npl7Ijh2vOZiwftMWoVLKWVu2wM03w//+B6edZpdra9/e6VReY+/e30hJOQ2AkJA+dO06hcaNhzicqu7RFqFSynt16AA//GAL4MKF0LOnHWV64OgNchuipk1PJSFhA2Fh8ezfn8Ly5UNJS3vM6Vj1ihZCpZTzROz+hmvWwLnnwn33QZ8+8NtvTifzCsHBnenTZzodOjwBQFragyxd2p/8/HUOJ6sftBAqpbxHmzZ2FZrvv7f7Hp52Gtx9NxToep2+vo1p1+5eBg3KoGXLsRQUbGLRou6sXHkRWVlfUFSUQVHRDqdj1kl6j1Ap5Z3y8+HOO+H116FTJ/j3v21rUQGQmfku69b97ajjffr8RtOmibUfyMvpPUKlVN0THAyvvQYzZoAxcN55dpun9HSnk3mFli1H06/fUjp2fPaw4ykpp7Jx478wptShZHWPtgiVUt4vNxeeespOsSgogOefh9tvb7AT8Y/kdhdjTDE5OTNZvfpKSkvz8PFpRNu2E4iKug2XKxCRht3u0Qn1Sqn6Yd06SEy0i3cPHw4ffNCgJ+KX58CBLDZvvueoyfmBge0JDOxE06anExDQmrCwfrhcIQQFtXcmaC3TQqiUqj9KSuxUi7vusl2m48fDvfeCn5/TybxKaWkBq1dfQXb2t5WeN2DAlgZRDLUQKqXqn7Q02z369dd2z8NXXoEhOtH8SMa4+f33T/HxCaWoaDvgZvfub9i3L4Xi4l2EhPQhOvpbAgPbOB21RmkhVErVX199BbfeCtu32wW8X3oJwsOdTlUnZGf/SGrqSIwppmXLsXTr9ka9vZeoo0aVUvXXxRfD6tW2GH7yiV239J13bLepqlR4+LnExPwEwM6db7Nu3d8dTuQMLYRKqbrv4JZOS5dCixZ2lZqLLoLUVKeTeb2mTU9l0KB0RPzZufMdNm78F6Wl+U7HqlVaCJVS9UdsLCQn27VKk5IgPt4+LipyOplXCwhozZAh2YSHjyQ9/XmSkkKYOVNYv/4m3O76v+ar3iNUStVP6enwj3/AN99A587w6qtwxhlOp/JqxrjJyvqMzMw32bv3l6NeHzhwW50dVKODZZRSDdfPP9uCuHEjnHUWPPOMXdBbVaqkZB/Llw9l//6Uw44HBXUjIuJi9u1LJi9vMb6+TQkIaI3LFUSvXp/i69vIocSV00KolGrYCgttAXzkEQgIgMces8XR39/pZF7N7T5AaWkebncxK1dewL59Sys9PyioGz16/IdGjcqtN47yukIoIs2AaUB7IA243Bizt5zzSoGVnqfbjDEXHevaWgiVUhVKSbG7WfzyC3TvbkeXDhzodKo6o6BgE5s33w9AWFg8/v6RhIT0xpgSdu58m4yM1wBo3Hg4LVpcSZMmpxIc3AURHydjA95ZCJ8B9hhjnhKRCUBTY8w95Zy3zxgTejzX1kKolKqUMXYj4HHjYMcOO/fw+eftaFN1wowxpKc/z6ZNdx12PDCwE127vkJe3jJ+//0T2rS5k5Ytr6v1fN5YCNcBicaYTBFpBcw0xnQr5zwthEqpmpGXB48+aifgh4XZRb3HjtWFvE9SaWk+hYVpbN8+mb17f6WoaOtR57RocTWdO79IcXEWRUXbadr09BpvNXpjIcwxxjTxPBZg78HnR5xXAiQDJcBTxpivjnVtLYRKqeOSmmpbh3Pn2kE0//43DBvmdKp6Iy9vGbm5C8nPX0doaAx79vxIVtZnh50TEBBFp07Pk5PzG0FBXYmK+ie//z6NwsIt+PqG07Lltfj4hJxUDkcKoYhMB1qW89L9wHuHFj4R2WuMaVrONVobY3aISEfgV+B0Y8ymcs67AbgBoG3btv22bj36XyBKKVUhtxs+/NAu4L1zp20ZPvEEREY6nazecbuLSEt7mG3bnsTlCsbtrnzyvkgAgwdn4ud3VIk4Lt7YIqxS1+gR73kX+M4Y81ll52mLUCl1wg52l77wAgQF2YE148fr6NIa4HaX4HL5UlpawLp1YzHGjb9/C0pK8ti9+wuiom6jsHAbzZqdQ2TkVSf9ed5YCJ8Fsg8ZLNPMGDP+iHOaAvnGmCIRiQDmAyONMasru7YWQqXUSVu/3hbAr7+Gdu1sd+mFFzqdSp0Eb1x0+yngTBHZAJzheY6IxIvIm55zegBLRCQF+A17j7DSIqiUUtWia1e7q8W330JIiF239IILdO3Sekon1CulVGUOHLAjSx9+GPbtg7PPhmefhehop5Op4+CNLUKllKob/P3hrrtsd+lpp8FPP0H//nYwTWGh0+lUNdBCqJRSVdGqFcyYAStXwumnw/33Q+/e8N13TidTJ0kLoVJKHY/eveH77+1i3n5+dhDN+efr/cM6TAuhUkqdiDPPtGuXTp5s9z6MjrYT8/fvdzqZOk5aCJVS6kT5+8O//gWbN8N118Hrr9u9D59+WjcDrkO0ECql1MmKiID33oM5c6BLF5gwAWJi4L//tYt8K6+mhVApparLkCEwezb8+KNdtu3yyyEx0W77pLyWFkKllKpu55wDq1fDiy/Cli1w1ll2kv68eU4nU+XQQqiUUjXBzw9uvRU2bLDLtW3ZYluM11xj90FUXkMLoVJK1aSAADt45vffbVfptGnQrRs88gj88YfT6RRaCJVSqnY0bWqL4Lp1MGIETJxoC+KECXbXC+UYLYRKKVWbOnWyq9HMmQNRUba12LYtvPaaHWCjap0WQqWUqm0i9n7h4sXw6qt2PuJNN9k1TH/91el0DY4WQqWUcoqIXY0mIwPeeQd277brmJ52Gkyf7nS6BkMLoVJKOc3HB8aMsfcPn37azkU880wYNQqWL3c6Xb2nhVAppbxFYKCdapGTY/c/nDED+va1RTI52el09ZYWQqWU8jahofDQQ7Btmx1V+vHHEBdnNwXWgljttBAqpZS3atwYnnzS3kN88EG7Mk3fvvY+YkqK0+nqDS2ESinl7cLD7QT87dvtbhe//mpbiFdfDRs3Op2uztNCqJRSdUWTJvDss5CVZbtMv/4aevSwUy8yMpxOV2dpIVRKqbomIgKeeAI2bYIbb4S33rL7II4aBTt3Op2uztFCqJRSdVXLlvDyAlPWvwAAC+BJREFUy7B2LVx0EXz5JbRqZYvjhg1Op6sztBAqpVRd17EjfPIJJCXB6NHw9tt226crr4TUVKfTeT0thEopVV8MHQrvvgtr1tgVa77+GmJi4LLL4KefnE7ntbQQKqVUfdO5s13DdP16O5Dm88/tZsEJCTBrltPpvI4WQqWUqq/atIEpU+wo0/vug61bITERBgyAn392Op3X0EKolFL1XUQEPP44pKXBU0/Z72efbSfsv/02FBU5ndBRWgiVUqqhCAqCe+6xS7fdey/s2wf/93/QpYvdD7G42OmEjtBCqJRSDU1AgJ2HmJv7/9u78xi7yjKO49+fU2xY27KklJbSooWIUekCNJZFEMtSpKiJ0BApS9LQIEIMCAIxJPCHLIpUtlAEi6K0IkshEbsIKMFCWyjdWFqQgmRoC6UgS7DUxz/ed+B0OndkcOaec+f+PsnNPfe95555zpt3znPPe859X7jhhjS26dSp6dritdfC+++XHWFdORGamTWr7bdPCXDFCrj/fhg4EM49F7bbLg3ftmhR2RHWhROhmVmzk+C44+Dxx+Hhh2H06DTjxQEHwPjx6Yf6EWVH2WOcCM3MLJHgsMPSmeCbb6ZJgpcuTUO39esHV1+dynsZJ0IzM9ta//5pkuA1a9J1xD594PzzYfBgOOusXpUQnQjNzKy2vn3TdcQNG2DxYpg0KSXGIUPSHaePPdbw3aalJEJJO0uaK2lVfh5QY72hkuZIekbSSknD6hupmZl9ZNSoNNPFggUpIc6cCePGpWuJs2Y17N2mZZ0RXgjMj4gRwPz8uiO3A1dFxBeAA4F1dYrPzMxqOegguOWWNOXTddel5xNPTHebXnllOntsIGUlwonAjLw8Azih/QqS9gP6RMRcgIh4JyLeq1+IZmbWqR12SNcL16xJd5buvnv6wf7QoTBlShrrtAGUlQgHRkRrXn4NGNjBOvsAGyXdLekpSVdJaqlfiGZm9om0tMAJJ0Bra7rj9Kij4LbbYN9902Dfs2fD5s1lR1lTjyVCSfMkLe/gMbG4XkQE0NGV1j7AIcB5wAHA3sCpNf7WFEmLJC1av3599+6ImZl9cqNHp9kuXn4ZLr0Uli2DiRNh+PA03um775Yd4VYUJdztI+k54GsR0SppEPBwROzbbp2xwBURcVh+/T1gbESc1dm2x4wZE4uaZDQEM7PK27QpjVpz440wbx7suCNMmJButpkwIZ1N1oGkxRExpqP3yuoanQ1MzsuTgfs6WGch0F/Sbvn1EcDKOsRmZmbdZZtt0g/y586FRx9NN9U88EA6Sxw0CM45J509lqisRPhT4BuSVgFH5tdIGiPpFoCI2EzqFp0vaRkgYHpJ8ZqZ2f9r3DiYPj1dS5w1K/3sYto02GsvGDkSrrkGPvyw7mGV0jXak9w1ambWQNasgcsvTz/HgDQDxumnw+TJsMce3fZnqtg1amZmls4Gp09PN9Fcdlka2u2ii9JQbqNHw1139fjINU6EZmZWvu22g0sugYUL07XEs8+GlSvTTTWvvNKjf9qJ0MzMqmXcuHTtcONGmDMn/UC/BzkRmplZNfXtC4cf3uN/xonQzMyamhOhmZk1NSdCMzNrak6EZmbW1JwIzcysqTkRmplZU3MiNDOzpuZEaGZmTc2J0MzMmpoToZmZNbVeNw2TpPXAmm7Y1K7A692wnXpptHih8WJutHih8WJ2vD2v0WLurnj3iojdOnqj1yXC7iJpUa25q6qo0eKFxou50eKFxovZ8fa8Rou5HvG6a9TMzJqaE6GZmTU1J8Labi47gC5qtHih8WJutHih8WJ2vD2v0WLu8Xh9jdDMzJqazwjNzKypORF2QNLRkp6TtFrShWXHAyBpT0kPSVopaYWkc3L5pZJelbQkP44tfObHeR+ek3RUCTG/JGlZjmtRLttZ0lxJq/LzgFwuSdNyvEsljSoh3n0L9bhE0tuSzq1SHUu6VdI6ScsLZV2uU0mT8/qrJE0uIearJD2b47pHUv9cPkzS+4W6vqnwmdG5Pa3O+6U6xtvlNlCv40iNeGcWYn1J0pJcXoX6rXUsK68dR4QfhQfQArwA7A18Fnga2K8CcQ0CRuXlHYHngf2AS4HzOlh/vxx7X2B43qeWOsf8ErBru7IrgQvz8oXAFXn5WOBPgICxwOMVaAevAXtVqY6BQ4FRwPJPW6fAzsCL+XlAXh5Q55jHA33y8hWFmIcV12u3nSfyfijv1zF1jLdLbaCex5GO4m33/s+An1Sofmsdy0prxz4j3NqBwOqIeDEi/g3cCUwsOSYiojUinszL/wKeAQZ38pGJwJ0R8UFE/ANYTdq3sk0EZuTlGcAJhfLbI1kA9Jc0qIwAs68DL0REZ4Mz1L2OI+KvwIYO4uhKnR4FzI2IDRHxJjAXOLqeMUfEnIj4ML9cAAzpbBs57p0iYkGko+DtfLyfPR5vJ2q1gbodRzqLN5/VfRf4fWfbqHP91jqWldaOnQi3Nhh4pfD6n3SecOpO0jBgJPB4Lvp+7jK4ta07gWrsRwBzJC2WNCWXDYyI1rz8GjAwL1ch3qKT2PLgUdU6hq7XaVXibnM66Rt/m+GSnpL0iKRDctlgUpxtyoi5K22gKnV8CLA2IlYVyipTv+2OZaW1YyfCBiNpB+CPwLkR8TZwI/A5YH+gldQNUhUHR8Qo4BjgLEmHFt/M3zwrd9uypM8CxwN/yEVVruMtVLVOa5F0MfAhcEcuagWGRsRI4IfA7yTtVFZ8BQ3TBtqZxJZf6CpTvx0cyz5S73bsRLi1V4E9C6+H5LLSSdqG1HDuiIi7ASJibURsjoj/ANP5uGuu9P2IiFfz8zrgnhzb2rYuz/y8Lq9eerwFxwBPRsRaqHYdZ12t00rELelU4Djg5HzgI3cxvpGXF5Ous+2T4yt2n9Y15k/RBkqvY0l9gG8DM9vKqlK/HR3LKLEdOxFubSEwQtLwfGZwEjC75Jja+vp/BTwTET8vlBevo30LaLtzbDZwkqS+koYDI0gXw+sV7/aSdmxbJt0csTzH1XZ312TgvkK8p+Q7xMYCbxW6Septi2/RVa3jgq7W6Z+B8ZIG5C6+8bmsbiQdDfwIOD4i3iuU7yapJS/vTarTF3Pcb0sam/8XTuHj/axHvF1tA1U4jhwJPBsRH3V5VqF+ax3LKLMdd8ddQL3tQbpL6XnSt6WLy44nx3QwqatgKbAkP44FfgMsy+WzgUGFz1yc9+E5eugOsE7i3Zt0p9zTwIq2egR2AeYDq4B5wM65XMD1Od5lwJiS6nl74A2gX6GsMnVMStCtwCbSNZEzPk2dkq7Lrc6P00qIeTXp+k5bW74pr/ud3F6WAE8C3yxsZwwpAb0AXEceEKRO8Xa5DdTrONJRvLn818CZ7datQv3WOpaV1o49soyZmTU1d42amVlTcyI0M7Om5kRoZmZNzYnQzMyamhOhmZk1NSdCs4qStFlbzobRbTMYKM1CsPx/r2nW+/UpOwAzq+n9iNi/7CDMejufEZo1GKX55a5UmjvuCUmfz+XDJP0lDww9X9LQXD5Qac6/p/Pjq3lTLZKmK80JN0fStnn9HyjNFbdU0p0l7aZZ3TgRmlXXtu26Rk8svPdWRHyJNALIL3LZL4EZEfFl0iDW03L5NOCRiPgKad66Fbl8BHB9RHwR2EgadQTSXHAj83bO7KmdM6sKjyxjVlGS3omIHToofwk4IiJezIMXvxYRu0h6nTT016Zc3hoRu0paDwyJiA8K2xhGmsttRH59AbBNRFwu6UHgHeBe4N6IeKeHd9WsVD4jNGtMUWO5Kz4oLG/m43sGJpDGdhwFLMyzGJj1Wk6EZo3pxMLz3/PyY6RZDgBOBv6Wl+cDUwEktUjqV2ujkj4D7BkRDwEXAP2Arc5KzXoTf9Mzq65tJS0pvH4wItp+QjFA0lLSWd2kXHY2cJuk84H1wGm5/BzgZklnkM78ppJmK+hIC/DbnCwFTIuIjd22R2YV5GuEZg0mXyMcExGvlx2LWW/grlEzM2tqPiM0M7Om5jNCMzNrak6EZmbW1JwIzcysqTkRmplZU3MiNDOzpuZEaGZmTe2/T06c8jRq3PMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAFNCAYAAACdVxEnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcddn//9c1k0yWJt3TvaUttJSWNt1o2amCWpa7VRahuCHKJqjginKLiHrLfct9u3xFvKugt95IQb3hV7UsIquytewUCpTS0pQu6d40+8z1++OcSSbpJE3aTJLOvJ+PRx4558yZc645nX6uXJ9zzueYuyMiIpKNIj0dgIiISKYoyYmISNZSkhMRkaylJCciIllLSU5ERLKWkpyIiGQtJTnpNmZ2n5l9qqvX7UlmttbMTsvAdt3Mjginf2Fm3+rIugewn4+Z2YMHGmc2MrMxZlZlZtGejkUOnuk+OWmPmVWlzBYDdUA8nL/M3e/o/qh6DzNbC3zW3R/q4u06MMHdV3fVumY2FngHyHf3xq6IU6S3y+vpAKR3c/eS5HR7DbqZ5anhlN5C30dJUnelHBAzm2dmFWb2dTPbBPzazAaY2V/MrNLMdoTTo1Le86iZfTacvsjM/mFmN4frvmNmpx/guuPM7HEz22NmD5nZLWb2v23E3ZEYv2tm/wy396CZDU55/RNmts7MtpnZde0cn7lmtim1y8vMPmJmL4fTc8zsKTPbaWYbzexnZhZrY1u/MbPvpcx/NXzPe2Z2cat1zzSzF8xst5mtN7MbUl5+PPy9M+yOOy55bFPef7yZLTezXeHv4zt6bDp5nAea2a/Dz7DDzO5NeW2hmb0Yfoa3zWx+uLxF17CZ3ZD8dzazsWG37WfM7F3g4XD5H8J/h13hd2RKyvuLzOw/w3/PXeF3rChlW3nhev3M7LbwmG8ws+8l/13N7Agzeyx8/1Yzuyvd8ZCeoyQnB2MYMBA4DLiU4Pv063B+DFAD/Kyd988F3gAGA/8B3GZmdgDr/h54FhgE3AB8op19diTGC4FPA0OAGPAVADObDNwabn9EuL9RpOHuzwB7gfe32u7vw+k4cE34eY4DTgU+107chDHMD+P5ADABaH0+cC/wSaA/cCZwhZl9OHzt5PB3f3cvcfenWm17IPBX4KfhZ/sv4K9mNqjVZ9jn2KSxv+P8O4Lu7ynhtn4UxjAH+C3w1fAznAysbet4pHEKcBTwoXD+PoLjNAR4HkjtXr8ZmAUcT/A9/hqQSLPN3wCNwBHADOCDwGfD174LPAgMIPgu/L9OxCrdwd31o58O/RA0NqeF0/OAeqCwnfWnAztS5h8l6O4EuAhYnfJaMeDAsM6sS9CANgLFKa//L/C/HfxM6WL815T5zwH3h9PXA0tSXusTHoPT2tj294Dbw+lSggR0WBvrXg3ckzLvwBHh9G+A74XTtwM3paw3MXXdNNv9MfCjcHpsuG5eyusXAf8Ipz8BPNvq/U8BF+3v2HTmOAPDCZLJgDTr/Xcy3va+f+H8Dcl/55TPNr6dGPqH6/QjSMI1QHma9ZqOEzCU4Dx0Ucrri4BHwunfAouBUd3xf1A/nf9RJScHo9Lda5MzZlZsZv8ddv/sJuge629tX6W2KTnh7tXhZEkn1x0BbE9ZBrC+rYA7GOOmlOnqlJhGpG7b3fcC29raF0HVdraZFQBnA8+7+7owjolhF96mMI5/I6jq9qdFDMC6Vp9vrpk9EnYT7gIu7+B2k9te12rZOmBkynxbx6aF/Rzn0QT/ZjvSvHU08HYH402n6diYWdTMbgq7PHfTXBEODn8KO7Cvw4B8YGPYtbyTIBEPCV//GmDAs2a2snX3sfQ8JTk5GK0vzf0ycCQw19370tw91lYXZFfYCAw0s+KUZaPbWf9gYtyYuu1wn4PaWtndXyNIEqfTsqsSgm7PVQRXRfYFvnkgMRBUsql+DywFRrt7P+AXKdvd36XU7xE06qnGABs6EFdr7R3n9QT/Zv3TvG89cHgb29xLUMUnDUuzTupnvBBYSNCl24+gQkvGsBWobWdfqfHUAYPdvX/409fdpwC4+yZ3v8TdRwCXAT+3A7ydQzJDSU66UilBF9DO8PzOtzO9w7AyWgHcYGYxMzsO+JcMxfhH4CwzO9GCi0RuZP//h34PfJGgkf9Dqzh2A1VmNgm4ooMx3A1cZGaTwyTbOv5SgiqpNjy/dWHKa5UE3YTj29j2MmCimV1oZnlmdj4wGfhLB2NrHUfa4+zuGwnOlf08vEAl38ySSfA24NNmdqqZRcxsZHh8AF4ELgjXnw2c24EY6giq7WKCajkZQ4Kg6/e/zGxEWPUdF1bdpKy3keCc23+aWd8wpsPN7BQAMzsv5YKaHQRJNt15PekhSnLSlX4MFBH8lfw0cH837fdjBBdvbCM4D3YXQeOWzgHH6O4rgSsJEtdGgkatYj9vu5PgYoiH3X1ryvKvECSgPcAvw5g7EsN94Wd4GFgd/k71OeBGM9tDcA7x7pT3VgPfB/4Zdr0d22rb24CzCKqwbQRdcWe1iruj9necPwE0EFSzWwjOSeLuzxJc2PIjYBfwGM3V5bcIKq8dwHdoWRmn81uCSnoD8FoYR6qvAK8Ay4HtwL+Tvk38JMFFNq+F+/4jwXlFgGOAZyy4n3Qp8EV3X7OfuKQb6WZwyTrhZdyr3D3jlaSI9G6q5OSQZ2bHhF1IkfAS+4XAvft7n4hkP414ItlgGPB/BBeBVABXuPsLPRuSiPQG6q4UEZGspe5KERHJWkpyIiKStQ65c3KDBw/2sWPH9nQYIiLSizz33HNb3b2s9fJDLsmNHTuWFStW9HQYIiLSi5hZ6yHpAHVXiohIFlOSExGRrKUkJyIiWUtJTkREspaSnIiIZC0lORERyVpKciIikrWU5EREJGspyYmISNY65EY8ERHpFHdoaIC8PDALfpLicaitbZ5vaAh+Cgqgvh4iEUgkoLGxef1oNNhm65/GxuB3NBqsF48H700k0q8fj0NVFQwcmP71g/1pa79txZ5IBMcoGg2mk8cu9TMkpxsbIT+/5TaS60NwjFPXiUTajumww+CUUzL2z68kJ9JbtG4gtm+HmhoYMgR27gyW79wJmzcHjTAE6yUb1by85gbopZeCZePGweuvQ0UF1NXBxIlQVgZbtsDu3cFrY8YE28vLg9LSoHFPJoY1a4LXkw1hTU3ws307PPFE8HvYMJgxA2Kx5gRQUxNMm8Hevc2fLfn6jh3Qr1/QyEPQCO7dG8QYjQbTeXnB64WFwbaTDXFSMlnV1zcnmJqaYFvV1cF88pikvi+1cY7HM/tvKvt37rlKciLdIvXZihs3Bo3re+8FDXlxMWzYEDSKDzwAw4cH65WUwC23wNq1QaJYuDBIItXV8Ic/wAc/GDToxcXw17/CyJFBIw7Qv3+QtBoagoZ627Zu/8gdEo02/4VfVBQkiU2bml/ftAkefzxILiNGNB/HkpIguezdG0zn5wfbaWgIjkdjY3CsktVSaWmQ1IYMCbaRnx+8Fok0J6bGxmC91MrBvbnyys8Ppquqgn307RvEHY3CunXQp0+wLFnRmQXL8vKCf4u8PHj7bZgwoTn+aDT4LjQ0BNtPfW/qT7JSTCSCmKPR5vhT10vOJxKwdWvweWKxtrd7oD+t99vWTzze/DtZzSU/Z/LfP7m9SHiGa+/eIOZYrHlZcv3ktiD498rLC/6N2oqppCSjX99D7qGps2fPdg3QLEBzRbB5c/CfqrER1q8PGri33goS1IgRQcVSXBwknrVr4U9/ynxsZs0NcTJB1NUF8xMmBI3DsGFB0njvvaDC2rULKiuDWB9/vHlbffoEyXPoUPjnP4MGZvt2mDcv2Mb48cF7BgwIGmMIPv/o0UFSffvt4D2lpUECKSkJ4ikpCRr2ESOal0UiQZIwC+br64NY00k2XMnfIj3IzJ5z99mtl6uSk96htjZo4P/ylyARxWKwahU8+GCQpCBIBOPHw/33d/3+x48PuuY+9KGgcb//fjjuuCCJ7twJn/50kCSTlcGcOUHjXloaxLdzZ9A1OHZsUJ0kz2u0PgfUXU4/vXl6zpwD305bCQ5a/uXeC7nHMYse0HsTiUYikZbNo7tjZjQ2VhGN9sG9gZ07HyUeryIa7UtJyVTy88uIx/dSXf06iUQtdXXriUZLyMsbSF3du9TWrgMi5OcPZtCgs6irq2Dr1nsoLBxDnz5TMYuRl9ef6urXqKl5i1hsOO4JEom97NjxCPn5A+nb91ji8Wqqql6gqOgIioomEI/vYfv2+ygsHEd+fhk1NW9SX78Z93ry88twjxOJFBGJFFJUdARmUQoLx9DQsJWtW5eybduficVG0K/fiRQWjgWgoWEz0Wg/Skqm09i4k/z8QTQ0bCWRqKG2di35+UMoKBhBbe1aEokaotF+RKN92LPnWerrNxGLDaehYSt5eQOIRksBiERi1NdvpqjocMzyicWGMXLk54hECg7mn7pdquSk6yW/U4lEcO5n6VL4/e+DJLJjR1BVpBo6NKjGOqKwsOWFAqmmT4cPfCCYjkSCKqe8PHjPmDEwaFBQpdTWBhVUL5f8v2kZTiLJxjudRKKRRKKWaLTPPrEkEg1s376M2tr1DBp0VtgoDyUvbyB7975CXd27xON7KSw8jMGDP8yWLXexffsD1NdvZMSIyykuPor6+k0UFo4BIuzY8SB7975OPL6bhobt1NWtp7T0GKLREvr3n8fOnQ+zc+fjDB/+WYqKxlNQMJJ1677Pli13Eo32JR7fTUHBaCKRAmpqVjfFWVIyi4KCkdTWrmPv3peAKKWlszHLo6BgJKNGXU1t7TrWr/8h8XgVNTVvYZaHewP5+UPJy+tHNFpCVdWL5OcPpqFhC5FIIe6NuDemOWoGZKpdjQDJ84tRoK1zilFisWHk5w+grm4DkUgh9fUb028xUkwiUd1qacc/g1kekUgh8XhVyrIY7g0UFh4GRHGvo6FhOwCx2DDq6zeSSNQAMHDg6UybtqxD+2o/jvSVXEaTnJnNB35C8K/xK3e/qdXrhwG3A2XAduDj7l7R3jaV5HqJeDyotN58E373O3joIdiz58C2tWABPPJI8/uLioLuuZNOCrrRJk0Kut6GDGk+n9VBdXUbqaj4MYlEDePH/6Cpse4ue/a8SHHxhH32W1+/FTMjGu1HZeUfKS2dTXHxEdTWVlBf/x6JRB2bNt3O1q1/ZuzYb1NSUs62bX+hT59p9OlzFKWls6iqeoni4klUV7/J1q33smfPCmpr11BUNAH3BKWlM+jf//1s2/YXtm69l5qaNxk48EwGDDiV/PzBbN9+P1u2/L4pppKSGZSUlFNV9TKRSIy6ug3U1a3f5zMVFo6nvn5Tmoax5xQXT6K2dh2x2FAgaLij0WL27DmwtiIvrz+NjTspLDwccGpr1xCJFFFSMpO+feeEn7+OWGxoU2VVV7eeqqrnKS4+ipKScvLyBoYxvEAiUcugQWeGVVQee/e+zNq1N1JT8yZjxlxHXl4pe/Y8Tyw2jHi8ikSimiFDFlFdvQr3OLHYkDAx57Nnz3OYRSkpmU5t7Tqqq9+gqOgICgtHU1dXQU3NO/TvfwrRaMs/5OrrK8nL609d3btUVb1Cff0m+vY9huLiSZjlYRYDErg3YhYjHt/N3r2vYRYhL28A8Xg1sVgZdXUbKCqaCDjx+G7y84cSjRbiHqeu7j2i0T5EoyVEIi17AeLxasCIRoua/oDbseNvmMUYMGDeAf07per2JGdBP8GbwAeACmA5sMjdX0tZ5w/AX9z9f8zs/cCn3f0T7W1XSS7D3IPzMKtWBb+feQZ+9CN4993my6g744wz4Kmngi6zyZOD80hHHhlcWTd0aIuurj17nqOkZDpmUdydDRtuYfDgfwn/GoRdu57EPU5R0Xh27nyCjRt/yc6dD9OnzzSmTbuPaLSUvLzSlI/iPPnkMBoatjQtC5LCKkpL59K377GUlZ2NWYzKyrvZsuVO8vOHMmnS7WzY8DMaG3czfPhnqKurYPDgjxCNFjUlK/c4iUQDdXXraGjYSkPDVrZtu48hQy6gsXEna9Z8FbN8qqtfB6CgYBR1dRXk5Q0iP38QNTVvAhCJFDX9RVtYOJ7a2jWdP8Ypgr+SN+1/xVby8gaRSFQ3xZK6fMiQ89m9+ymqql4AoH//U4nHdzUlkPHj/52NG2+jqOiIsPLqQ58+U8nLKyUer2bz5juorLyLMWO+yahR12AW4dVXP8Leva9w2GHXsX37/RQUjAoruy0MGnQ6RUVHhsfOiUZLqal5m6KiccRiw9i58wkikQLq6irIzx/EkCGL2q1EzYxEoo7du5+ipGRm2Bivp7j4SN5668owAS2gb9+5YSWYj3ucxsZd5OcPxD1Bff1mCgqGd/q4SvfpiSR3HHCDu38onP8GgLv/IGWdlcB8d19vwbd0l7v3bW+7SnJdaNeu4BLyX/4SnnsuuOy8I44/PugKPO644CKPoUODc1k7d8K0acGFFkA8XsOePc/S0LCDPn2mUFw8gfr6ShKJOvLzB7B27Xd4773FxOO7GDjwdLZvvw+AuXNX884732LLljsBmDlzOevX30xl5V0d/miDBp3Ftm1/AaB///czePBHWL368504OOkddti3gAjr1n3noLeVnz+U4uIJxOM1VFU9B+zbdTR9+hOsX/9D3BsYMeIK3n77q9TUvNH0el7eIEpLZzNgwPsZOPBD9OlzNPX1lcTju9m69V4qK//EsGEXUVZ2HvF4FbW1a9m791V27XqCSCTGhAm3Eo0WYRalsXE3O3b8nX79jic/f8g+iaOu7r2w667z1XB757hEukJPJLlzCRLYZ8P5TwBz3f2qlHV+Dzzj7j8xs7OBPwGD3b3Na6mV5Dohecn1Cy/AG2/AbbfBY491/P1nnRUksmHD4Mwzmy73rq2toLLyLgYPPoe8vH7U1LzJSy99iFhsGJMm3U5+/hBefnk+tbVvN20qGi3hiCN+wurV1xCP7z6gj9OnTzn5+YPC6q2csrJzycsrZc2a60gk9qZ9z6BBCzn66D81XYAQj9fgXs/GjbdRWfl/NDRsoabmLYqLpzBkyAUMHvxh3nnnOoqLjyIvrz/vvPON/cYVifRhwIBTaWioZPfupygsHEtx8RT27n2ZY455lfr6zbz33q2MG/c93n33P8jPH8iIEZe1ONkej1c3zSdjbSsJNDTsIJGoo6BgWKePoUi26q1JbgTwM2Ac8DhwDnC0u+9sta1LgUsBxowZM2vdunUZifmQ5x5c6XfllXDHHR17z9FHwxe/CCecEFRk/fvjZrg34N7Q9Fd7Xd0m8vMHYBbj5Zc/yI4dDzVtoqRkJlVVz3c63KFDP8WRRy5m7dob2bDhp0yc+AtWrfpU08n8o4++l7q6Dbz11pUMHfopjjrqN2m3k0g0kEhU4+7s2vUEiUQ1r712AVOn/pVBg87odFwtt11HIlFPXl4pa9d+j7VrvwXAiBGfY+zYbxONlhCNFh/UPkTk4PXK7spW65cAq9x9VHvbVSXXymOPBTcj/+EP+1/3pJPge9/DZ81g85572bbtz4wadQ1FRROIxQbjnqC2dh3PPDO+6S15eYNobNz/TcrDh1/G4MEf5pVXTm963+TJdzJgwGm4N/D440GVMmHCz+nff154snvfKsXd2bv3VRoattC///sxMxoadhCNlu7T3dWeRKIuI5cl79jxMDt3PsLYsTeqq02kF+mJJJdHcOHJqcAGggtPLnT3lSnrDAa2u3vCzL4PxN39+va2m/NJrrISrr8efvGLfV5K5EHNCKg6AmJ1fYhMnsreL59LXWwX9fUbqa19l927nyEe39XifSUlM5k48eesXn0Nu3c/1bR82LBPs2nTr/fZT79+JzNp0u288soCqquD64imTv0LgwadSSJRR2PjbmKxshbv2bPnOerrKxk0aH5XHAURkRa6/WZwd280s6uABwhuIbjd3Vea2Y3ACndfCswDfmBmTtBdeWWm4jlkvfwyvPoqjd/+ClRsJFIPlfOg9kKoK4PYDthxUh/iY8uoLdxNY+P28I17gadh49NpNxvcd/QoAFVVz/P888c2vTZ8+Gc58shfhnNGXl4/xo+/ierqVaxc+VEmTvw5RUWHM2fOSl599Ry2bv0/+vU7EYBIpGCfBAdQWjqra46HiEgn6GbwDkgk6li58qPU17/HwIFnMHTox6ir28CmTbdTVnY+AwfOJx6vIj+/P/F4LdFoIfX1m4lGS8LzOf0w68RTjdzh1lvhyiupGQav3ATVh+27mhHDqScWG05x8SSi0T7063cSffpMIxLJp7FxF5FIIcXFk9i79xXefvsr1NSsZsqUP1FWdjZbttxFPF7FG298FoDCwsOZO/fNTsXa0LCdhoZtFBdP6PjnExHpYj1yM3gm9ESSW7nyPCor/3hQ2zjppL289NIHGD/+3+nf/8R9V2hoCG6o/trX4NVXAYjH4J/3QqIICqpLKSg+jPxB4xg06EyGDv04ZgU0Nm4nFhvSoRjc4+H9RhOazie5x1m+fBr5+QMpL3+kU+e9RER6C41d2QF7977GunXfZceOv9O//ylMnnw3VVXPU1n5R0pKZnDkkbexY8eDbN/+NwoLDyMWG8K77960/w0DTzwRXKX45puXc8wxrwCONcbh2Wfh2mtpfOEfVJwDo96Bt6+BaH2E/LkfIFH0AEOHfIxJR/0u7YUOHU1wEFyaXlw8cZ9ls2e/gFm+LqQQkayjSi5UU7OW5csnh0P1DKG+fhPDhn2GnTsfJh6vZtasZ5pG3ki1efMdFBQcxt69r/LWW1dgFuPYY9eye/eTrFx5btp9leWfRmXDQwz6Jxz1A8jbC6s/BxXnpY/thBO2kp8/qCs/rohIVlEltx/bti0lkahh1qwXKCmZxssvn86mTbdhls+0aQ+mTXAAQ4d+DID+/U+kb99jicWGUlAwnLKyc9rcV2VDcI/ZthPgH3+Bo78Jmy8sg4bKpnX69TuZXbseZ/jwy5TgREQOUE4mubq6jdTWvkO/fsc3LauqepFYbBilpdMBOPzw/2TTptvD0dIntrWpFpLvTRo//oesWfPV/b7v1X8DGioZM+ZaSkqmM3DgmeTllVBdvTocoV1ERA5EJy75yx7PPHMEL7xwQotlDQ3byM9vPr9VUnI0RxzxXx1OcOkUvVnVYn7mZc3TJSWzGD++5fm88eN/wJAh55OXFzwpt7j4iH1G8hYRkY7LySSX7hEhQZIb2HU7+fKXiXyzeRDfwveg788ebJqfNOk2Ro36MmVl5wPQp8+0rtu3iIgAOdpdmU4isZf8/NEHv6H164MHdAKRmSnLx42F4z4AjwazJSXlAEyZsoT6+p/t8+wnERE5eDlZyaUTj+8lEjmIgXZffBF+8IOmBAfAuMObJr3pab77isUGd/vDPEVEcoEquVA8Xn3giebII4MnZCeddhosW4btfQZePClceGjdqiEikg2U5EKJRPWBPTLl619vmeDeeQfGjgUgGKM6SUlORKS7KcmFgu7KTlRylZUwpNVoI9u2wcDmi1daJjmNJiIi0t10Tg5IJBpxr+94Jbd4ccsEV1QEjz7aIsFB8xOeRUSkZ6iSo/mWgg6dk3vjDbgs5Ya36uogyaWRrpI77LDr2bv3lQMNVUREOkFJjuCiE2D/V1decgn86lfN83/7W5sJDtInuXHjvpN+ZRER6XJKcjRXcpFIO/eqbdrUMsE98wzMmdPudlOTnEb4FxHpfjonR/BQVIBIpDD9Ck8/DcOHN8+vW7ffBAe68EREpKcpyZGa5Ar2fTEeh+OOa57/znda3vDdDl14IiLSs3K6u9LdMTPck0kuzWDIJSXN09u3w4ABHd6+WX7q3AFGKSIiByrHK7ngBu1kJWfWqpJbtw5qa4PpFSs6leAACgqGM3bsjeGckpyISHdTkgMSiXqgVXflkiVNI5cwYgTMmnVAeygtDUZp1oUnIiLdL6eTnLuHv1udk3OHRYuaV9yw4SD2EhzilhehiIhId8hokjOz+Wb2hpmtNrNr07w+xsweMbMXzOxlMzsjk/HsK3gywD4Xnixd2rzKs88e1B6SF5+Y6eGnIiLdLWNJzoLW/RbgdGAysMjMJrda7V+Bu919BnAB8PNMxZNeG+fkvvSl4PeJJ8IxxxzkPoJDrCd8i4h0v0xWcnOA1e6+xt3rgSXAwlbrONA3nO4HvJfBePaR7K5sUcm99RasWROs8OCDbb21w1TJiYj0nEyeKBoJrE+ZrwDmtlrnBuBBM/s80Ac4LYPxpBF0V7Y4JzdxfPDSuHHtDtnVcUEibXk7gYiIdIeevvBkEfAbdx8FnAH8zsz2icnMLjWzFWa2orKysgt336qSa0h56S9/6ZI9JBLBLQhtjqYiIiIZk8kktwEYnTI/KlyW6jPA3QDu/hRQCAxuvSF3X+zus919dllZWZcF2Lq70h55InjhwgthcuvThwemsXEXAHl5/bpkeyIi0nGZTHLLgQlmNs6CE1IXAEtbrfMucCqAmR1FkOS6slTbj2R3ZXif3AMPB4tvvrnL9uDeCEAsNqzLtikiIh2TsXNy7t5oZlcBDwBR4HZ3X2lmNwIr3H0p8GXgl2Z2DUHf4UWeLK+6RatK7pbFcOaZLQdjPkhDhlxATc1qRo/+apdtU0REOiajdyi7+zJgWatl16dMvwackMkY2pPaXWnxKEYcLr+8S/cRieTrGXIiIj2kpy886WFhkttSQaQmDmecAWed1cMxiYhIV8nxJBeek3v5OSKNwH/+Z8+GIyIiXSqnk1xTd+XubcE9cpMm9XBEIiLSlXI6yTV1V9bs3vcxOyIicsjLySQ3btz3w6kEbN+Ox+uxfN2sLSKSbXIyyeXlBQ8/dfdgrEoDy1clJyKSbXIyyTWPHBYkOY+AFaiSExHJNjmZ5CD5lO5EUMlFgJiSnIhItsnpJOfu8MwzeN9SLBLt4ZhERKSr5XSSI94A//wnDB5Izh4KEZEslpMtu1mY5NZXQFUV3r8fzV2YIiKSLTI6dmWvt6Ei+F1UiFk3jgstIiLdIicruSYVwYPLvaiQXD8UIiLZKEdb9rBr8oUXoX9/KIyR5oHkIiJyiMvtlv299+Dww3GcXD8UIlHDC6YAACAASURBVCLZKLdb9sot4QNSE6rkRESyUI627GF35euvQySCe4KcPRQiIllMLXt+PqrkRESyU0637A7w8Y+HlZzukxMRyTY5muRSElpBAeCq5EREspBa9sJCQOfkRESyUW637AYUFOCuc3IiItkooy27mc03szfMbLWZXZvm9R+Z2Yvhz5tmtjOT8aTst3mmoABVciIi2SljY1eaWRS4BfgAUAEsN7Ol7v5ach13vyZl/c8DMzIVT5sKCvBaVXIiItkoky37HGC1u69x93pgCbCwnfUXAXdmMJ59hd2VquRERLJTJlv2kcD6lPmKcNk+zOwwYBzwcAbjSd1j82Rhoc7JiYhkqd7Ssl8A/NHd4+leNLNLzWyFma2orKzs2j03VXK6T05EJNtkMsltAEanzI8Kl6VzAe10Vbr7Ynef7e6zy8rKui7ClKsre0++FxGRrpLJln05MMHMxplZjCCRLW29kplNAgYAT2UwltZ7bZ7UzeAiIlkrYy27uzcCVwEPAK8Dd7v7SjO70cwWpKx6AbDE3Xvm0dyxmCo5EZEslbFbCADcfRmwrNWy61vN35DJGNrjsXyIRNAAzSIi2SlHW/awuzIWA1AlJyKSpXK7ZQ+TnCo5EZHslNstuyo5EZGsltste4EqORGRbJaTLXvTAM0tKjndDC4ikm1yMsk1aTonp/vkRESyUW637Cndlbl+KEREslGOtuz7dleqkhMRyT653bLHCsIJVXIiItkot1v2AlVyIiLZLEdb9pbdlarkRESyU2637LF8QJWciEi2yumW3VtUcrpPTkQk2+RokgsTWkFw4YmG9RIRyU653bLrZnARkayW2y17yjm5XD8UIiLZKCdbdks+hFyP2hERyWq52bI3NAS/YzonJyKSzXKzZW9KcvnhAlVyIiLZKDdb9sZ48DsWw90BJ1cPhYhINsvNlr2pkosRJDhUyYmIZKHcbNkbm7srg/NxoJvBRUSyT24muYbG4HdBAarkRESyV0ZbdjObb2ZvmNlqM7u2jXU+amavmdlKM/t9JuNp0uLCk2QlpyQnIpJt8jK1YTOLArcAHwAqgOVmttTdX0tZZwLwDeAEd99hZkMyFU8LYSXn+c3dlarkRESyTyZb9jnAandf4+71wBJgYat1LgFucfcdAO6+JYPxNEt2V8ZiqJITEclemWzZRwLrU+YrwmWpJgITzeyfZva0mc1PtyEzu9TMVpjZisrKyoOPrKE++B2LqZITEcliPd2y5wETgHnAIuCXZta/9UruvtjdZ7v77LKysoPfa9OFJ6rkRESyWSZb9g3A6JT5UeGyVBXAUndvcPd3gDcJkl5GWWOY5PJVyYmIZLNMtuzLgQlmNs7MYsAFwNJW69xLUMVhZoMJui/XZDCmQNqrK3WfnIhItslYknP3RuAq4AHgdeBud19pZjea2YJwtQeAbWb2GvAI8FV335apmJqkjHjiyScSqLtSRCTrZOwWAgB3XwYsa7Xs+pRpB74U/nSfFsN6qbtSRCRb5WbLnnILQfOwXrl5KEREsllutuxpzsmpkhMRyT652bInk1w0qkpORCSL5WbLnuyuBFTJiYhkr9xs2ZOP2gFVciIiWSw3W/Z48GTw4OJOVXIiItkqN1v2eKJpUg9NFRHJXrmZ5BpTz8npoakiItkqN1v2RLJ6a+6uzNVDISKSzXKyZbfGeNO0BmgWEcle7Q7rZWZnt1rkwFbgRXffk7GoMi2RSJ0JfyvJiYhkm/2NXfkvaZYNBKaZ2Wfc/eEMxJR58WQl56rkRESyWLtJzt0/nW65mR0G3A3MzURQGZfSXalKTkQkex1Qy+7u64D8Lo6l+8R1Tk5EJBcc0KN2zOxIoK6LY+k+Kd2VyVsIdJ+ciEj22d+FJ3+mOQskDQSGAx/PVFAZ16KS00NTRUSy1f4quZtbzTuwDXjL3eszE1I3iO97daW6K0VEss/+Ljx5LDltZkOBY4C+QCWwJbOhZVA8GPHE3TVAs4hIFutQy25mHwWeBc4DPgo8Y2bnZjKwjGpUJScikgs6euHJdcAx7r4FwMzKgIeAP2YqsIxK7Ht1pSo5EZHs09GWPZJMcKFtnXhv79Pi6kpVciIi2aqjldz9ZvYAcGc4fz6wLDMhZV66sSsP5ZwtIiLpdahld/evAouBaeHPYnf/+v7eZ2bzzewNM1ttZtemef0iM6s0sxfDn8929gMckPi+I56Y6T45EZFs0+Gbwd39T8CfOrq+mUWBW4APABXAcjNb6u6vtVr1Lne/qqPb7RJpRjxRJScikn32dzP4Hva9GRyC4UHc3fu28/Y5wGp3XxNuawmwEGid5LpfmhFPdE5ORCT77O8+udKD2PZIYH3KfAXpB3Q+x8xOBt4ErnH39WnW6VppuitVyYmIZJ+ebtn/DIx192nA34D/SbeSmV1qZivMbEVlZeXB73XsuKZJDdAsIpK9MtmybwBGp8yPCpc1cfdt7p4c6PlXwKx0G3L3xe4+291nl5WVHXxk//ZvyS2jSk5EJHtlsmVfDkwws3FmFgMuAJamrmBmw1NmFwCvZzCe1D03TamSExHJXgf0qJ2OcPdGM7sKeACIAre7+0ozuxFY4e5LgS+Y2QKgEdgOXJSpeNqmSk5EJFtlLMkBuPsyWt007u7Xp0x/A/hGJmNoT+oAzarkRESyT4627Kk3fifSLBMRkWyQo0mumR6aKiKSvXK8ZdcAzSIi2SwnW/bUcSo1rJeISPZSy65KTkQka+V4y+6q5EREsliOtuz7Xl2pR+2IiGSfHE1yzdyTgzVHezQOERHpejme5LwpyZll9L54ERHpATma5FKvrmwMlpgqORGRbJOjSS6VKjkRkWyV00kuGLtSlZyISLbK0SSX2l2pSk5EJFvlaJJrpkpORCR75XiS09WVIiLZLCeTXMuxKxvDKVVyIiLZJieTXKrmSk5JTkQk2yjJeSMQ0bBeIiJZKMeTnANxnY8TEclSOZrkWp6TU1eliEh2ytEk18xdlZyISLbK8STnquRERLJYRpOcmc03szfMbLWZXdvOeueYmZvZ7EzGk7LHpilVciIi2StjSc6C8ugW4HRgMrDIzCanWa8U+CLwTKZiaU9wdaUqORGRbJTJSm4OsNrd17h7PbAEWJhmve8C/w7UZjCWtIIBmlXJiYhkq0wmuZHA+pT5inBZEzObCYx2979mMI40dHWliEgu6LELT8wsAvwX8OUOrHupma0wsxWVlZVdHIkqORGRbJXJJLcBGJ0yPypcllQKHA08amZrgWOBpekuPnH3xe4+291nl5WVdWGIurpSRCSbZTLJLQcmmNk4M4sBFwBLky+6+y53H+zuY919LPA0sMDdV2QwJqD1AM2q5EREslXGkpwHly1eBTwAvA7c7e4rzexGM1uQqf12lio5EZHsldESxt2XActaLbu+jXXnZTKW9JLPk1OSExHJRjk64knrqyvVXSkiko1yNMk1C87JqZITEclGOZ7kXJWciEgWy9Ekl/qAVFVyIiLZKkeTXDPdQiAikr1yOskFY1fqFgIRkWyVo0lON4OLiOSCHE1yzfSoHRGR7JXjSU6P2hERyWY5meRajl2pc3IiItkqJ5NcS6rkRESyVY4nOV1dKSKSzXI0yenqShGRXJCjSa6ZKjkRkeylJKdKTkQka+V4knPdJyciksVyNMnpnJyISC7I0STXTOfkRESyV04nOXdH98mJiGSvHE1yGvFERCQX5GiSa6ZzciIi2SvHk5xGPBERyWYZTXJmNt/M3jCz1WZ2bZrXLzezV8zsRTP7h5lNzmQ8KfsNpxKAq5ITEclSGUtyFpRHtwCnA5OBRWmS2O/dfaq7Twf+A/ivTMWTjns8nFIlJyKSjTJZyc0BVrv7GnevB5YAC1NXcPfdKbN9AM9gPPsIbgRHlZyISJbKZOs+ElifMl8BzG29kpldCXwJiAHvz2A8qXsFUpOcKjkRkWzU4xeeuPst7n448HXgX9OtY2aXmtkKM1tRWVnZBXtNJrmGcPuq5EREslEmk9wGYHTK/KhwWVuWAB9O94K7L3b32e4+u6ysrAtCUyUnIpILMpnklgMTzGycmcWAC4ClqSuY2YSU2TOBtzIYT+p+AUgkkpWckpyISDbKWD+duzea2VXAAwSXL97u7ivN7EZghbsvBa4ys9OABmAH8KlMxdNS60pO3ZUiItkoo627uy8DlrVadn3K9Bczuf+2RcL9N4TzquRERLJRj1940hOS3ZW68EREJLvlZJLb9+pKVXIiItkox5OczsmJiGQzJTlUyYmIZKucTHL73kKgSk5EJBvlZJJTJScikhtyPMmpkhMRyWY5nuQaw3lVciIi2Sgnk5zukxMRyQ05meR0Tk5EJDfkeJJTJSciks1yPMmpkhMRyWY5meR0n5yISG7IySSnSk5EJDfkeJJTJSciks1yMsmZ6XlyIiK5ICeTnCo5EZHckONJTufkRESyWU4nOV1dKSKS3XIyyTUP66VKTkQkm+VkktM5ORGR3JCjrbsqOZHerqGhgYqKCmpra3s6FOlFCgsLGTVqFPn5+R1aP8eTnCo5kd6qoqKC0tJSxo4d23SKQXKbu7Nt2zYqKioYN25ch96T0e5KM5tvZm+Y2WozuzbN618ys9fM7GUz+7uZHZbJeFL2CyjJifRmtbW1DBo0SAlOmpgZgwYN6lR1n7EkZ0Ef4C3A6cBkYJGZTW612gvAbHefBvwR+I9MxdMqOgASidow1oLu2a2IdIoSnLTW2e9EJiu5OcBqd1/j7vXAEmBh6gru/oi7V4ezTwOjMhhPipZJLhKJdc9uReSQsW3bNqZPn8706dMZNmwYI0eObJqvr69v970rVqzgC1/4wn73cfzxx3dVuABcffXVjBw5kkQi0aXbPZRlsp9uJLA+Zb4CmNvO+p8B7kv3gpldClwKMGbMmC4IrTnJmeU1DfMlIpI0aNAgXnzxRQBuuOEGSkpK+MpXvtL0emNjI3l56ZvQ2bNnM3v27P3u48knn+yaYIFEIsE999zD6NGjeeyxx3jf+97XZdtO1d7n7o16RetuZh8HZgM/TPe6uy9299nuPrusrKwr9gckk5y6KkWkYy666CIuv/xy5s6dy9e+9jWeffZZjjvuOGbMmMHxxx/PG2+8AcCjjz7KWWedBQQJ8uKLL2bevHmMHz+en/70p03bKykpaVp/3rx5nHvuuUyaNImPfexjuDsAy5YtY9KkScyaNYsvfOELTdtt7dFHH2XKlClcccUV3HnnnU3LN2/ezEc+8hHKy8spLy9vSqy//e1vmTZtGuXl5XziE59o+nx//OMf08Z30kknsWDBAiZPDs46ffjDH2bWrFlMmTKFxYsXN73n/vvvZ+bMmZSXl3PqqaeSSCSYMGEClZWVQJCMjzjiiKb5TMtkOt4AjE6ZHxUua8HMTgOuA05x97oMxpO6VyC4hSAa7ds9uxSRA3f11RBWVV1m+nT48Y87/baKigqefPJJotEou3fv5oknniAvL4+HHnqIb37zm/zpT3/a5z2rVq3ikUceYc+ePRx55JFcccUV+1wC/8ILL7By5UpGjBjBCSecwD//+U9mz57NZZddxuOPP864ceNYtGhRm3HdeeedLFq0iIULF/LNb36ThoYG8vPz+cIXvsApp5zCPffcQzwep6qqipUrV/K9732PJ598ksGDB7N9+/b9fu7nn3+eV199temqxttvv52BAwdSU1PDMcccwznnnEMikeCSSy5pinf79u1EIhE+/vGPc8cdd3D11Vfz0EMPUV5eTlcULB2RyUpuOTDBzMaZWQy4AFiauoKZzQD+G1jg7lsyGEsrzScuIxFVciLSceeddx7RaHBv7a5duzjvvPM4+uijueaaa1i5cmXa95x55pkUFBQwePBghgwZwubNm/dZZ86cOYwaNYpIJML06dNZu3Ytq1atYvz48U2Jpa0kV19fz7Jly/jwhz9M3759mTt3Lg888AAADz/8MFdccQUA0WiUfv368fDDD3PeeecxePBgAAYOHLjfzz1nzpwWl+3/9Kc/pby8nGOPPZb169fz1ltv8fTTT3PyySc3rZfc7sUXX8xvf/tbIEiOn/70p/e7v66SsUrO3RvN7CrgAYJn2dzu7ivN7EZghbsvJeieLAH+EHYhvuvuCzIVU1LqOTglOZFDwAFUXJnSp0+fpulvfetbvO997+Oee+5h7dq1zJs3L+17Cgqa25loNEpjY+MBrdOWBx54gJ07dzJ16lQAqqurKSoqarNrsy15eXlNF60kEokWF9ikfu5HH32Uhx56iKeeeori4mLmzZvX7mX9o0ePZujQoTz88MM8++yz3HHHHZ2K62Bk9Jycuy9z94nufri7fz9cdn2Y4HD309x9qLtPD38ynuACzZWczsmJyIHatWsXI0eOBOA3v/lNl2//yCOPZM2aNaxduxaAu+66K+16d955J7/61a9Yu3Yta9eu5Z133uFvf/sb1dXVnHrqqdx6660AxONxdu3axfvf/37+8Ic/sG3bNoCm7sqxY8fy3HPPAbB06VIaGhrS7m/Xrl0MGDCA4uJiVq1axdNPPw3Asccey+OPP84777zTYrsAn/3sZ/n4xz/eohLuDr3iwpPup+5KETl4X/va1/jGN77BjBkzOlV5dVRRURE///nPmT9/PrNmzaK0tJR+/fq1WKe6upr777+fM888s2lZnz59OPHEE/nzn//MT37yEx555BGmTp3KrFmzeO2115gyZQrXXXcdp5xyCuXl5XzpS18C4JJLLuGxxx6jvLycp556qkX1lmr+/Pk0NjZy1FFHce2113LssccCUFZWxuLFizn77LMpLy/n/PPPb3rPggULqKqq6tauSgBLXsFzqJg9e7avWLHioLbR2FjFP/5RCkBp6THMmvVsV4QmIl3o9ddf56ijjurpMHpcVVUVJSUluDtXXnklEyZM4JprrunpsDptxYoVXHPNNTzxxBMHva103w0ze87d97lvIycrudQ75lXJiUhv9stf/pLp06czZcoUdu3axWWXXdbTIXXaTTfdxDnnnMMPfvCDbt93TlZy8Xg1TzwRlOH9+5/K9OkPdUVoItKFVMlJW1TJ7Vfq1ZWFPRiHiIhkUk4muUik+SbMvDzdDC4ikq1yMskFD0gIzstpxBMRkeyVk0kOIBiERZWciEg2y9kkl6RKTkTSed/73tc0NFbSj3/846YhstKZN28eyQvjzjjjDHbu3LnPOjfccAM333xzu/u+9957ee2115rmr7/+eh56qOsukMulR/LkbJJLjgWtSk5E0lm0aBFLlixpsWzJkiXtDpKcatmyZfTv3/+A9t06yd14442cdtppB7St1lo/kidTMnFz/IHI2SSXpEpORNI599xz+etf/9o0fuPatWt57733OOmkk7jiiiuYPXs2U6ZM4dvf/nba948dO5atW7cC8P3vf5+JEydy4oknNj2OB4J74I455hjKy8s555xzqK6u5sknn2Tp0qV89atfZfr06bz99tstHoHz97//nRkzZjB16lQuvvhi6urqmvb37W9/m5kzZzJ16lRWrVqVNq5ceyTPofPkuwyJxbrncQ8icuDeeutqqqq69lE7JSXTmTCh7YGfBw4cyJw5c7jvvvtYuHAhS5Ys4aMf/Shmxve//30GDhxIPB7n1FNP5eWXX2batGlpt/Pcc8+xZMkSXnzxRRobG5k5cyazZs0C4Oyzz+aSSy4B4F//9V+57bbb+PznP8+CBQs466yzOPfcc1tsq7a2losuuoi///3vTJw4kU9+8pPceuutXH311QAMHjyY559/np///OfcfPPN/OpXv9onnlx7JE/OV3Kx2IieDkFEeqnULsvUrsq7776bmTNnMmPGDFauXNmia7G1J554go985CMUFxfTt29fFixoHof+1Vdf5aSTTmLq1KnccccdbT6qJ+mNN95g3LhxTJw4EYBPfepTPP74402vn3322QDMmjWraVDnVLn4SB5VcrHhPR2CiOxHexVXJi1cuJBrrrmG559/nurqambNmsU777zDzTffzPLlyxkwYAAXXXRRu4+Zac9FF13EvffeS3l5Ob/5zW949NFHDyre5ON62npUTy4+kidnK7lBg4K/ptRdKSJtKSkp4X3vex8XX3xxUxW3e/du+vTpQ79+/di8eTP33Xdfu9s4+eSTuffee6mpqWHPnj38+c9/bnptz549DB8+nIaGhhYNemlpKXv27NlnW0ceeSRr165l9erVAPzud7/jlFNO6fDnycVH8uRskps8eQnHHbcxvDFcRCS9RYsW8dJLLzUlufLycmbMmMGkSZO48MILOeGEE9p9/8yZMzn//PMpLy/n9NNP55hjjml67bvf/S5z587lhBNOYNKkSU3LL7jgAn74wx8yY8YM3n777ablhYWF/PrXv+a8885j6tSpRCIRLr/88g59jlx9JE9ODtAsIr2fBmjOTR15JE9nBmjO+XNyIiLSO9x0003ceuutXXIuLilnuytFRKR3ufbaa1m3bh0nnnhil21TSU5ERLKWkpyI9FqH2jUDknmd/U4oyYlIr1RYWMi2bduU6KSJu7Nt2zYKCzv+sOuMXnhiZvOBnwBR4FfuflOr108GfgxMAy5w9z/uuxURyUWjRo2ioqLioMculOxSWFjIqFGjOrx+xpKcBTeg3QJ8AKgAlpvZUndPHf/mXeAi4CuZikNEDk35+fkthocSORCZrOTmAKvdfQ2AmS0BFgJNSc7d14avZf9DjUREpNtl8pzcSGB9ynxFuExERKRbHBIXnpjZpWa2wsxWqH9eREQ6KpPdlRuA0Snzo8Jlnebui4HFAGZWaWbrDj48BgNbu2A73UXxZt6hFvOhFi8cejEfavHCoRdzV8V7WLqFmUxyy4EJZjaOILldAFx4sBt19y55bICZrUg3zllvpXgz71CL+VCLFw69mA+1eOHQiznT8Wasu9LdG4GrgAeA14G73X2lmd1oZgsAzOwYM6sAzgP+28zaf2KgiIhIJ2T0Pjl3XwYsa7Xs+pTp5QTdmCIiIl3ukLjwJEMW93QAnaR4M+9Qi/lQixcOvZgPtXjh0Is5o/Eecs+TExER6ahcruRERCTL5VySM7P5ZvaGma02s2t7Oh4AMxttZo+Y2WtmttLMvhguv8HMNpjZi+HPGSnv+Ub4Gd4wsw/1UNxrzeyVMLYV4bKBZvY3M3sr/D0gXG5m9tMw5pfNbGY3x3pkynF80cx2m9nVve0Ym9ntZrbFzF5NWdbpY2pmnwrXf8vMPtXN8f7QzFaFMd1jZv3D5WPNrCblWP8i5T2zwu/S6vAzWTfH3OnvQXe1JW3Ee1dKrGvN7MVweY8f43bas575Hrt7zvwQDBT9NjAeiAEvAZN7QVzDgZnhdCnwJjAZuAH4Spr1J4exFwDjws8U7YG41wKDWy37D+DacPpa4N/D6TOA+wADjgWe6eHvwSaC+2p61TEGTgZmAq8e6DEFBgJrwt8DwukB3RjvB4G8cPrfU+Idm7peq+08G34GCz/T6d18jDv1PejOtiRdvK1e/0/g+t5yjNtpz3rke5xrlVzTeJruXg8kx9PsUe6+0d2fD6f3ENxy0d4QaAuBJe5e5+7vAKsJPltvsBD4n3D6f4APpyz/rQeeBvqb2fCeCBA4FXjb3dsbVKBHjrG7Pw5sTxNLZ47ph4C/uft2d98B/A2Y313xuvuDHtxCBPA0+7mCOoy5r7s/7UHr9luaP2OXa+MYt6Wt70G3tSXtxRtWYx8F7mxvG915jNtpz3rke5xrSa7Xj6dpZmOBGcAz4aKrwhL+9mR5T+/5HA48aGbPmdml4bKh7r4xnN4EDA2ne0vMEAxMkNoo9OZjDJ0/pr0p9osJ/kpPGmdmL5jZY2Z2UrhsJEGMST0Vb2e+B73lGJ8EbHb3t1KW9Zpj3Ko965Hvca4luV7NzEqAPwFXu/tu4FbgcGA6sJGgW6I3OdHdZwKnA1da8HzAJuFfjL3q8l0ziwELgD+Ei3r7MW6hNx7TtpjZdUAjcEe4aCMwxt1nAF8Cfm9mfXsqvlYOqe9BikW0/IOt1xzjNO1Zk+78Hudakuuy8TS7mpnlE3wh7nD3/wNw983uHnf3BPBLmrvLesXncPcN4e8twD0E8W1OdkOGv7eEq/eKmAkS8vPuvhl6/zEOdfaY9njsZnYRcBbwsbBBI+zy2xZOP0dwTmtiGFtql2a3x3sA34PecIzzgLOBu5LLessxTtee0UPf41xLck3jaYZ/0V8ALO3hmJL96rcBr7v7f6UsTz1n9REgeXXVUuACMyuwYGzQCQQnlbuNmfUxs9LkNMHFBq+GsSWvgvoU8P+lxPzJ8EqqY4FdKV0X3anFX769+Rin6OwxfQD4oJkNCLvdPhgu6xZmNh/4GrDA3atTlpdZ8DBlzGw8wTFdE8a828yODf8vfDLlM3ZXzJ39HvSGtuQ0YJW7N3VD9oZj3FZ7Rk99j7vqippD5YfgSp43Cf7Cua6n4wljOpGgdH8ZeDH8OQP4HfBKuHwpMDzlPdeFn+ENMnglWjsxjye4ouwlYGXyWAKDgL8DbwEPAQPD5UbwpPi3w880uwdi7gNsA/qlLOtVx5ggAW8EGgjOQXzmQI4pwbmw1eHPp7s53tUE51KS3+VfhOueE35XXgSeB/4lZTuzCRLL28DPCAeq6MaYO/096K62JF284fLfAJe3WrfHjzFtt2c98j3WiCciIpK1cq27UkREcoiSnIiIZC0lORERyVpKciIikrWU5EREJGspyYn0EDOLW8snI3TZSPYWjEb/6v7XFMlueT0dgEgOq3H36T0dhEg2UyUn0stY8Hyw/7Dg2V/PmtkR4fKxZvZwOIjw381sTLh8qAXPbXsp/Dk+3FTUzH5pwTO9HjSzonD9L1jwrK+XzWxJD31MkW6hJCfSc4padVeen/LaLnefSjAyxY/DZf8P+B93n0Yw6PFPw+U/oTdp7gAAAVFJREFUBR5z93KC546tDJdPAG5x9ynAToLRMCB4lteMcDuXZ+rDifQGGvFEpIeYWZW7l6RZvhZ4v7uvCQe63eTug8xsK8FwUw3h8o3uPtjMKoFR7l6Xso2xBM/imhDOfx3Id/fvmdn9QBVwL3Cvu1dl+KOK9BhVciK9k7cx3Rl1KdNxms/Bn0kwVuBMYHk4mr1IVlKSE+mdzk/5/VQ4/STBaPcAHwOeCKf/DlwBYGZRM+vX1kbNLAKMdvdHgK8D/YB9qkmRbKG/4ER6TpGZvZgyf7+7J28jGGBmLxNUY4vCZZ8Hfm1mXwUqgU+Hy78ILDazzxBUbFcQjFqfThT43zARGvBTd9/ZZZ9IpJfROTmRXiY8Jzfb3bf2dCwihzp1V4qISNZSJSciIllLlZyIiGQtJTkREclaSnIiIpK1lORERCRrKcmJiEjWUpITEZGs9f8DHvp54pqha8QAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model-unet.h5')"
      ],
      "metadata": {
        "id": "_yZl3gD1E7qj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "np.random.seed(0)\n",
        "\n",
        "# CLAHE\n",
        "def clahe_equalized(imgs):    \n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))    \n",
        "    imgs_equalized = clahe.apply(imgs)\n",
        "    return imgs_equalized\n",
        "\n",
        "patch_size = 512\n",
        "\n",
        "#loading model architectures\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "IMG_HEIGHT = patch_size\n",
        "IMG_WIDTH = patch_size\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = unetmodel(input_shape) #/residualunet(input_shape)/attentionunet(input_shape)/attention_residualunet(input_shape) \n",
        "model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "model.load_weights('/content/model-unet.h5') #loading weights\n",
        "\n",
        "\n",
        "path1 = '/content/drive/MyDrive/DRIVE/training/images'    #test dataset images directory path\n",
        "path2 = '/content/drive/MyDrive/DRIVE/training/1st_manual'     #test dataset mask directory path\n",
        "\n",
        "\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "\n",
        "testimg = []\n",
        "ground_truth = []\n",
        "prediction = []\n",
        "global_IoU = []\n",
        "global_accuracy = []\n",
        "\n",
        "testimages = sorted(os.listdir(path1))\n",
        "testmasks =  sorted(os.listdir(path2))\n",
        "\n",
        "for idx, image_name in enumerate(testimages):  \n",
        "   if image_name.endswith(\".jpg\"):  \n",
        "      predicted_patches = []\n",
        "      test_img = skimage.io.imread(path1+\"/\"+image_name)\n",
        "     \n",
        "      test = test_img[:,:,1] #selecting green channel\n",
        "      test = clahe_equalized(test) #applying CLAHE\n",
        "      SIZE_X = (test_img.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "      SIZE_Y = (test_img.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "      test = cv2.resize(test, (SIZE_X, SIZE_Y))\n",
        "      testimg.append(test)           \n",
        "      test = np.array(test)\n",
        "\n",
        "      patches = patchify(test, (patch_size, patch_size), step=patch_size) #create patches(patch_sizexpatch_sizex1)\n",
        "\n",
        "      for i in range(patches.shape[0]):\n",
        "                for j in range(patches.shape[1]):\n",
        "                  single_patch = patches[i,j,:,:]\n",
        "                  single_patch_norm = (single_patch.astype('float32')) / 255.\n",
        "                  single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
        "                  single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "                  single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8) #predict on single patch\n",
        "                  predicted_patches.append(single_patch_prediction)\n",
        "      predicted_patches = np.array(predicted_patches)\n",
        "      predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
        "      reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape) #join patches to form whole img\n",
        "      prediction.append(reconstructed_image) \n",
        "\n",
        "      groundtruth=[]\n",
        "      groundtruth = skimage.io.imread(path2+'/'+testmasks[idx]) #reading mask of the test img      \n",
        "      SIZE_X = (groundtruth.shape[1]//patch_size)*patch_size \n",
        "      SIZE_Y = (groundtruth.shape[0]//patch_size)*patch_size  \n",
        "      groundtruth = cv2.resize(groundtruth, (SIZE_X, SIZE_Y))  \n",
        "      ground_truth.append(groundtruth)\n",
        "\n",
        "      y_true = groundtruth\n",
        "      y_pred = reconstructed_image\n",
        "      labels = [0, 1]\n",
        "      IoU = []\n",
        "      for label in labels:\n",
        "          jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "          IoU.append(jaccard)\n",
        "      IoU = np.mean(IoU) #jacard/IoU of single image\n",
        "      global_IoU.append(IoU)\n",
        "\n",
        "      cm=[]\n",
        "      accuracy = []\n",
        "      cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "      accuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1]) #accuracy of single image\n",
        "      global_accuracy.append(accuracy)\n",
        "\n",
        "\n",
        "avg_acc =  np.mean(global_accuracy)\n",
        "mean_IoU = np.mean(global_IoU)\n",
        "\n",
        "print('Average accuracy is',avg_acc)\n",
        "print('mean IoU is',mean_IoU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#prediction on single image\n",
        "from datetime import datetime \n",
        "reconstructed_image = []\n",
        "test_img = skimage.io.imread('/content/drive/MyDrive/DRIVE/test/images/01_test.tif') #test image\n",
        "\n",
        "predicted_patches = []\n",
        "start = datetime.now()   \n",
        "\n",
        "test = test_img[:,:,1] #selecting green channel\n",
        "test = clahe_equalized(test) #applying CLAHE\n",
        "SIZE_X = (test_img.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "SIZE_Y = (test_img.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "test = cv2.resize(test, (SIZE_X, SIZE_Y))        \n",
        "test = np.array(test)\n",
        "patches = patchify(test, (patch_size, patch_size), step=patch_size) #create patches(patch_sizexpatch_sizex1)\n",
        "\n",
        "for i in range(patches.shape[0]):\n",
        "      for j in range(patches.shape[1]):\n",
        "          single_patch = patches[i,j,:,:]\n",
        "          single_patch_norm = (single_patch.astype('float32')) / 255.\n",
        "          single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
        "          single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "          single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8) #predict on single patch\n",
        "          predicted_patches.append(single_patch_prediction)\n",
        "predicted_patches = np.array(predicted_patches)\n",
        "predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
        "reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape) #join patches to form whole img\n",
        "\n",
        "stop = datetime.now()\n",
        "print('Execution time: ',(stop-start)) #computation time\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Test Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(test_img)\n",
        "plt.subplot(122)\n",
        "plt.title('Prediction')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(reconstructed_image,cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LpwM8YPm8FFX",
        "outputId": "f7cb6ffb-3ed1-4f1f-baaa-117d242dd7e0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 512, 512, 16  160         ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 512, 512, 16  64         ['conv2d_171[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_171[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_81 (Dropout)           (None, 512, 512, 16  0           ['activation_171[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 512, 512, 16  2320        ['dropout_81[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 512, 512, 16  64         ['conv2d_172[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_172[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_36 (MaxPooling2D  (None, 256, 256, 16  0          ['activation_172[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 256, 256, 32  4640        ['max_pooling2d_36[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 256, 256, 32  128        ['conv2d_173[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_173[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_82 (Dropout)           (None, 256, 256, 32  0           ['activation_173[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 256, 256, 32  9248        ['dropout_82[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 256, 256, 32  128        ['conv2d_174[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_174[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_37 (MaxPooling2D  (None, 128, 128, 32  0          ['activation_174[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 128, 128, 64  18496       ['max_pooling2d_37[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 128, 128, 64  256        ['conv2d_175[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_175[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_83 (Dropout)           (None, 128, 128, 64  0           ['activation_175[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 128, 128, 64  36928       ['dropout_83[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 128, 128, 64  256        ['conv2d_176[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_176[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_38 (MaxPooling2D  (None, 64, 64, 64)  0           ['activation_176[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 64, 64, 128)  73856       ['max_pooling2d_38[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 64, 64, 128)  512        ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " dropout_84 (Dropout)           (None, 64, 64, 128)  0           ['activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 64, 64, 128)  147584      ['dropout_84[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 64, 64, 128)  512        ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_39 (MaxPooling2D  (None, 32, 32, 128)  0          ['activation_178[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 32, 32, 256)  295168      ['max_pooling2d_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 32, 32, 256)  1024       ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " dropout_85 (Dropout)           (None, 32, 32, 256)  0           ['activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 32, 32, 256)  590080      ['dropout_85[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 32, 32, 256)  1024       ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_36 (UpSampling2D  (None, 64, 64, 256)  0          ['activation_180[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 64, 64, 384)  0           ['up_sampling2d_36[0][0]',       \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 64, 64, 128)  442496      ['concatenate_36[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 64, 64, 128)  512        ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " dropout_86 (Dropout)           (None, 64, 64, 128)  0           ['activation_181[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 64, 64, 128)  147584      ['dropout_86[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 64, 64, 128)  512        ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_37 (UpSampling2D  (None, 128, 128, 12  0          ['activation_182[0][0]']         \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 128, 128, 19  0           ['up_sampling2d_37[0][0]',       \n",
            "                                2)                                'activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 128, 128, 64  110656      ['concatenate_37[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 128, 128, 64  256        ['conv2d_183[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_183[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_87 (Dropout)           (None, 128, 128, 64  0           ['activation_183[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 128, 128, 64  36928       ['dropout_87[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 128, 128, 64  256        ['conv2d_184[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_184[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_38 (UpSampling2D  (None, 256, 256, 64  0          ['activation_184[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 256, 256, 96  0           ['up_sampling2d_38[0][0]',       \n",
            "                                )                                 'activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 256, 256, 32  27680       ['concatenate_38[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 256, 256, 32  128        ['conv2d_185[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_185[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_88 (Dropout)           (None, 256, 256, 32  0           ['activation_185[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 256, 256, 32  9248        ['dropout_88[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 256, 256, 32  128        ['conv2d_186[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 256, 256, 32  0           ['batch_normalization_186[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_39 (UpSampling2D  (None, 512, 512, 32  0          ['activation_186[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 512, 512, 48  0           ['up_sampling2d_39[0][0]',       \n",
            "                                )                                 'activation_172[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 512, 512, 16  6928        ['concatenate_39[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 512, 512, 16  64         ['conv2d_187[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_187[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_89 (Dropout)           (None, 512, 512, 16  0           ['activation_187[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)            (None, 512, 512, 16  2320        ['dropout_89[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_188 (Batch  (None, 512, 512, 16  64         ['conv2d_188[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_188 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_188[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)            (None, 512, 512, 1)  17          ['activation_188[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_189 (Batch  (None, 512, 512, 1)  4          ['conv2d_189[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_189 (Activation)    (None, 512, 512, 1)  0           ['batch_normalization_189[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,968,229\n",
            "Trainable params: 1,965,283\n",
            "Non-trainable params: 2,946\n",
            "__________________________________________________________________________________________________\n",
            "Average accuracy is nan\n",
            "mean IoU is nan\n",
            "Execution time:  0:00:00.455922\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime \n",
        "reconstructed_image = []\n",
        "test_img = skimage.io.imread('/content/drive/MyDrive/DRIVE/test/images/01_test.tif') #test image\n",
        "\n",
        "predicted_patches = []\n",
        "start = datetime.now()   \n",
        "\n",
        "test = test_img[:,:,1] #selecting green channel\n",
        "test = clahe_equalized(test) #applying CLAHE\n",
        "SIZE_X = (test_img.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "SIZE_Y = (test_img.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "test = cv2.resize(test, (SIZE_X, SIZE_Y))        \n",
        "test = np.array(test)\n",
        "patches = patchify(test, (patch_size, patch_size), step=patch_size) #create patches(patch_sizexpatch_sizex1)\n",
        "\n",
        "for i in range(patches.shape[0]):\n",
        "      for j in range(patches.shape[1]):\n",
        "          single_patch = patches[i,j,:,:]\n",
        "          single_patch_norm = (single_patch.astype('float32')) / 255.\n",
        "          single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
        "          single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "          single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8) #predict on single patch\n",
        "          predicted_patches.append(single_patch_prediction)\n",
        "predicted_patches = np.array(predicted_patches)\n",
        "predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
        "reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape) #join patches to form whole img\n",
        "\n",
        "stop = datetime.now()\n",
        "print('Execution time: ',(stop-start)) #computation time\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Test Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(test_img)\n",
        "plt.subplot(122)\n",
        "plt.title('Prediction')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(reconstructed_image,cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "J6sC_dlcEq1K",
        "outputId": "09619ece-6b83-4627-db2b-8fefd90b162e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time:  0:00:00.061712\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking segmentation results\n",
        "import random\n",
        "test_img_number = random.randint(0, len(testimg))\n",
        "plt.figure(figsize=(20, 18))\n",
        "plt.subplot(123)\n",
        "plt.title('Test Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(testimg[test_img_number])\n",
        "plt.subplot(011)\n",
        "plt.title('Ground Truth')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(ground_truth[test_img_number],cmap='gray')\n",
        "plt.subplot(022)\n",
        "plt.title('Prediction')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(prediction[test_img_number],cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "IKEQ9bXlF7hY",
        "outputId": "48190302-775e-470a-9923-c9256f9f3447"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-43443037c364>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    plt.subplot(011)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
          ]
        }
      ]
    }
  ]
}